<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jongmin&#39;s Blog</title>
  <icon>https://www.gravatar.com/avatar/b47cc7a7502c34344cff139c35f843bd</icon>
  <subtitle>Survivor of digital era, SW engineer, evangelist, husband and father</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://kimjmin.net/"/>
  <updated>2019-08-22T01:11:19.370Z</updated>
  <id>http://kimjmin.net/</id>
  
  <author>
    <name>Jongmin Kim (김종민)</name>
    <email>kimjmin@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2019 파이콘 부스 운영 후기</title>
    <link href="http://kimjmin.net/2019/08/2019-08-pycon-seoul/"/>
    <id>http://kimjmin.net/2019/08/2019-08-pycon-seoul/</id>
    <published>2019-08-21T03:00:00.000Z</published>
    <updated>2019-08-22T01:11:19.370Z</updated>
    
    <content type="html"><![CDATA[<p>올해도 어김없이 파이콘 행사가 돌아왔습니다. <a href="/2017/08/2017-08-pycon-seoul">2017년</a>, <a href="/2016/08/pyconapac-seoul-2016">2016년</a> 행사 운영 후기는 남겼는데 작년에는 운영기를 남기지 않았었네요. 그러고보니 블로그도 참 오랬만에 쓰는 것 같습니다.</p><p>Elastic 은 올해로 4년째 파이콘 한국 스폰서로 참여하고 있습니다. 처음 참여할때는 저 혼자 부스 지키면서 점심 교대 할 사람도 없어 아침에 김밥 싸 와서 부스 뒤에 앉아 먹고 그랬는데, 올해는 저희 직원분들이 4분이나 같이 해 주셔서 개인적으로 많이 편했습니다. 그러고보니 Elastic 도 이제 전 세계적으로는 직원이 1,500명 한국은 15분이 계시네요. 제가 처음 입사했을땐 전 세계에 200명 이었는데, 회사가 잘 커서 뿌듯합니다. 🥰</p><p>부스는 제일 구석에 있었는데, 그래도 꽤나 많은 분들이 와 주셨습니다. 여느 때와 마찬가지로 와서 설문 남겨 주시는 분들께 양말, 티셔츠, 휴대폰 홀더 같은 SWAG 들을 다는 못 드리고 (수량이 부족해서) 50%의 꽝 확률로 추첨해서 드렸습니다. 그래도 첫 날 오후 3시 즘에 다 떨어졌네요.</p><p><img src="IMG_2084.jpg" alt=""> <img src="IMG_2085.jpg" alt=""> <img src="IMG_2089.jpg" alt=""></p><p>올해는 저희 행사 예산 중에 상품 구매 예산이 20만원 정도 나와서 3분 정도는 추첨을 통해 더 좋은 경품을 드릴 수 있게 되었습니다. 제가 행사 전날 일렉트로 마트 가서 사 온 경품으로 드릴 짐벌, 키보드, 이어폰 입니다.</p><p><img src="IMG_2120.jpg" alt=""></p><p>하지만 설문만 하신 분들 전부를 대상으로 경품을 추첨 하기는 좀 그랬습니다. 파이콘 하면 열정있는 개발자들이 많이 모이는 곳인데 뭔가 개발자 스러운 챌린지 이벤트를 좀 해야하지 않나 싶었습니다. Elastic Stack 은 여러 제품들로 되어 있지만 사실 파이썬으로 만들어 진 것은 큐레이터 정도 밖에 없어서 파이콘은 항상 참여하면서도 딱히 뭔가 괜찮은 이벤트를 할 아이디어가 그 동안 없었는데, 올해는 아이디어를 좀 내서 Elastic APM 을 수집하는 챌린지를 해 보았습니다. 그래서 챌린지에 참석하신 분들 대상으로 좀 좋은 경품들을 드리기로 했습니다. </p><p>저희 Elastic 커뮤니티 회원들이 사용 하는 클라우드 서버가 있는데, 여기 파이콘 이벤트를 위한 스페이스와 전용 계정을 만들고 안내 페이지를 후다닥 구글 도큐먼트로 만들었습니다.</p><p><a href="https://docs.google.com/document/d/1QU7fui79WinkxLrl7goXNTRXveR6ozlqTOORp3-X218" target="_blank" rel="noopener"><img src="apm-event.png" alt=""></a></p><p>본인이 개발 중인 토이 프로젝트 등에 몇 줄의 코드만 삽입하면 저희가 준비한 클라우드 서버로 APM 데이터가 수집되는 이벤트 입니다. Elastic APM 에서 지원되는 장고, 플래스크, node.js, 레일즈, 스프링 등을 사용 해 보신 분이라면 30분 정도면 금방 할 수 있는 수준이라고 저는 생각했습니다. 업계 유명 연예인이신 <a href="https://blog.outsider.ne.kr/" target="_blank" rel="noopener">변정훈</a> 님이 node.js 로 제일 처음 참여 해 주셨고, 다른 분들도 한분 한분 참여 해 주셨는데, 둘째날 마감 30분 전에 부스 앞에 노트북 들고 앉아서 완성 해 주신 분도 계셨습니다. 일단 수집에 성공하면 클라우드 서버에 바로 목록이 나타나기 때문에 저희가 실시간으로 확인이 가능합니다.</p><p><img src="apm-screen.png" alt=""> <img src="apm-screen-2.png" alt=""></p><p>추첨에 참여할 조건은 </p><ol><li>APM 데이터가 성공적으로 클라우드에 수집됨</li><li>일반 설문에 답변하고 설문 마지막 문항에 애플리케이션명 정확히 기입</li></ol><p>이었습니다. 한 20분 정도만 지원하면 딱 좋겠다 했는데, 정확히 17분이 지원 해 주셨고 그 중 5분은 설문 미참여 내지는 불확실로 추첨 제외 해서 최종적으로 12분이서 1,2,3등 상품을 두고 사다리 타기를 했습니다. 아래는 사다리 추첨 때의 영상과 사진들입니다.</p><iframe src="https://www.facebook.com/plugins/video.php?href=https%3A%2F%2Fwww.facebook.com%2Fkimjmin81%2Fvideos%2F2992519370789422%2F&show_text=0&width=560" width="560" height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true"></iframe><p><img src="Image from iOS-2.jpg" alt=""> <img src="Image from iOS-6.jpg" alt=""> </p><p>챌린지 이벤트 진행이 제가 생각했던 모양대로 어느정도 잘 흘러가서 참 좋았습니다. 이벤트 안내 페이지와 클라우드 서버는 파이콘이 끝난 이후에도 계속 유지하고 있습니다. Elastic APM 테스트 해 보실 분들은 지금도 들어가셔서 해 보실 수 있습니다. <a href="https://docs.google.com/document/d/1QU7fui79WinkxLrl7goXNTRXveR6ozlqTOORp3-X218" target="_blank" rel="noopener">이벤트 안내 페이지는 여기 있습니다.</a></p><p>일반 SWAG 추첨이랑 챌린지 이벤트 외에도 올해는 Elastic Cloud 30일 무료 제공 코드도 가지고 왔습니다. 그냥 가입하면 원래는 14일간 무료입니다. 스탠딩 배너에 저희 <a href="https://www.facebook.com/groups/elasticsearch.kr/" target="_blank" rel="noopener">한국 Elastic 페이스북 커뮤니티</a>로 링크되는 QR 코드까지 포함하면 이번 부스에는 가지고 온 QR 코드 링크만 4개였네요</p><p><img src="IMG_2113.jpg" alt=""></p><p>올해는 부스에서 도와 주신 분들이 많아 맘 편하게 세션도 몇개 들을 수 있었습니다. 파이콘 대가이시면서 저희 서포트 엔지니어이신 조인석님의 발표도 들었습니다.</p><p><img src="IMG_2099.jpg" alt=""></p><p>올해도 여느때와 마찬가지로 즐거운 시간이었습니다. 매년 점점 더 발전하면서도 처음의 즐거움과 열정을 잃지 않는 파이썬 커뮤니티, 앞으로도 계속 번창하길 바라겠습니다. 내년에는 Gold 보다 더 높은 스폰서로 참여할 수 있도록 노력 해 보겠습니다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;올해도 어김없이 파이콘 행사가 돌아왔습니다. &lt;a href=&quot;/2017/08/2017-08-pycon-seoul&quot;&gt;2017년&lt;/a&gt;, &lt;a href=&quot;/2016/08/pyconapac-seoul-2016&quot;&gt;2016년&lt;/a&gt; 행사 운영 후기는 남겼
      
    
    </summary>
    
      <category term="ICT" scheme="http://kimjmin.net/categories/ICT/"/>
    
    
      <category term="PyCon" scheme="http://kimjmin.net/tags/PyCon/"/>
    
      <category term="Conference" scheme="http://kimjmin.net/tags/Conference/"/>
    
      <category term="파이콘" scheme="http://kimjmin.net/tags/%ED%8C%8C%EC%9D%B4%EC%BD%98/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Stack 7.0 출시 밎 지금까지의 변경들</title>
    <link href="http://kimjmin.net/2019/04/2019-04-elastic-stack-7-release/"/>
    <id>http://kimjmin.net/2019/04/2019-04-elastic-stack-7-release/</id>
    <published>2019-04-09T15:00:00.000Z</published>
    <updated>2019-08-21T01:21:20.990Z</updated>
    
    <content type="html"><![CDATA[<p>Elasticsearch, Kibana, Logstash, Beats 제품들을 개발하는 Elastic 사 에서는 이 4 제품들을 통틀어 Elastic Stack 이라고 부릅니다. 예전에 Beats가 생기기 전에는 ELK(Elsaticsearch, Logstash, Kibana) 스택으로 더 잘 알려져 있었는데 이 스토리는 <a href="https://www.elastic.co/kr/elk-stack" target="_blank" rel="noopener">https://www.elastic.co/kr/elk-stack</a> 페이지에서 좀 더 자세히 보실 수 있습니다.</p><p>Elastic Stack은 5.0 부터 ELKB 제품들의 버전을 모두 일치시키면서 같이 릴리즈를 해 왔습니다. 여느 소프트웨어 제품들과 마찬가지로 Elastic Stack 제품들은 <code>6.5.1</code> 처럼 <code>메이져.마이너.버그픽스</code> 규칙으로 넘버링이 됩니다. 하지만 보통 Elastic Stack은 <font color="blue"><strong>마이너 버전</strong>에서 기능들이 추가</font> 되고 <font color="red"><strong>메이져 버전</strong>은 색인, 검색 성능 및 안전성의 개선에 초점을 맞추기 때문에 <strong>오히려 기능들이 Deprecated 되거나 Expire</strong></font> 되는 경우가 많습니다. 메이져 업데이트의 경우 Elasticsearch 가 핵심으로 사용하는 Lucene(루씬) 의 메이져 버전과 같이 업데이트 하기 때문에 데이터의 저장 방식이 바뀐다거나 탐색 또는 스코어링 공식이 바뀌는 등의 구조적인 변화가 있기 때문에 이전 버전에서 지원하던 기능이 더 이상 지원되지 않는 경우가 많기 때문입니다.</p><p>5.0 버전 부터 그 동안 있었던 주요 변경점을 간단히 살펴보면 다음과 같습니다. 상세한 내용은 공식 홈페이지의 릴리스 블로그 포스트 (<a href="https://www.elastic.co/blog/category/releases" target="_blank" rel="noopener">https://www.elastic.co/blog/category/releases</a>) 에서 모두 살펴보실 수 있습니다.</p><h3 id="Elastic-Stack-5-x"><a href="#Elastic-Stack-5-x" class="headerlink" title="Elastic Stack 5.x"></a>Elastic Stack 5.x</h3><blockquote><p>5.x 에서는 상용 플러그인인 X-Pack 출시와 Elastic Cloud Enterprise 같은 로드맵의 발표, 그리고 BKD-Tree를 이용한 IP, Geo 등의 연산 및 색인속도의 상승이 가장 주요한 포인트였습니다.</p></blockquote><p><img src="5-improve.png" alt=""></p><ul><li><a href="https://www.elastic.co/blog/elastic-stack-5-0-0-released" target="_blank" rel="noopener">5.0</a> : X-Pack, Ingest Node, Painless 스크립트 언어, BKD-Tree 를 이용한 half-float 등의 구조 추가및 성능 향상, 기본 검색으로 BM25 사용, 운영 환경에서 부트스트랩 체크, Kibana 전반적인 디자인 변경 등</li><li><a href="https://www.elastic.co/blog/elastic-stack-5-3-0-released" target="_blank" rel="noopener">5.3</a> : Cross Cluster Search, Logstash의 Persistent Queues (디스크 큐), Logstash 모니터링, Beats 모듈</li><li><a href="https://www.elastic.co/blog/elastic-stack-5-4-0-released" target="_blank" rel="noopener">5.4</a> : <a href="https://www.elastic.co/kr/blog/introducing-machine-learning-for-the-elastic-stack" target="_blank" rel="noopener">머신러닝</a> 기능 추가</li><li><a href="https://www.elastic.co/blog/elastic-stack-5-6-0-released" target="_blank" rel="noopener">5.6</a> : 6.0 으로 롤링 업그레이드를 위한 마이그레이션 도구 지원</li></ul><h3 id="Elastic-Stack-6-x"><a href="#Elastic-Stack-6-x" class="headerlink" title="Elastic Stack 6.x"></a>Elastic Stack 6.x</h3><blockquote><p>6.x 은 sparse fields 를 개선한 디스크 저장 효율 개선, Sequence ID를 이용한 리커버리 효율 개선, 5.6 에서 6.x 으로 중단 없는 롤링 업그레이드가 가장 주요한 포인트였습니다. 그리고 시스템 안정성 때문에 Type 을 하나로 제한하는 변화가 있었습니다. 그 외에도 점차 스택에서 솔루션 으로 제품 컨셉이 변경이 되면서 각 마이너 버전 마다 추가되는 기능들이 많았습니다.</p></blockquote><p><img src="6-improve.png" alt=""></p><ul><li><a href="https://www.elastic.co/blog/elastic-stack-6-0-0-released" target="_blank" rel="noopener">6.0</a> : <strong><font color="red">type을 한개만 쓸 수 있도록 제한</font></strong>, 롤링 업그레이드, Sequence ID를 이용한 리커버리, sparse fields, Kibana 디자인이 색약자들을 고려한 형태로 변경 등</li><li><a href="https://www.elastic.co/blog/elastic-stack-6-1-0-released" target="_blank" rel="noopener">6.1</a> : APM 출시</li><li><a href="https://www.elastic.co/blog/elastic-stack-6-2-0-released" target="_blank" rel="noopener">6.2</a> : SAML 연동 인증, Beats 모니터링, Kibana의 Vega 시각화 도구 추가</li><li><a href="https://www.elastic.co/blog/elastic-stack-6-3-0-released" target="_blank" rel="noopener">6.3</a> : <strong><a href="https://www.elastic.co/kr/blog/doubling-down-on-open" target="_blank" rel="noopener">X-Pack 소스코드 공개 및 통합</a></strong>, 기본 배포판에 X-Pack Basic 탑재. 기본 배포 방식이 바뀌어서 6.2 –&gt; 6.3 으로 업그레이드 하는 것이 오히려 5.6 –&gt; 6.0 으로 업그레이드 하는 것 보다 복잡해졌습니다. 이에 따른 설정 방법은 <a href="/2018/08/2018-08-install-security-over-es63">관련 블로그 포스트</a> 에서도 설명했습니다. 그 외에도 Elasticsearch SQL, Rollups 기능이 추가되었습니다.</li><li><a href="https://www.elastic.co/blog/elastic-stack-6-4-0-released" target="_blank" rel="noopener">6.4</a> : 다른 기능은 큰 변경이 없지만, 저희 입장에서는 <a href="https://www.elastic.co/kr/blog/nori-the-official-elasticsearch-plugin-for-korean-language-analysis" target="_blank" rel="noopener">한국어 형태소 분석기인 노리</a>가 출시되었기 때문에 큰 의미가 있는 릴리즈였습니다.</li><li><a href="https://www.elastic.co/blog/elastic-stack-6-5-0-released" target="_blank" rel="noopener">6.5</a> : 클러스터간 복제(Cross Cluster Replication), Kibana에 Infra, Log 앱 추가, Beats 중앙 관리 기능 등</li><li><a href="https://www.elastic.co/blog/elastic-stack-6-6-0-released" target="_blank" rel="noopener">6.6</a> : 프로즌 인덱스, Kibana에서 Index Lifecicle 관리 UI 등. 그리고 정식 릴리즈에 포함된 것은 아니지만 이 시기에 <a href="/2019/01/2019-01-korea-region-map">Elastic Map Service 에 한국 시군구 지도를 추가</a>했습니다.</li><li><a href="https://www.elastic.co/blog/elastic-stack-6-7-0-released" target="_blank" rel="noopener">6.7</a> : Kibana 지도 확장 기능 및 Uptime 앱 추가.</li></ul><h3 id="Elastic-Stack-7-0"><a href="#Elastic-Stack-7-0" class="headerlink" title="Elastic Stack 7.0"></a><a href="https://www.elastic.co/blog/elastic-stack-7-0-0-released" target="_blank" rel="noopener">Elastic Stack 7.0</a></h3><p><img src="illustration-7point0-launch-01.svg" alt="https://www.elastic.co/blog/elastic-stack-7-0-0-released"></p><p>그리고 2019년 4월 7.0 버전이 출시되었습니다. 7.0 출시는 이전의 5.0, 6.0 출시 때와 비교하면 얌전하게 출시된 것 같습니다. 예전에는 메이져 버전이 출시되면 홈페이지도 전면적으로 개편하고 라이브 출시 행사도 하고 했었는데 말이죠. 7.0 에서 반영된 주요 기능들은 다음과 같습니다. 여느 메이져 버전때와 마찬가지로 7.0 에서는 기본적인 성능과 안전성 향상에 주요 포인트를 두고 있습니다.</p><h5 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a><a href="https://www.elastic.co/blog/elasticsearch-7-0-0-released" target="_blank" rel="noopener">Elasticsearch</a></h5><ul><li>Java High-Level Rest Client의 모든 기능이 완성되었습니다. 8.0 에서 transport client 는 제거됩니다.</li><li>Adaptive Replica Selection 이 7.0 부터 디폴트로 됩니다. Replica가 여러개가 있으면 더 빠른 Replica를 능동적으로 찾아 쿼리합니다.</li><li>Cross Cluster Search를 할 때 여러 원격 클러스터를 통합 검색할 때 라운드 트립을 최소화 시켜 성능을 향상시킵니다.</li><li>Refresh Interval이 기존에는 리프레시 간격이 기본 1초로 설정되어 실시간에 가까운 검색 기능을 제공했지만 이제는 (디폴트로 30초 동안) 검색 요청이 없으면 search idle 샤드로 설정하고 다음 검색 요청이 올 때 까지 리프레시가 잠정적으로 중지됩니다. 이는 색인 성능을 비약적으로 상승시킵니다.</li><li>Minimun Master Node 설정이 자동화됩니다. 이제 Quorum (Split Brain) 때문에 마스터 후보 노드의 1/2+1 값을 따로 설정하지 않아도 마스터 후보 노드가 추가되거나 제거될 때 이 값이 자동으로 설정됩니다.</li><li>Faster Top-k Retrieval 가 적용되어 단순한 쿼리를 할때 전체 도큐먼트가 아닌 top 10,000개의 도큐먼트에서 쿼리를 합니다. total hit 수와 스코어가 변하지만 쿼리 결과는 그대로이며 쿼리 속도가 약 10배 가량 향상됩니다. 정확한 hit 수를 가져와야 하는 쿼리나 aggregation 에는 적용되지 않습니다.</li><li>디폴트 Primary Shard 개수가 5 에서 1로 변경됩니다.</li><li>Open JDK 가 기본 번들로 포함되어 Java를 따로 설치하지 않아도 실행이 됩니다.</li></ul><blockquote><p>기본 설정 중에서 특히 중요한 디스커버리 설정하는 부분이 바뀌었습니다. 예전처럼 <code>discovery.zen.ping.unicast.hosts:</code> 로 하시면 안되고요 <code>discovery.seed_hosts:</code> 로 설정 해야 합니다. <code>discovery.zen.minimum_master_nodes</code> 설정도 없어지고 대신 <code>cluster.initial_master_nodes:</code> 설정에 있는 master eligible nodes 들 중에서 과반수 이상이 살아있어야 클러스터가 정상적으로 실행되도록 변경되었습니다. 자세한 내용은 도큐먼트를 참고하세요.<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.0/discovery-settings.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.0/discovery-settings.html</a></p></blockquote><h5 id="Kibana"><a href="#Kibana" class="headerlink" title="Kibana"></a><a href="https://www.elastic.co/blog/kibana-7-0-0-released" target="_blank" rel="noopener">Kibana</a></h5><p><img src="dark-mode.gif" alt=""></p><ul><li>Kibana에 새로운 UI 템플릿 셋트가 적용되었습니다.</li><li>다크 테마가 추가되었습니다.</li><li>대시보드에 반응형 디자인을 적용해서 되어 모바일 화면에서도 잘 보입니다.</li><li>Kibana Query Language가 디폴트로 적용됩니다.</li><li>확장된 Time Picker가 적용됩니다.</li></ul><h5 id="API-변경"><a href="#API-변경" class="headerlink" title="API 변경"></a>API 변경</h5><p>사실 추가된 기능들 보다 신경 쓰이는 것들은 기존에 쓰던 방식의 API의 변경 입니다. API 변경에 대한 토론은 <a href="https://github.com/elastic/elasticsearch/issues/15613#issuecomment-239435920" target="_blank" rel="noopener">해당 깃헙 이슈</a> 에서 보실 수 있습니다.</p><p>7.0을 사용하려면 클라이언트 프로그램들을 새로운 API에 맞게 수정 해야 하기 때문에 업그레이드가 망설여 지는 것이 사실입니다. 특히 6.0 때 부터 예고되었던 <strong><font color="red">Type 구조의 삭제</font></strong> 때문에 걱정 하시는 분들이 많을 것입니다. 알아보기 편하게 7.0 버전에서 변경된 API들을 아래 정리 해 보았습니다.</p><table><thead><tr><th>Search API</th><th>6.x 이전</th><th>7.0 이후</th></tr></thead><tbody><tr><td>search</td><td>/{index}/{type}/_search</td><td>{index}/_search</td></tr><tr><td>msearch</td><td>/{index}/{type}/_msearch</td><td>/{index}/_msearch</td></tr><tr><td>count</td><td>/{index}/{type}/_count</td><td>/{index}/_count</td></tr><tr><td>explain</td><td>/{index}/{type}/{id}/_explain</td><td>/{index}/_explain/{id}</td></tr><tr><td>search template</td><td>/{index}/{type}/_search/template</td><td>/{index}/_search/template</td></tr><tr><td>msearch template</td><td>/{index}/{type}/_msearch/template</td><td>/{index}/_msearch/template</td></tr></tbody></table><table><thead><tr><th>Document API</th><th>6.x 이전</th><th>7.0 이후</th></tr></thead><tbody><tr><td>index</td><td>/{index}/{type}/{id}</td><td>/{index}/<strong>_doc</strong>/{id}</td></tr><tr><td>delete</td><td>/{index}/{type}/{id}</td><td>/{index}/<strong>_doc</strong>/{id}</td></tr><tr><td>get</td><td>/{index}/{type}/{id}</td><td>/{index}/<strong>_doc</strong>/{id}</td></tr><tr><td>update</td><td>/{index}/{type}/{id}/_update</td><td>/{index}/_update/{id}</td></tr><tr><td>get source</td><td>/{index}/{type}/{id}/_source</td><td>/{index}/_source/{id}</td></tr><tr><td>bulk</td><td>/{index}/{type}/_bulk</td><td>/{index}/_bulk</td></tr><tr><td>mget</td><td>/{index}/{type}/_mget</td><td>/{index}/_mget</td></tr><tr><td>termvectors</td><td>/{index}/{type}/{id}/_termvector</td><td>/{index}/_termvector/{id}</td></tr><tr><td>mtermvectors</td><td>/{index}/{type}/_mtermvectors</td><td>/{index}/_mtermvectors</td></tr></tbody></table><table><thead><tr><th>Index API</th><th>6.x 이전</th><th>7.0 이후</th></tr></thead><tbody><tr><td>create index</td><td>/{index}</td><td>변경 없음</td></tr><tr><td>get mapping</td><td>/{index}/_mapping/{type}</td><td>/{index}/_mapping</td></tr><tr><td>put mapping</td><td>/{index}/_mapping/{type}</td><td>/{index}/_mapping</td></tr><tr><td>get field mapping</td><td>/{index}/{type}/_mapping/field/{fields}</td><td>/{index}/_mapping/field/{fields}</td></tr><tr><td>get template</td><td>/_template/{template}</td><td>변경 없음</td></tr><tr><td>put template</td><td>/_template/{template}</td><td>변경 없음</td></tr></tbody></table><p>Search 그리고 Index API 에서는 type 을 입력하던 부분을 모두 생략한다고 생각 하면 될 것 같습니다. Document API 에서를 type 이 들어가던 부분을 지정자 <strong><code>_doc</code></strong> 로 대치하면 대부분 적용됩니다. 그리고 제가 테스트 해 본 결과 Document API 의 경우에는 7.0 에서 <code>/{index}/_update/{id}</code> 대신 <code>/{index}/_doc/{id}/_update</code>  처럼 과거 형식으로 입력을 해도 정상적으로 실행이 됩니다.</p><h4 id="5-x-에서-업그레이드를-할-때-다중-type을-단일-type으로"><a href="#5-x-에서-업그레이드를-할-때-다중-type을-단일-type으로" class="headerlink" title="5.x 에서 업그레이드를 할 때 다중 type을 단일 type으로"></a>5.x 에서 업그레이드를 할 때 다중 type을 단일 type으로</h4><p>사실 큰 문제는 5.x 이전 버전에서 한 인덱스에 여러 타입을 사용중인 경우 일 것입니다. 이 경우는 어쩔 수 없이 Logstash 또는 _reindex API를 이용해서 구조를 변경해서 새로 재 색인을 해야 합니다. 이에 관한 가이드는 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.0/removal-of-types.html" target="_blank" rel="noopener">Removal of mapping types</a> 페이지에서 볼 수 있습니다. 좀 더 팁을 드리자면 다음과 같은 경우들로 구분해서 생각을 해 볼 수 있을 것 같습니다.</p><h5 id="type-별로-다른-매핑을-사용하는-경우"><a href="#type-별로-다른-매핑을-사용하는-경우" class="headerlink" title="type 별로 다른 매핑을 사용하는 경우"></a>type 별로 다른 매핑을 사용하는 경우</h5><p>이때는 각각의 type 별로 새로운 인덱스를 만들어야 할 것입니다. 예를 들어 아래와 같이 my_index 라는 인덱스에 type_1, type_2 두개의 타입이 있는 경우<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;type_1&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;type_2&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>아래 처럼 타입 별로 인덱스를 나누어 생성하고 데이터를 재색인 해야 합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT my_index-type_1</span><br><span class="line">&#123; ... &#125;</span><br><span class="line"></span><br><span class="line">PUT my_index-type_2</span><br><span class="line">&#123; ... &#125;</span><br></pre></td></tr></table></figure></p><p>Logstash 의 입/출력 설정은 다음과 같이 설정해서 재색인이 가능합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; &quot;http://10.0.0.1:9200&quot;</span><br><span class="line">    index =&gt; &quot;my_index&quot;</span><br><span class="line">    query =&gt; &apos;&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; &quot;query&quot;: &quot;*&quot; &#125; &#125; &#125;&apos;</span><br><span class="line">    size =&gt; 500</span><br><span class="line">    scroll =&gt; &quot;5m&quot;</span><br><span class="line">    docinfo =&gt; true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; [&quot;http://10.0.0.2:9200&quot;]</span><br><span class="line">    index =&gt; &quot;my_index-%&#123;[@metadata][_type]&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h5 id="type-별로-매핑이-거의-유사한-경우-단-동일한-도큐먼트-ID가-존재하지-않아야-함"><a href="#type-별로-매핑이-거의-유사한-경우-단-동일한-도큐먼트-ID가-존재하지-않아야-함" class="headerlink" title="type 별로 매핑이 거의 유사한 경우. 단 동일한 도큐먼트 ID가 존재하지 않아야 함."></a>type 별로 매핑이 거의 유사한 경우. 단 동일한 도큐먼트 ID가 존재하지 않아야 함.</h5><p>이 경우는 한 인덱스로 매핑을 병합해서 사용할 수 있을 것입니다. 다음과 같이 my_index 안에 type_1 에는 name, age, gender, 그리고 type_2 에는 name, age, address 라는 필드가 생성되어 있다고 가정을 하면<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;type_1&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: ...</span><br><span class="line">        &quot;age&quot;: ...</span><br><span class="line">        &quot;gender&quot;: ...</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;type_2&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: ...</span><br><span class="line">        &quot;age&quot;: ...</span><br><span class="line">        &quot;address&quot;: ...</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>아래와 같이 하나의 my_index 인덱스에 name, age, gender, address 를 병합하는 매핑을 생성합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;name&quot;: ...</span><br><span class="line">      &quot;age&quot;: ...</span><br><span class="line">      &quot;gender&quot;: ...</span><br><span class="line">      &quot;address&quot;: ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>만약에 type의 이름이 유의미한 값이었다면 type의 이름도 하나의 필드 값으로 만들어 저장하면 됩니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">      &quot;type&quot;: ... # &lt;-- &quot;type_1&quot; 또는 &quot;type_2&quot; 입력</span><br><span class="line">      &quot;name&quot;: ...</span><br><span class="line">      &quot;age&quot;: ...</span><br><span class="line">      &quot;gender&quot;: ...</span><br><span class="line">      &quot;address&quot;: ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>이 경우 Logstash 의 입/출력 설정은 다음과 같이 해서 재색인이 가능합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; &quot;http://10.0.0.1:9200&quot;</span><br><span class="line">    index =&gt; &quot;my_index&quot;</span><br><span class="line">    query =&gt; &apos;&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; &quot;query&quot;: &quot;*&quot; &#125; &#125; &#125;&apos;</span><br><span class="line">    size =&gt; 500</span><br><span class="line">    scroll =&gt; &quot;5m&quot;</span><br><span class="line">    docinfo =&gt; true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">   mutate &#123;</span><br><span class="line">    add_field =&gt; &#123; &quot;type&quot; =&gt; &quot;%&#123;[@metadata][_type]&#125;&quot; &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; [&quot;http://10.0.0.2:9200&quot;]</span><br><span class="line">    index =&gt; &quot;my_index&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h5 id="한-인덱스-안에-parent-child-구조로-type-이-나뉘어-있는-경우"><a href="#한-인덱스-안에-parent-child-구조로-type-이-나뉘어-있는-경우" class="headerlink" title="한 인덱스 안에 parent - child 구조로 type 이 나뉘어 있는 경우"></a>한 인덱스 안에 parent - child 구조로 type 이 나뉘어 있는 경우</h5><p>이 경우와 관련해서는 예전의 <a href="/2018/01/2018-01-parent-child-to-join">Elasticsearch 6.x 에서의 join 사용</a> 포스트를 참고하시기 바랍니다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Elasticsearch, Kibana, Logstash, Beats 제품들을 개발하는 Elastic 사 에서는 이 4 제품들을 통틀어 Elastic Stack 이라고 부릅니다. 예전에 Beats가 생기기 전에는 ELK(Elsaticsearch,
      
    
    </summary>
    
      <category term="Engineering" scheme="http://kimjmin.net/categories/Engineering/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Maps Service 한국지도 추가</title>
    <link href="http://kimjmin.net/2019/01/2019-01-korea-region-map/"/>
    <id>http://kimjmin.net/2019/01/2019-01-korea-region-map/</id>
    <published>2019-01-27T15:00:00.000Z</published>
    <updated>2019-01-28T04:09:52.617Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Elasticsearch-Kibana-에서-위치정보-사용"><a href="#Elasticsearch-Kibana-에서-위치정보-사용" class="headerlink" title="Elasticsearch, Kibana 에서 위치정보 사용"></a>Elasticsearch, Kibana 에서 위치정보 사용</h2><p>Elasticsearch 에서는 숫자, 텍스트 뿐 아니라 지역 정보를 가지고 활용이 가능합니다. logstash 또는 ingest pipeline 의 geopoint 필터를 사용하면 IP 주소로부터 다음과 같은 정보들의 추출이 가능합니다.</p><p><img src="region-info.png" alt=""></p><p>Elasticsearch에 지역정보를 저장하고 Kibana 에서 지역 정보를 표시하는 방법은 아래의 2가지가 있습니다.</p><p><img src="kibana-vis.png" alt=""></p><p>Coordinate Map은 위의 <code>geoip.location</code> 필드의 <code>{ &quot;lon&quot;:113.25, &quot;lat&quot;:23.1167 }</code> 같은 geo_point 형식으로 저장된 데이터를 이용해서 지도에 표시하는 방법입니다. 이 정보를 기반으로 아래와 같이 지도에 원이나 사각형, 열지도(heatmap) 형식으로 수치를 표현하는 것이 가능합니다.</p><p><img src="coordinate-map.png" alt=""></p><p>Region Map은 geo_point 가 아니라 term aggregation 을 이용해서 위의 <code>geoip.country_code</code> 필드의  <code>KR</code>,<code>US</code>,<code>CN</code> 같은 keyword 형식으로 저장된 필드의 값을 가지고 미리 정의된 geo-hash 영역에 대입하여 지도에 나타내는 방식입니다.</p><p><img src="region-map.png" alt=""></p><p>Region Map에서 지원되는 지도들은 Options 의 Vector Map 항목에서 선택이 가능합니다.</p><p><img src="select-region.png" alt=""></p><p>지원되는 지도와 데이터의 종류들은 Elastic Maps Service - <a href="https://maps.elastic.co" target="_blank" rel="noopener">https://maps.elastic.co</a> 페이지에서 확인이 가능합니다.</p><p><img src="ems-world.png" alt=""></p><h2 id="Elastic-Maps-Service-에-한국-지도-추가"><a href="#Elastic-Maps-Service-에-한국-지도-추가" class="headerlink" title="Elastic Maps Service 에 한국 지도 추가"></a>Elastic Maps Service 에 한국 지도 추가</h2><p>기쁘게도 이번에 Elastic Maps Service에 한국 지도 2종이 추가되었습니다.</p><ul><li>South Korea Provinces</li><li>South Korea Municipalities</li></ul><p>기본적으로 Elastic Maps Service 는 위키데이터에 있는 정보들을 활용합니다. South Korea Provinces 의 경우에는 <a href="https://www.wikidata.org/wiki/Q884" target="_blank" rel="noopener">wikidata</a>에 있는 정보를 활용해서 8개의 도와 서울특별시, 광역시 정도 들을 표시합니다.</p><p><img src="ems-sk-province.png" alt=""></p><p>South Korea Municipalities 지도는 시,군,구 단위까지의 정보를 표시할 수 있습니다. 이 정보는 wikidata에 없기 때문에 <a href="https://github.com/e9t" target="_blank" rel="noopener">박은정</a> 님으로부터 처음 작성된 <a href="https://github.com/southkorea/southkorea-maps" target="_blank" rel="noopener">South Korea Maps</a> 의 정보를 활용하고 있습니다. 이 중 <a href="http://kostat.go.kr" target="_blank" rel="noopener">통계청 통계지리정보서비스 - KOSTAT</a> 자료 부분을 활용합니다. </p><p><img src="ems-south-korea.png" alt=""></p><p>데이터의 출처와 라이센스는 Elastic Maps Service 의 깃헙<br><a href="https://github.com/elastic/ems-file-service/blob/master/sources/kr/README.md" target="_blank" rel="noopener">https://github.com/elastic/ems-file-service/blob/master/sources/kr/README.md</a><br>에 명시하고 있습니다.</p><p>맵 geo.json 파일은 South Korea Maps 에 있는 실제 맵 보다 사이즈를 줄이기 위해 2차 가공을 다시 한번 했습니다. KOGL 라이센스는 2차 가공을 허용한다고 명시하고 있어서 문제는 없다고 판단했습니다. Merge 기록은 아래에 있습니다.<br><a href="https://github.com/elastic/ems-file-service/pull/74" target="_blank" rel="noopener">https://github.com/elastic/ems-file-service/pull/74</a></p><p>이제 Kibana의 Region Map에서 대한민국 시군구 지도를 활용할 수 있습니다. options 에서 vector map을 South Korea Municipalities 으로 선택하고 분석할 keyword 값과 일치하는 join field를 선택하면 됩니다.<br><img src="kibana-south-korea.png" alt=""></p><p>시군구 명칭과 코드들은 <a href="https://maps.elastic.co/#file/south_korea_municipalities" target="_blank" rel="noopener">https://maps.elastic.co/#file/south_korea_municipalities</a> 에서 확인할 수 있으며 <a href="https://sgis.kostat.go.kr/contents/shortcut/shortcut_05_01.jsp" target="_blank" rel="noopener">통계청 통계지리정보서비스</a> 에서 코드표를 다운로드 할 수 있습니다. <strong>알림마당 &gt; 자료신청 &gt; 자료 다운로드</strong> 페이지 하단에 <strong>코드표 및 이용설명서</strong> 를 다운로드 하시면 됩니다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Elasticsearch-Kibana-에서-위치정보-사용&quot;&gt;&lt;a href=&quot;#Elasticsearch-Kibana-에서-위치정보-사용&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch, Kibana 에서 위치정보 
      
    
    </summary>
    
      <category term="Engineering" scheme="http://kimjmin.net/categories/Engineering/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Elastic Maps Service" scheme="http://kimjmin.net/tags/Elastic-Maps-Service/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Stack 롤링 업그레이드</title>
    <link href="http://kimjmin.net/2018/12/2018-12-elasticsearch-rolling-upgrade/"/>
    <id>http://kimjmin.net/2018/12/2018-12-elasticsearch-rolling-upgrade/</id>
    <published>2018-12-07T15:00:00.000Z</published>
    <updated>2018-12-08T02:10:22.426Z</updated>
    
    <content type="html"><![CDATA[<p>얼마 전에 Elastic Stack 6.5 가 출시되었습니다. 6.5 는 마이너 업그레이드이지만 상당히 방대한 새로운 기능들을 포함하고 있습니다. 6.5 에 대한 자세한 내용들은 출시 블로그에서 확인 바랍니다.<br><a href="https://www.elastic.co/kr/blog/elastic-stack-6-5-0-released" target="_blank" rel="noopener">https://www.elastic.co/kr/blog/elastic-stack-6-5-0-released</a></p><p><a href="/2018/01/2018-01-build-es-cluster-8">Elastic Cluster 구성</a> 시리즈에서 구성했던 시스템을 계속해서 제 여러 용도의 데모 서버로 사용하고 있습니다. 6.1 버전으로 처음 설치 한 이후에 가끔 한번씩 새 버전이 나올 때 마다 업그레이드를 해 주고 있었습니다. 이번에도 6.5.0 이 나오면서 이전에는 6.4.2 버전이었 던 것ㅇ르 새로 나온 6.5.1로 업그레이드를 하였습니다. 롤링 업그레이드 하는 전체 과정은 동영상으로 기록했습니다. 포스트 맨 하단에 있습니다.</p><p>데모 서버의 컨셉 아키텍쳐는 아래와 같습니다. 총 4개의 서버에 각각 Elasticsearch 노드를 하나씩 설치했습니다. 3개는 데이터 노드로 사용하고 하나는 Coordinate Only 노드로 설정해서 서비스 노드로 사용합니다. 서비스 노드가 있는 서버에는 Kibana, Logstash, Filebeat, Metricbeat 그리고 테스트를 위해 PHP, MySQL, Apache 웹 서버를 깔고 워드프레스 블로그를 설치 해 놓았습니다.</p><p><img src="es-architecture.png" alt=""></p><p>Elastic Stack 업그레이드에 대한 내용은 아래의 공식 도큐먼트에 자세히 나와 있습니다.<br><a href="https://www.elastic.co/guide/en/elastic-stack/current/upgrading-elastic-stack.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elastic-stack/current/upgrading-elastic-stack.html</a></p><p>Elasticsearch 를 업그레이드 하는 방법은 크게 다음의 3가지로 구분할 수 있습니다</p><p><strong><a href="#Full-Cluster-Restart">1. Full Cluster Restart</a></strong><br><strong><a href="#Cluster-Re-Index">2. Cluster Re-Index</a></strong><br><strong><a href="#Rolling-Upgrade">3. Rolling Upgrade</a></strong></p><p><img src="upgrade-support.png" alt=""></p><p>2.x –&gt; 5.x 와 같이 메이져 버전으로 업그레이드를 할 때는 롤링 업그레이드가 불가능합니다. 따라서 전체 클러스터를 재시작해야 합니다. 마이너 버전 끼리만 롤링 업그레이드가 가능하나 예외적으로 5.x 의 마지막 마이너 버전인 5.6.x 에서는 6.x 버전으로 롤링 업그레이드가 가능합니다.</p><p>다음은 각각 업그레이드에 대한 설명입니다.</p><blockquote><p>참고로 Elasticsearch 는 3, 4 메이져 버전이 없고 1.x &gt; 2.x &gt; 5.x &gt; 6.x 순서로 릴리즈가 되었습니다.</p></blockquote><h4 id="Full-Cluster-Restart"><a href="#Full-Cluster-Restart" class="headerlink" title="Full Cluster Restart"></a>Full Cluster Restart</h4><p>Full Cluster Restart 는 말 그대로 모든 노드를 내렸다가 프로그램을 업그레이드 하고 다시 전체 재시작을 하는 방법입니다. 클러스터 전체 재시작이 일어나기 때문에 필연적으로 운영 시스템의 가동 중단 시간이 발생하게 됩니다.</p><p>데이터가 저장 된 경로의 내용들을 그대로 두고 elasticsearch를 새로 설치 한 다음에 <code>path.data</code> 경로만 기존 데이터 경로로 설정하여 재실행 하면 업그레이드가 끝납니다. Unix 의 경우는 path.data 경로의 심볼릭 링크를 변경해서 업그레이드 하기도 합니다.</p><p><img src="full-cluster-restart.gif" alt=""></p><p>다만 Full Cluster Restart 라도 <strong><font color="red">2개 단계 이상의 상위 메이져 버전으로는 업그레이드가 불가능합니다</font></strong>. 2.x 버전의 운영 클러스터를 6.x 버전의 운영 클러스터로 업그레이드는 할 수 없습니다. 2개 단계 이상으로 업그레이드를 하기 위해서는 <strong><a href="#Cluster-Re-Index">Cluster Re-Index</a></strong>를 해야 합니다.<br>그리고 2.x 에서 생성한 인덱스를 5.x 으로 full cluster restart 해서 유지한 경우에도 이 인덱스는 6.x 으로 업그레이드가 불가능합니다. 5.x 클러스터에서 사용중이지만 2.x 에서 생성된 인덱스는 5.x 클러스터 안에서 다시 재색인을 해 주어야 합니다.</p><p>이전 버전에서 찍은 스냅샷을 새 버전에서 restore 해서 업그레이드 하는 방법도 있습니다. 이 경우에도 색인이 끝난 샤드의 세그먼트 파일을 그대로 복사하는 것이기 때문에 내부적으로는 <code>path.data</code> 를 유지한 Full Cluster Restart 방식과 유사하게 동작합니다. 따라서 2개 단계 이상의 버전에서는 스냅샷을 불러올 수 없습니다.</p><p><img src="snapshot-restore.png" alt=""></p><p><strong>Full Cluster Restart 의 특징을 요약하면 다음과 같습니다.</strong></p><blockquote><ul><li>운영 시스템의 가동 중단 시간이 필연적으로 발생합니다.</li><li>2 단계 이상 버전으로 업그레이드가 불가능합니다.</li><li>스냅샷 &amp; 복원 과정도 Full Cluster Restart 와 동일합니다.</li></ul></blockquote><h4 id="Cluster-Re-Index"><a href="#Cluster-Re-Index" class="headerlink" title="Cluster Re-Index"></a>Cluster Re-Index</h4><p>2.x 에서 6.x 와 같이 두개의 메이져 버전을 업그레이드 하는 경우에는 클러스터를 새로 구성하고 이전 클러스터에서 새로운 클러스터로 데이터를 재색인 하는 방법을 사용할 수 있습니다. 미리 클러스터를 이중화 시켜서 데이터의 재색인이 끝난 뒤 클라이언트 프로그램이 새로운 Elasticsearch 클러스터를 바라보도록 변경하기만 하면 가동 중단 시간도 거의 없이 안전한 업그레이드가 가능합니다. 마치 <a href="https://martinfowler.com/bliki/BlueGreenDeployment.html" target="_blank" rel="noopener">Blue Green 배포</a> 기법과 유사한 개념입니다.</p><p>인덱스에 <code>_source</code> 를 저장하지 않도록 설정했으면 그 인덱스는 재색인이 불가능 합니다. 이 경우 원본 데이터에서 다시 가져오는 방법을 써야 합니다.</p><p>이전 클러스터의 데이터를 새로운 클러스터로 재색인 하기 위해서는 <code>Logstash</code> 를 사용하거나 <code>_reindex API</code>를 활용합니다.</p><p><img src="reindex.png" alt=""></p><p>Logstash 를 사용하는 방법은 다음과 같습니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; &quot;es.production.mysite.org&quot;</span><br><span class="line">    index =&gt; &quot;mydata-2018.09.*&quot;</span><br><span class="line">    query =&gt; &apos;&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; &quot;query&quot;: &quot;*&quot; &#125; &#125; &#125;&apos;</span><br><span class="line">    size =&gt; 500</span><br><span class="line">    scroll =&gt; &quot;5m&quot;</span><br><span class="line">    docinfo =&gt; true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    index =&gt; &quot;copy-of-production.%&#123;[@metadata][_index]&#125;&quot;</span><br><span class="line">    document_type =&gt; &quot;%&#123;[@metadata][_type]&#125;&quot;</span><br><span class="line">    document_id =&gt; &quot;%&#123;[@metadata][_id]&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><code>docinfo =&gt; true</code> 설정을 하면 document_id 까지 모두 동일하게 재색인을 합니다. 더 자세한 설명은 <a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-elasticsearch.html" target="_blank" rel="noopener">Logstahs Elasticsearch input 도큐먼트</a>를 참고하세요.</p><p>원격 클러스터간 _reindex API 를 사용하는 방법은 다음과 같습니다.<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"source"</span>: &#123;</span><br><span class="line">    <span class="attr">"remote"</span>: &#123;</span><br><span class="line">      <span class="attr">"host"</span>: <span class="string">"http://otherhost:9200"</span>,</span><br><span class="line">      <span class="attr">"username"</span>: <span class="string">"user"</span>,</span><br><span class="line">      <span class="attr">"password"</span>: <span class="string">"pass"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"source"</span>,</span><br><span class="line">    <span class="attr">"query"</span>: &#123;</span><br><span class="line">      <span class="attr">"match"</span>: &#123;</span><br><span class="line">        <span class="attr">"test"</span>: <span class="string">"data"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"dest"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"dest"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>원격 클러스터간 _reindex API를 사용하려면 <code>elasticsearch.yml</code> 파일에 다음과 같이 <code>reindex.remote.whitelist</code> 설정이 되어 있어야 합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reindex.remote.whitelist: &quot;otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*&quot;</span><br></pre></td></tr></table></figure></p><p>_reindex 는 기본적으로 <code>document_id</code>, <code>@timestamp</code> 값 까지 동일하게 복사합니다. 더 자세한 설명은 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.5/docs-reindex.html" target="_blank" rel="noopener">_reindex API 도큐먼트</a>를 참고하세요.</p><p><strong>Cluster Re-Index 의 특징을 요약하면 다음과 같습니다.</strong></p><blockquote><ul><li>2 단계 이상의 버전으로 바로 업그레이드가 가능합니다.</li><li>클러스터를 별도로 준비를 위한 비용이 발생합니다.</li><li>데이터를 새로 색인해야 하기 때문에 다른 업그레이드 방법들과 비교하여 시간이 오래 걸립니다.</li><li>비교적 안정적으로 가동 중단 시간 없이 업그레이드가 가능합니다.</li><li>_source 가 저장되어 있지 않으면 사용이 불가능합니다.</li></ul></blockquote><h4 id="Rolling-Upgrade"><a href="#Rolling-Upgrade" class="headerlink" title="Rolling Upgrade"></a>Rolling Upgrade</h4><p>6.4.1 -&gt; 6.5.1 같이 마이너 버전 간에는 롤링 업그레이드가 가능합니다. 롤링 업그레이드는 클러스터에 있는 노드들을 하나씩 내리고 업그레이드 한 뒤 다시 시작해서 업그레이드를 하는 방식입니다. Elasticsearch 노드들 간에는 메이져 버전이 같으면 마이너 버전이 달라도 클러스터 구성이 가능하기 때문에 사용 가능한 방법입니다. 클러스터 전체를 재시작 하지 않기 때문에 가동 중단 시간이 발생하지 않습니다.</p><p><img src="rolling-upgrade.gif" alt=""></p><p>원래는 마이너 버전 간의 업그레이드이지만, 5.6.x 부터는 메이져 버전의 가장 마지막 버전은 그 다음 메이져 버전으로도 롤링 업그레이드가 가능합니다. 메이져 버전 간에 롤링 업그레이드를 할때는 Kibana에 제공되는 마이그레이션 도구를 이용해서 이전 버전의 인덱스들이 새 버전으로 마이그레이션 했을 때 문제 없이 실행이 되는지를 체크하는 것이 안전합니다. </p><p>6.2 이전의 버전과 6.3 이후 버전의 경우에도 배포판의 방식에 큰 변경이 있었기 때문에 별도 가이드 도구가 제공됩니다. 아래 사이트에서 확인이 가능합니다.<br><a href="https://www.elastic.co/products/upgrade_guide" target="_blank" rel="noopener">https://www.elastic.co/products/upgrade_guide</a><br><img src="upgrade-tool.png" alt=""></p><p>그리고 예전에 작성된 <a href="/2018/08/2018-08-install-security-over-es63">Elastic 6.3 에서 상용 라이센스 활성</a> 블로그포스트도 참고하시기 바랍니다.</p><p>롤링 업그레이드는 다음 순서로 진행됩니다. 자세한 내용은 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.5/rolling-upgrades.html" target="_blank" rel="noopener">Rolling upgrades 도큐먼트</a> 에 있습니다.</p><ol><li><p>Shard Allocation 중지 : 노드를 중단했을때 샤드들이 재배치 되지 않도록 다음 명령을 실행합니다.</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"persistent"</span>: &#123;</span><br><span class="line">    <span class="attr">"cluster.routing.allocation.enable"</span>: <span class="string">"none"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Sync Flus 실행 : Primary - Replica 샤드들 간의 세그먼트 저장 상태를 동기화 시켜줍니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST _flush/synced</span><br></pre></td></tr></table></figure></li><li><p>노드 1개 중단 : 중단하고 나면 클러스터 상태가 <strong><font color="orange">Yellow</font></strong> 로 됩니다.</p></li><li>중단한 노드 업그레이드 : 이 때 설치된 플러그인들도 모두 제거하고 새 버전에 맞게 새로 설치 해 줘야 합니다.</li><li><p>중단한 노드 재시작 : 아래 명령으로 노드가 정상적으로 실행됬는지 확인합니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET _cat/nodes</span><br></pre></td></tr></table></figure></li><li><p>Shard Allocation 재가동 : unassigned 된 샤들이 새 노드에 다시 배치되도록 다음 명령을 실행합니다.</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"persistent"</span>: &#123;</span><br><span class="line">    <span class="attr">"cluster.routing.allocation.enable"</span>: <span class="literal">null</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>클러스터 상태가 <strong><font color="green">Green</font></strong> 이 될 때 까지 기다립니다. 클러스터 상태는 아래 명령으로 확인이 가능합니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET _cat/health</span><br></pre></td></tr></table></figure></li><li><p>클러스터 상태가 <strong><font color="green">Green</font></strong>이 되고 나면 다시 1번 과정 부터 모든 노드들에 돌아가면서 실행을 반복합니다.</p></li></ol><p><strong>Rolling Upgrade 의 특징을 요약하면 다음과 같습니다.</strong></p><blockquote><ul><li>마이너 버전 혹은 메이져의 마지막 버전에서만 사용이 가능합니다.</li><li>운영 시스템의 가동 중단 시간이 발생하지 않습니다.</li><li>절차가 복잡하여 플러그인 미설치, 샤드 중단 미실행 등의 실수나 unassign 중 새로 색인된 샤드 등이 있을 때 대규모의 샤드 재배치가 발생하여 시스템에 부하가 발생 할 위험이 있습니다.</li></ul></blockquote><p>아래는 처음 언급한 데모 환경을 6.4.2 에서 6.5.1로 업그레이드 하는 과정을 녹화 한 영상입니다. 앞의 롤링 업그레이드 과정을 실행하고 있으니 참고 해 보시기 바랍니다.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/fkwMt_K0nRQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;얼마 전에 Elastic Stack 6.5 가 출시되었습니다. 6.5 는 마이너 업그레이드이지만 상당히 방대한 새로운 기능들을 포함하고 있습니다. 6.5 에 대한 자세한 내용들은 출시 블로그에서 확인 바랍니다.&lt;br&gt;&lt;a href=&quot;https:/
      
    
    </summary>
    
      <category term="Engineering" scheme="http://kimjmin.net/categories/Engineering/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Elastic Cluster Settings" scheme="http://kimjmin.net/tags/Elastic-Cluster-Settings/"/>
    
  </entry>
  
  <entry>
    <title>나는 과연 SW Engineer 라고 말할 수 있을까?</title>
    <link href="http://kimjmin.net/2018/10/2018-10-am-i-engineer/"/>
    <id>http://kimjmin.net/2018/10/2018-10-am-i-engineer/</id>
    <published>2018-10-25T15:00:00.000Z</published>
    <updated>2018-10-26T06:37:27.139Z</updated>
    
    <content type="html"><![CDATA[<p>저는 지금 Elastic 에서 Community Engineer 라는 직책을 맡고 있습니다. 주 업무는 개발자 커뮤니티를 지원하는 일이고요 (물론 저는 한국에 직원이 많이 없어서 이런 저런 다른 일들도 많이 합니다), 다른 회사에서는 Evangelist 혹은 Developer Advocate 이라는 직함을 쓰는 곳도 있습니다. 저도 예전에는 전도사(Evangelist) 직함을 사용했었습니다.</p><p>소속되어 있는 팀도 지금은 Community Team 이라고 하는데, 예전 팀 이름은 DevRel Team 이었습니다. 처음 입사할 때는 7명이었는데 사람들이 나가고, 들어오고, 팀 옮기고 하면서 지금은 17명 입니다. 아직은 기업에서 Community 팀을 따로 운영하지 않는 곳이 많이 있지만, Elastic은 Community 팀을 매우 중요하게 생각합니다. 홈페이지의 엔지니어 팀 소개에도 당당히 3번째로 올라와 있습니다.</p><p><img src="engineering-page.png" alt=""></p><p>새 입사 직원들의 입문 교육때도 Community Team 에 대해 이야기하는 시간이 별도로 있고, 가끔은 저희 팀 미팅에 CEO(창업자)인 Shay Banon이 참여하기도 합니다. 그리고 제 매니저인 저희 팀 리더도 대부분의 리더쉽 미팅에 참여하며 꽤 중요한 발언들을 하곤 합니다.</p><p>Community Team은 팀원들의 역할이 제각각이라 Job을 정의하는것이 쉽지가 않습니다. 팀 안에 크게는 Advocate 과 Program 팀이 나누어져 있는데, Program 팀은 일반 Community 들을 찾아내고, 필요한 도움을 주는것이 주 역할이고, Advocate 은 컨퍼런스나 밋업에서 저희 기술 소개를 하는것이 주 역할입니다. 저는 Advocate 이지만 한국에서는 Program도 같이 겸하고 있습니다.</p><p><img src="community-team.jpg" alt=""></p><p>Community Team 은 저희 회사에서 Distributed 비중이 가장 큰 팀입니다. 17명의 직원이 14개 국가, 11개의 서로 다른 타임존에서 근무를 하고 있습니다. 각자 지역에서 하는 일도 다르고, 역할의 비중도 다르다보니, 저희는 회사가 정한 업무나 매니저와 함께 일을 정하는 것이 아니라, 대부분은 개개인이 스스로 일을 찾아서 하는 편입니다. 간혹 program 팀원이 어느 지역에 어떤 컨퍼런스나 밋업이 있다고 찾아서 알려주고 가서 발표좀 해 달라고 요청이 오기도 하지만, 보통은 각자 로컬에 있는 이벤트들을 직접 찾아서 발표 신청하고, 발표 준비해서 발표하고, 끝나면 이벤트 정리하는 일들을 각각 하는 편입니다.</p><p>이런 식으로 일을 하다 보니 팀원들마다 하는 일의 분량도, 비중도 다릅니다. 특히 저 같은 경우 한국에 직원이 많지 않다보니 서포트, 교육, 기술영업도 많이 하는데, 저희 유럽에 있는 팀원들의 경우는 1년에 컨퍼런스, 밋업에서 발표하는 횟수가 50번 정도 됩니다. 그래서 저희는 개인 평가 지표라는 것이 없습니다. 각자가 하는 일의 비중이 다르다보니 비교가 쉽지 않습니다. 좋은 점은 자유도가 높아 목표달성에 대한 스트레스가 적고, 나쁘게 말하면 승진이나 연봉 상승의 기회가 적습니다.</p><p>팀원들마다 각자 고충이 있겠지만 저희 팀원들이 하는 가장 큰 고민은 오늘 제목처럼</p><blockquote><p>나는 과연 SW Engineer 라고 말할 수 있을까?</p></blockquote><p>하는 것입니다.</p><p>저희 advocate 팀원들도 대부분 이전 직장에서는 프로그램 개발 일을 하던 사람들이었습니다. 커뮤니티 활동이 좋아서 지금은 커뮤니티 활동이 직업이 되었지만, 마음 한 구석에는 <em>*그래도 엔지니어인데, 이렇게 개발에 손을 놔도 되나…</em> 하는 생각들을 대부분 하고 있습니다. 저 역시 마찬가지이고요.</p><p>지금은 저도 컴퓨터로 하는 생산 작업들은</p><ul><li>발표/교육 자료 만들기</li><li>데모 만들기</li><li>블로그 쓰기</li></ul><p>정도입니다. 물론 써 놓은 블로그들과, 데모를 만들면서 작업한 설정파일 등이 나중에 서포트나 컨설팅, 교육 등을 할때 정말 유용하게 쓰이고는 있습니다. 그래도 마지막으로 뭔가 돌아가는 프로그램을 만들어본건 언제인지 기억도 잘 안 나네요.</p><p>하지만 Elastic 에서 만큼은 Community Engineer 라는 업무에 자부심을 가지고 일할 수 있을것 같습니다. 이유는 크게 두가지 입니다.</p><h3 id="1-엔지니어로서-동료들에게-인정을-받는다"><a href="#1-엔지니어로서-동료들에게-인정을-받는다" class="headerlink" title="1. 엔지니어로서 동료들에게 인정을 받는다"></a>1. 엔지니어로서 동료들에게 인정을 받는다</h3><p>요즘 기업들 마다 SW Engineer 구하려고 난리입니다. 좋은 프로그래머 구하기가 하늘의 별따기라고 하지요. 비전공자이거나 심지어 다른 업무를 하던 사람들도 요즘은 코딩을 배워 프로그래머가 되려고 하는 사람들도 많습니다. 또 예전처럼 주니어때는 코딩을 하다가 연차가 오르면 관리자로 가고 하지 않고, 요즘은 코딩을 오래 한 사람들의 경험을 그만큼 인정하고 대우하는 경우도 많아진 것 같습니다. 최근 분위기가 이렇다보니 은연중에 코딩에 손을 놓고, 따라가기가 벅찬 사람들은 좌절감을 느낄수도 있을것 같습니다.</p><p>Elastic에는 2018년 10월 현재 1,100 명 정도의 직원이 있는데 60% 정도가 엔지니어입니다. 엔지니어들 중에는 코드를 짜는 엔지니어들이 대다수이지만, 주 업무가 그렇지 않은 엔지니어들도 많습니다. 대표적으로</p><ul><li>기술지원(support) 엔지니어</li><li>커뮤니티 엔지니어</li><li>교육 엔지니어</li><li>컨설턴트</li><li>솔루션 아키텍트</li></ul><p>등이 있습니다. </p><p>제가 Elastic은 정말 멋진 회사라고 생각하는 이유 중 하나가, 업무의 경중을 가리지 않고 서로 존중하는 모습들 때문에 그렇습니다. 회사 리더들이 정한 정책같은 이유 때문이 아니라 순수하게 동료들끼리 서로의 직업을 존중해줍니다.</p><p>저는 Community Engineer 이지만 항상 처음 만나는 회사 동료들과 제 소개를 하면 다른 엔지니어들로부터 <strong><em>“정말 멋진 일을 하고 있군! 우리 회사가 성장하기 위해서 커뮤니티팀이 정말 중요하지”</em></strong> 라는 이야기를 자주 듣습니다. 제가 2015년에 입사하고 그 동안 한국에서 했던 <a href="/2014/03/start-es-community">커뮤니티 밋업</a>, 행사에 대한 일이나, 회사 <a href="/2017/11/2017-11-technical-translations">홈페이지 번역 리뷰</a> 한 일 등을 이야기 하면 <strong><em>“그건 종민이 너 아니면 누구도 너 만큼 해 낼 수 없는 일이었고, 네가 우리 동료라서 정말 행운이다.”</em></strong> 라는 이야기도 여러번 들었습니다.</p><p>저 뿐만이 아니라 기술지원 엔지니어 같은 경우도 비슷합니다. 한국에 현재 기술지원(support) 엔지니어도 3분이 계신데, 다들 유망한 회사에서 오신 실력있고 인정받는 개발자 분들이었습니다. 사실 개발을 주 업무로 하시던 분들에게 서포트 엔지니어로 합류를 권해드리는게 쉽게 내키는 일은 아니지만, Elastic의 서포트 엔지니어들은 충분히 그럴만한 가치가 있다고 생각합니다.</p><p>저희 회사의 첫 Support Engineer 이자, 현재 서포트 팀의 최고 헤드인 Marty 에게 예전에 들었던 이야기 입니다. Elastic에 직원이 스무명 남짓이던 시절, Elastic 에서 서포트팀을 맡아 줄 사람이 필요하다고 Elastic에 합류한 예전 직장동료가 Marty를 스카우트 하러 왔습니다. 합류하기로 결정하고 Elastic으로 가면서<br><strong><em>“서포트는 보통 개발자들이 자기가 하기 귀찮아하는 고객 상대 같은 일들을 대신 처리 해 주는 일이겠지”</em></strong><br>라는 생각으로 왔는데, 처음에 오자마자 개발자들이 모두 자기에게 몰려와서<br><strong><em>“정말 잘 왔다! 이런 중요한 직책을 맡아줘서 너무 고맙고, 앞으로 우리 회사의 성공은 너의 어깨에 달려있다. 잘 부탁한다.”</em></strong><br>이런 이야기들을 막 해주길래 이게 무슨 상황이지? 여긴 대체 뭐 하는 회사야? 라는 생각을 했다고 합니다.</p><p>올해 저희 서포트 엔지니어들 끼리 summit을 하느라 모두 출장중일 때 개발팀과 기타 다른 엔지니어들이 1주일 동안 자신들의 업무를 중지하고 서포트 엔지니어들의 일을 대신 한 적이 있었는데 슬랙의 서포트 채널에 계속 보이던 이야기가<br><strong><em>“서포트 엔지니어들은 이렇게 어려운 일들을 어떻게 매일 처리하고 있는지, 정말 존경스럽다.”</em></strong><br>라는 대화들을 자주 했습니다.</p><p>개발자가 아니라서 인정받기 힘들것 같은 걱정은 Elastic에 있는 동안은 하지 않아도 될 것 같습니다.</p><p>그리고 두 번째는</p><h3 id="2-뛰어난-개발자가-많다"><a href="#2-뛰어난-개발자가-많다" class="headerlink" title="2. 뛰어난 개발자가 많다"></a>2. 뛰어난 개발자가 많다</h3><p>입니다.</p><p>이상하게 들리실지 모르지만, 회사에 너무 뛰어난 개발자들이 많아서, 사실 제가 개발로 그분들을 따라잡을 수 있을것 같다는 생각이 들지 않습니다.<br>그래도 저 역시 나름 이전 직장에서는 개발 좀 한다는 이야기 들으면서 다니긴 했는데, Elastic에는 <strong>탑 레벨 아파치 커미터도 10명이나 있고</strong>, 한글 형태소 분석기가 필요해서 만들어달라고 했더니, 기존 형태소 분석기 소스만 적당히 보고 <strong><a href="https://www.elastic.co/kr/blog/nori-the-official-elasticsearch-plugin-for-korean-language-analysis" target="_blank" rel="noopener">2주만에 버그도 없고 10배나 가볍고 빠른 분석기를 만들어 오는 개발자</a></strong> 라던가, <strong><a href="https://www.elastic.co/kr/blog/timelion-timeline" target="_blank" rel="noopener">출장 비행기에서 혼자 데이터 분석 시각 툴을 만드는 개발자</a></strong> 같은 소위 굇수들이 있어서 사실 여기서 내가 궂이 열등감 느끼며 개발할 필요는 없겠다 라는 생각이 들었습니다. 저는 계속 제가 좋아하는 일 하면서 즐겁게 지내면 될 것 같습니다.</p><p>그래도 올해 파이콘에서 하이퍼커넥트 에서 주관한 <a href="https://hyperconnect.github.io/2018/08/18/gem-pick-start.html" target="_blank" rel="noopener">젬 줍기 배틀</a>에 참석해서 오랫만에 코드 한번 짜 봤는데, 순위가 중간 이상은 갔습니다. 감을 많이 잃긴 했지만 다시 하면 할 수는 있을것 같더군요. (사실 파이썬 코딩은 이 날 처음 해봤습니다.)</p><p>여하튼, 도전적인 포스트의 제목에 대한 제 결론은</p><blockquote><p>SW Engineer 로 부터 멀어질 것 같은 불안감이 스스로에게서 나왔지만, 좋은 동료들이 있어 극복 해 낼 수 있을것 같다.</p></blockquote><p>정도로 마무리 하겠습니다.</p><p>마지막 사진은 이번에 더블린에서 찍은 저희 엔지니어들의 모습입니다. 사람이 점점 많아져서 제작년에는 사진작가가 사다리를 놓고 찍고, 작년에는 건물 3층 창문에서 찍었는데, 올해는 드론을 날려서 찍었습니다.</p><p><img src="eah-dublin.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;저는 지금 Elastic 에서 Community Engineer 라는 직책을 맡고 있습니다. 주 업무는 개발자 커뮤니티를 지원하는 일이고요 (물론 저는 한국에 직원이 많이 없어서 이런 저런 다른 일들도 많이 합니다), 다른 회사에서는 Evange
      
    
    </summary>
    
      <category term="Engineering" scheme="http://kimjmin.net/categories/Engineering/"/>
    
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Engineering" scheme="http://kimjmin.net/tags/Engineering/"/>
    
      <category term="SW Engineer" scheme="http://kimjmin.net/tags/SW-Engineer/"/>
    
  </entry>
  
  <entry>
    <title>Elastic 모니터링 전용 클러스터</title>
    <link href="http://kimjmin.net/2018/09/2018-09-dedicated-es-monitoring/"/>
    <id>http://kimjmin.net/2018/09/2018-09-dedicated-es-monitoring/</id>
    <published>2018-09-09T15:00:00.000Z</published>
    <updated>2019-02-09T00:34:29.606Z</updated>
    
    <content type="html"><![CDATA[<p>Elastic Stack은 자체적인 클러스터 모니터링 기능을 가지고 있습니다. 기본적인 설정법은 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/configuring-monitoring.html" target="_blank" rel="noopener">공식 도큐먼트</a>에 자세히 나와 있습니다.</p><h3 id="모니터링-활성"><a href="#모니터링-활성" class="headerlink" title="모니터링 활성"></a>모니터링 활성</h3><p>6.2 이하 버전은 X-Pack 플러그인을 설치해야 하며, 6.3 버전 부터는 기본 다운로드 패키지에 포함이 되어 있습니다. 모니터링 기능은 Basic 라이센스 이기 때문에 유료 라이센스 없이 Kibana 의 모니터링 메뉴에 가서 <strong>Turn on monitoring</strong> 버튼을 클릭하기만 하면 모니터링 기능이 활성화 됩니다.</p><p><img src="monitoring.png" alt=""></p><p>Basic 라이센스는 1개의 클러스터만 모니터링 가능하며 보관 주기는 최대 1주일까지만 가능합니다. Gold 이상의 라이센스는 다중 클러스터 및 보관 주기도 자유롭게 설정 가능합니다.</p><p><img src="monitoring-subscription.png" alt=""></p><h3 id="Logstash-Beats-모니터링-설정"><a href="#Logstash-Beats-모니터링-설정" class="headerlink" title="Logstash, Beats 모니터링 설정"></a>Logstash, Beats 모니터링 설정</h3><p>위와 같이 Kibana에서 모니터링을 활성화 하면 기본적으로 Elasticsearch, Kibana는 자동으로 설정이 끝납니다. 이전 버전에서 롤링 업그레이드를 했거나 해서 설정이 잘 되지 않은 경우는 <code>elasticsearch.yml</code> 파일에 아래 내용을 추가하고 노드를 재시작하면 모니터링이 실행됩니다.</p><ul><li><strong>elasticsearch.yml</strong><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">xpack.monitoring.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="string">xpack.monitoring.collection.enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></li></ul><p>Beats와 Logstash의 경우는 <code>logstash.yml</code>, <code>~beat.yml</code> 파일에서 아래와 같이 설정을 해 주어야 합니다.</p><ul><li><p><strong>logstash.yml</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">xpack.monitoring.elasticsearch.url:</span> <span class="string">["&lt;es_host&gt;:9200"]</span></span><br><span class="line"><span class="string">xpack.monitoring.elasticsearch.username:</span> <span class="string">"logstash_system"</span></span><br><span class="line"><span class="string">xpack.monitoring.elasticsearch.password:</span> <span class="string">"&lt;logstash_system password&gt;"</span></span><br></pre></td></tr></table></figure></li><li><p><strong>~beat.yml</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">output.elasticsearch:</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">["&lt;es_host&gt;:9200"]</span></span><br><span class="line"><span class="attr">  username:</span> <span class="string">"&lt;user&gt;"</span></span><br><span class="line"><span class="attr">  password:</span> <span class="string">"&lt;password&gt;"</span></span><br><span class="line"></span><br><span class="line"><span class="string">xpack.monitoring.enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></li></ul><p>위와 같이 설정한 뒤 재시작하고 나면 모든 스택의 제품들이 모니터링 화면에 나타납니다.<br><img src="monitoring-all-stack.png" alt=""></p><p>참고로 모니터링 데이터의 기본 보관 기간은 1주일 입니다. 이 설정은 <code>elasticsearch.yml</code>의 다음 설정으로 변경이 가능합니다.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">xpack.monitoring.history.duration:</span> <span class="string">"30d"</span></span><br></pre></td></tr></table></figure></p><h3 id="모니터링-전용-클러스터-분리"><a href="#모니터링-전용-클러스터-분리" class="headerlink" title="모니터링 전용 클러스터 분리"></a>모니터링 전용 클러스터 분리</h3><p>기본적으로 모니터링 데이터는 <code>.monitoring-es-6-2018.09.08</code> 형식의 인덱스로 모니터링중인 해당 클러스터에 저장됩니다. 하지만 저장 주기가 길어지면 모니터링 데이터의 양도 많아지고, 운영 클러스터가 다운되었을 때 모니터링 데이터도 함께 유실될 수 있습니다. Elastic Stack은 모니터링 데이터를 운영 클러스터가 아닌 별도의 클러스터에 저장하도록 설정이 가능합니다.</p><p>설정은 운영 클러스터의 <code>elasticsearch.yml</code> 파일만 해 주면 kibana, logstash, beats들의 모니터링 정보도 함께 원격 클러스터에 저장됩니다. <code>elasticsearch.yml</code> 파일에 아래 내용을 추가합니다.</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">xpack.monitoring.exporters:</span></span><br><span class="line"><span class="attr">  remote-cluster:</span></span><br><span class="line"><span class="attr">    type:</span> <span class="string">http</span></span><br><span class="line"><span class="attr">    host:</span> <span class="string">["&lt;monitoring_cluster_host&gt;:9200"]</span></span><br><span class="line"><span class="attr">    auth:</span></span><br><span class="line"><span class="attr">      username:</span> <span class="string">"&lt;user&gt;"</span></span><br><span class="line"><span class="attr">      password:</span> <span class="string">"&lt;password&gt;"</span></span><br></pre></td></tr></table></figure><p><code>remote-cluster</code> 부분에는 내가 설정하는 임의의 구분자명를 입력하면 됩니다.</p><p>만약에 운영 클러스터와 원격 모니터링 클러스터에 모니터링 데이터를 모두 저장하고 싶으면 아래와 같이 <code>type: local</code> 값을 설정하면 됩니다.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">xpack.monitoring.exporters:</span></span><br><span class="line"><span class="attr">  local:</span></span><br><span class="line"><span class="attr">    type:</span> <span class="string">local</span></span><br><span class="line"><span class="attr">  remote-cluster:</span></span><br><span class="line"><span class="attr">    type:</span> <span class="string">http</span></span><br><span class="line"><span class="attr">    host:</span> <span class="string">["&lt;monitoring_cluster_host&gt;:9200"]</span></span><br><span class="line"><span class="attr">    auth:</span></span><br><span class="line"><span class="attr">      username:</span> <span class="string">"&lt;user&gt;"</span></span><br><span class="line"><span class="attr">      password:</span> <span class="string">"&lt;password&gt;"</span></span><br></pre></td></tr></table></figure></p><h3 id="Elastic-Cloud로-모니터링-전용-클러스터-사용"><a href="#Elastic-Cloud로-모니터링-전용-클러스터-사용" class="headerlink" title="Elastic Cloud로 모니터링 전용 클러스터 사용"></a>Elastic Cloud로 모니터링 전용 클러스터 사용</h3><p>Elastic 사에서는 SaaS 형태의 Elastic Cluster 클라우드 서비스를 운영하고 있습니다. 클라우드 서비스는 <a href="https://cloud.elastic.co" target="_blank" rel="noopener">https://cloud.elastic.co</a> 에 접속해서 사용 가능합니다. 처음 계정을 만들면 14일간 무료로 사용이 가능하며 X-Pack Gold, Platinum 기능들의 사용이 가능합니다. 관리 화면에서 간편하게 버튼을 클릭해서 elasticsearch 노드들과 kibana의 실행이 가능합니다.</p><p><img src="es-cloud-login.png" alt=""> <img src="es-cloud-1.png" alt=""> <img src="es-cloud-2.png" alt=""> <img src="es-cloud-3.png" alt=""> <img src="es-cloud-4.png" alt=""></p><p>Elastict 사에서는 기존의 Gold / Platinum 기술지원 구독을 구매한 고객에게 <strong>무료로 Elastic Cloud에 모니터링 전용 클러스터를 제공</strong>하고 있습니다. 관련된 내용은 <a href="https://www.elastic.co/blog/introducing-the-elastic-stack-monitoring-service" target="_blank" rel="noopener">https://www.elastic.co/blog/introducing-the-elastic-stack-monitoring-service</a> 에서 확인이 가능합니다. 모니터링 클러스터를 사용하면 모니터링 데이터 저장 공간을 아낄 수 있고 문제가 생겼을 경우 Elastic의 기술지원 엔지니어들이 모니터링 클러스터에서 직접 문제의 확인이 가능하기 때문에 더욱 효과적인 기술지원이 가능한 장점이 있습니다.</p><p>클러스터를 만들고 나면 Elastic Cloud의 관리 화면에서 elasticsearch 및 kibana의 엔드포인트 주소를 확인할 수 있습니다.</p><p><img src="es-cloud-5.png" alt=""></p><p>kibana 엔드포인트 주소로 접속하면 모니터링 클러스터의 kibana에 접속해서 사용이 가능합니다. 위의 <code>&lt;monitoring_cluster_host&gt;</code>에 elasticsearch 엔드포인트 주소를 입력하면 Elastic Cloud를 모니터링 클러스터로 사용이 가능합니다.</p><p>Gold 이상의 라이센스를 적용중이라면 Elasticsearch 노드들에 TLS 설정이 되어 있을것입니다. 이런 클러스터의 경우 <strong>Elastic Cloud의 클러스터에 접속하려면 SSL 인증키가 필요합니다.</strong> 이 인증키는 support 고객지원 시스템에서</p><blockquote><p>How To Configure Your Elasticsearch 5.x/6.x Cluster to Use The Elastic Stack Monitoring Service</p></blockquote><p>라는 제목으로 검색하면 나오는 아티클 페이지에서 다운로드가 가능합니다. 운영 클러스터의 <code>elasticsearch.yml</code> 파일에 아래와 같이 <code>ssl.certificate_authorities</code> 설정으로 인증키 파일을 추가합니다.</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">xpack.monitoring.exporters:</span></span><br><span class="line"><span class="attr">  remote-cluster:</span></span><br><span class="line"><span class="attr">    type:</span> <span class="string">http</span></span><br><span class="line"><span class="attr">    host:</span> <span class="string">["https://&lt;elastic_cluster_elasticsearch_endpoint&gt;:&lt;port&gt;"]</span></span><br><span class="line"><span class="attr">    auth:</span></span><br><span class="line"><span class="attr">      username:</span> <span class="string">"&lt;monitoring_user&gt;"</span></span><br><span class="line"><span class="attr">      password:</span> <span class="string">"&lt;password&gt;"</span></span><br><span class="line"><span class="attr">    ssl:</span></span><br><span class="line"><span class="attr">      certificate_authorities:</span> <span class="string">["/&lt;file_path&gt;/&lt;elastic_cloud_cert&gt;.pem"]</span></span><br></pre></td></tr></table></figure><p>위의  <code>&lt;monitoring_user&gt;</code>는 모니터링 클러스터에 만들어진 모니터링 데이터를 입력받는 user 입니다. 이 사용자는 <code>remote_monitoring_agent</code> role 을 가지고 있으면 됩니다. 아래는 모니터링 데이터를 입력받기 위한 monitoring 이라는 사용자 계정을 만든 예 입니다.<br><img src="monitoring-user.png" alt=""></p><p>이제 Elastic Cloud 전용 모니터링 클러스터의 Kibana 화면에서 monitoring 메뉴를 확인하면 여러개의 클러스터 정보가 수집되고 있는 것을 확인할 수 있습니다.</p><p><img src="monitoring-multiple-cluster.png" alt=""></p><p>운영 클러스터의 Kibana, Logstash, Beats의 모니터링은 별도로 설정하지 않아도 알아서 모니터링 클러스터로 수집이 됩니다.</p><p><img src="es-cloud-all-stack.png" alt=""></p><p>저는 모니터링 클러스터를 Elastic Cloud 도쿄 리전에 설치하고 <a href="/2018/01/2018-01-build-es-cluster-8">예전에 구성한 클러스터</a>의 모니터링 데이터를 수집하도록 했습니다. 전체 구성도는 아래와 같습니다.</p><p><img src="monitoring-architect.png" alt=""></p><p>아직까지 Elasticsearch의 모니터링 기능을 사용하지 않고 계시다면 사용 해 보기를 적극 추천 해 드립니다. 클러스터 상태와 문제가 되는 여러 근본 원인들의 포인팅이 가능합니다. 🤓</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Elastic Stack은 자체적인 클러스터 모니터링 기능을 가지고 있습니다. 기본적인 설정법은 &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/configurin
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Elastic Cluster Settings" scheme="http://kimjmin.net/tags/Elastic-Cluster-Settings/"/>
    
      <category term="Monitoring" scheme="http://kimjmin.net/tags/Monitoring/"/>
    
      <category term="Elastic Cloud" scheme="http://kimjmin.net/tags/Elastic-Cloud/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Stack 업그레이드 시 주의할점</title>
    <link href="http://kimjmin.net/2018/09/2018-09-migration-caution/"/>
    <id>http://kimjmin.net/2018/09/2018-09-migration-caution/</id>
    <published>2018-08-31T15:00:00.000Z</published>
    <updated>2018-09-01T06:13:07.683Z</updated>
    
    <content type="html"><![CDATA[<p>지난번에 <a href="/2018/01/2018-01-build-es-cluster-8">Elastic Cluster 구성</a> 시리즈에서 구성 해 놓았던 클러스터를 6.4 버전으로 업그레이드를 하는 웨비나를 진행했습니다. 웨비나라기 보다는 개인 작업하는 모습을 공개적으로 방송을 하면서 진행을 했습니다.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/P6ezu7FJthg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><p>먼저 결론부터 말씀드리자면 중간에 버벅이면서 마이그레이션은 실패로 끝났습니다. 당시는 원인이 뭔지 몰라서 끝냈는데, 나중에 차근 차근 생각 해 보면서 원인을 찾았습니다.</p><p>우선 기존 클러스터는 6.2.3 버전으로 되어 있었고 아래 플러그인들이 elasticsearch에 설치되어 있었습니다.</p><ul><li>seunjeon</li><li>openkoreantext</li></ul><p>그리고 6.4 에서 한글 형태소 분석기인 nori 가 출시되었기 때문에 이제 다른 형태소 분석기는 설치하지 않고 nori만 설치 할 계획이었습니다.</p><p>일단 화려하게 6.2.3 –&gt; 6.4.0 으로 데이터 유실 없이 롤링 업그레이드를 하려고 했습니다.<br>기존의 6.2.3 데이터 노드를 하나씩 종료시키고 6.4.0 노드를 바인딩 하면서 샤드들을 재배치(를 기대)했습니다.</p><p><img src="monitoring-1.png" alt=""></p><p>그런데 몇개의 인덱스는 계속 기다려도 새로운 노드로 샤드들이 올라오지 않습니다.</p><p><img src="monitoring-2.png" alt=""> </p><p>kr-demo-data-1 노드를 새로 바인딩 시켰는데도 해당 노드에는 assign 이 안됩니다.</p><p><img src="monitoring-3.png" alt=""></p><p>결국 그때는 원인을 알지 못하고 풀 클러스터 재시작을 했는데 결국 그 인덱스의 샤드들은 살려내지 못했습니다.</p><p><img src="monitoring-4.png" alt=""></p><p>오늘에서야 원인을 깨달았는데, 샤드 재배치가 안 된 인덱스들은 모두 <strong>seunjeon 분석기를 적용 해 놓은 것들이었습니다.</strong> 6.4.0 에 seunjeon이 설치되어있지 않다 보니 데이터를 불러오는데 오류가 생겼던 것이었습니다. 6.3.0 부터는 플러그인 개발 구조도 바뀌어서 6.4.0에 seunjeon을 설치 할 수도 없었습니다.<br>매핑에 설정된 플러그인을 사용 못 하니 <strong>snapshot 떠 놓은 데이터를 restore 하는것도 안 되었습니다.</strong> 결국 저 데이터는 저장 해 놓은 소스를 다시 긁어다가 다시 색인을 할 수 밖에 없었습니다.</p><p>이 경우 해결방법은 다음과 같습니다.</p><ol><li>seunjeon 등의 커스텀 분석기등을 사용하는 인덱스는 모두 필드들을 기본 색인으로 바꾸고 임시(temp) 인덱스에 재색인 합니다. 또는 아예 index:false 로 해서 _source 만 저장하는것도 좋은 방법입니다. 어차피 도로 재색인 해 와야 하니까요.</li><li>기존 인덱스를 삭제합니다.</li><li>elasticsearch 노드를 새로운 버전으로 업그레이드 합니다.</li><li>새 버전에 맞는 형태로 인덱스 매핑을 다시 만듭니다.</li><li>임시 인덱스의 데이터를 새 인덱스로 다시 색인합니다.</li></ol><p>이 작업 과정은 다시 아래 영상에 있으니 한번 확인 하시고, 모두 오류 없는 업그레이드 하시기 바랍니다.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/1NPnSJ5i0-M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><p>가능하면 커스텀 플러그인들은 매 버전 직접 만들 자신이 없으면 사용을 자제하고 Elastic 에서 공식적으로 배포한 플러그인들을 사용하는것이 여러가지로 안전하고 좋을것 같습니다. 특히 6.4 부터 한글 형태소 분석기 nori도 나왔으니 이제 그동안 고질적인 요구사항이었던 한글 검색 부분도 원할하게 할 수 있게 되었습니다.</p><p>nori 플러그인에 대해서는 다음 블로그를 참고하세요.<br><a href="https://www.elastic.co/kr/blog/nori-the-official-elasticsearch-plugin-for-korean-language-analysis" target="_blank" rel="noopener">공식 한국어 분석 플러그인 “노리”</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;지난번에 &lt;a href=&quot;/2018/01/2018-01-build-es-cluster-8&quot;&gt;Elastic Cluster 구성&lt;/a&gt; 시리즈에서 구성 해 놓았던 클러스터를 6.4 버전으로 업그레이드를 하는 웨비나를 진행했습니다. 웨비나라기 보다는 
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Elastic Cluster Settings" scheme="http://kimjmin.net/tags/Elastic-Cluster-Settings/"/>
    
  </entry>
  
  <entry>
    <title>Elastic 6.3 에서 상용 라이센스 활성</title>
    <link href="http://kimjmin.net/2018/08/2018-08-install-security-over-es63/"/>
    <id>http://kimjmin.net/2018/08/2018-08-install-security-over-es63/</id>
    <published>2018-08-10T15:00:00.000Z</published>
    <updated>2018-08-11T06:56:22.080Z</updated>
    
    <content type="html"><![CDATA[<p>Elastic Satck 6.3 부터는 기존의 X-Pack 상용 기능이 별도 설치가 아닌 기본 내장으로 변경되었습니다. 이에 따른 새로운 설정법에 대해 설명합니다. Elastic Cluster 생성과 기본 설정에 대한 부분은 이전의 Elastic Cluster 구성 시리즈를 참고하세요.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote><p>Elastic Stack 6.3 버전부터 큰 변화가 있었습니다. 기존에 별도 플러그인으로 제공하던 기능들을 기본 배포 패키지에 포함시키게 되었습니다. 이에 대한 내용은 Elastic 공식 페이지의 아래 블로그 포스트를 참고하세요.</p><p><a href="https://www.elastic.co/kr/blog/doubling-down-on-open" target="_blank" rel="noopener">https://www.elastic.co/kr/blog/doubling-down-on-open</a></p><p>6.3 버전부터는 x-pack 플러그인 설치팩을 제공하지 않습니다. 2018년 8월 부터는 X-Pack 이라는 브랜드도 버리고 Elastic 확장 기능 (Elastic Feature) 라고만 명명하고 있습니다. 6.2 이전 버전에서는 <code>bin/elasticsearch-plugin install x-pack</code> 명령으로 계속 설치가 가능합니다. 6.3 버전 부터는 <a href="https://www.elastic.co/kr/downloads" target="_blank" rel="noopener">다운로드 페이지</a> 에서 아래와 같이 확장 기능이 포함된 배포판을 내려받을 수 있습니다.</p><p><img src="download.png" alt=""></p><p>라이센스 정책이 Elastic License로 바뀐 것을 볼 수 있습니다. 예전처럼 Apache 2.0 라이센스 버전을 내려받으려면 <a href="https://www.elastic.co/downloads/elasticsearch-oss" target="_blank" rel="noopener">https://www.elastic.co/downloads/elasticsearch-oss</a> 처럼 각 제품의 -oss 페이지에서 내려받을 수 있습니다.</p><p><img src="download-oss.png" alt=""></p><h3 id="cluster-구성"><a href="#cluster-구성" class="headerlink" title="cluster 구성"></a>cluster 구성</h3><p>3개의 서버에서 마스터, 데이터 노드등의 설정은 따로 구분하지 않고 3개의 노드로 클러스터를 구성 해 보겠습니다. 구성할 클러스터 정보와 각 서버들의 IP 주소는 아래와 같습니다. 그리고 각 서버에서 elasticsearch 노드들은 <code>elastic</code> 리눅스 계정으로 실행하겠습니다.</p><ul><li>클러스터명 : <strong>es-cluster</strong></li><li>노드명: <strong>es-node1, es-node2, es-node3</strong></li><li>각 서버 IP 주소 : <strong>179.34.27.193, 179.34.16.96, 179.34.22.211</strong></li></ul><p>디스커버리 정보를 IP 주소로 적어도 되지만 좀 더 편하게 하기 위해 <code>/ect/hosts</code> 파일에 아래 정보를 추가하겠습니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">179.34.27.193   es-node1</span><br><span class="line">179.34.16.96    es-node2</span><br><span class="line">179.34.22.211   es-node3</span><br></pre></td></tr></table></figure></p><p>이제 각 서버별로 <code>elasticsearch.yml</code> 파일에 아래 설정들을 추가합니다.<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">cluster.name:</span> <span class="string">es-cluster</span></span><br><span class="line"><span class="string">node.name:</span> <span class="string">$&#123;HOSTNAME&#125;</span></span><br><span class="line"><span class="string">network.host:</span> <span class="string">_site_</span></span><br><span class="line"><span class="string">bootstrap.memory_lock:</span> <span class="literal">true</span></span><br><span class="line"><span class="string">discovery.zen.ping.unicast.hosts:</span> <span class="string">["es-node1","es-node2","es-node3"]</span></span><br></pre></td></tr></table></figure></p><p><code>network.host</code> 설정을 실제 IP 주소로 주면 (<code>_site_</code>로 하면 자동으로 잡습니다) 부트스트랩 체크를 해서 바로 실행이 되지 않을 수 있습니다. 보통은<br><code>/etc/security/limits.conf</code><br>파일에<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">elastic soft memlock unlimited</span><br><span class="line">elastic hard memlock unlimited</span><br><span class="line">elastic - nofile  65536</span><br></pre></td></tr></table></figure></p><p>내용을 추가 해 주면 실행 됩니다. elastic 은 실행 할 리눅스 계정입니다. 정확한 것은 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html" target="_blank" rel="noopener">Bootstrap Checks</a> 문서를 참고하세요.</p><p>이제 es-node1 과 같은 서버에서 kibana를 실행하겠습니다. <code>kibana.yml</code> 파일에 다음 설정을 추가합니다.<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">server.host:</span> <span class="string">"es-node1"</span></span><br><span class="line"><span class="string">elasticsearch.url:</span> <span class="string">"http://es-node1:9200"</span></span><br></pre></td></tr></table></figure></p><p>이제 kibana 를 실행시켜 보겠습니다. 6.3 버전 부터는 이전 버전과 달리 Basic 기능(APM, 모니터링 등) 들이 이미 설치 된 채로 구동되는 것을 확인할 수 있습니다.</p><p><img src="kibana-init.png" alt=""></p><h3 id="모니터링-설정"><a href="#모니터링-설정" class="headerlink" title="모니터링 설정"></a>모니터링 설정</h3><p>모니터링 기능은 Basic 라이센스 이기 때문에 미리 설치는 되어 있으나, 모니터링 데이터를 수집하고 있지는 않습니다. Kibana 의 모니터링 메뉴에 가서 Turn on monitoring 버튼을 클릭하기만 하면 모니터링 기능이 활성화 됩니다.</p><p><img src="monitoring.png" alt=""></p><p>모니터링 기능을 활성화하고 나면 아래와 같이 모니터링 정보가 나타납니다.</p><p><img src="monitoring-enabled.png" alt=""></p><h3 id="Gold-Platinum-기능-활성"><a href="#Gold-Platinum-기능-활성" class="headerlink" title="Gold / Platinum 기능 활성"></a>Gold / Platinum 기능 활성</h3><p>Security, Graph, Machine Learning 등의 기능은 Gold, Platinum 등에서 사용 가능한 유료 기능입니다. 이 기능을 활성화 하려면 Kibana의<br>Management &gt; License Management 메뉴에 가서 </p><ol><li><code>Start a 30-day trial</code> 을 선택하고 30일 간 Platimun 기능을 무료로 사용 하던가</li><li><code>Update your license</code> 를 선택하고 구매한 Gold / Platinum 라이센스를 업로드 해서 활성화 할 수 있습니다.</li></ol><p><img src="license.png" alt=""> <img src="license-upload.png" alt=""></p><p>하지만 라이센스를 업로드 하려고 하면 아래와 같이 Security 설정에서 TLS를 적용해야 한다고 나옵니다.</p><p><img src="license-upload-no.png" alt=""></p><p>우선은 30일 트라이얼로 전환한 뒤 Security 와 TLS를 활성화 하고 다시 라이센스를 적용해야 할 것 같습니다. <code>Start a 30-day trial</code> 을 선택하여 트라이얼을 활성화 시킵니다.</p><p><img src="trial.png" alt=""></p><p>Kibana 화면을 새로고침 해 보면 Graph, Machine Learning 등의 플래티넘 기능들이 활성화 된 것을 확인할 수 있습니다.</p><p><img src="trial-enabled.png" alt=""></p><h3 id="Security-설정"><a href="#Security-설정" class="headerlink" title="Security 설정"></a>Security 설정</h3><p>하지만 Security 기능은 처음부터 활성화 되어 있지 않습니다. 6.2 버전 까지는 x-pack 을 확장팩으로 설치하게 되면 기본적으로 모든 x-pack 기능들의 설정이 enabled 되어 실행이 되었습니다. 하지만 Security의 경우는 6.3 부터는 disabled 가 디폴트로 되어 6.2 이전 버전에서 6.3 이후 버전으로 업그레이드 하는 경우 좀 복잡할 수 있습니다.<br>Security 기능을 활성하려면 elasticsearch.yml 파일에 설정을 추가 해 줘야 합니다. 이 설정이 다르면 노드들이 바인딩 되지 않기 때문에 노드별로 할 수가 없어서 어쩔 수 없이 full cluster restart 를 해야 합니다.</p><p>elasticsearch.yml 파일에 아래 설정을 추가한 뒤 모든 노드를 재시작합니다.<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">xpack.security.enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p><p>위 설정은 6.3 기준입니다. x-pack 이라는 브랜딩을 앞으로 사용하지 않기 때문에 <span style="color:red"><strong>6.x 이후 어느 시점에서는 위 설정 방법도 바뀔 수 있습니다.</strong></span></p><p>Security를 활성화 한 뒤에는 자동으로 생성되는 기본 계정들의 패스워드를 설정 해 줘야 합니다. 노드가 실행되고 있는 상태에서 새로 콘솔을 열고 elasticsearch 홈 디렉토리 아래 bin 디렉토리 아래에 있는 elasticsearch-setup-passwords 명령을 실행하면 기본 계정들의 패스워드를 설정할 수 있습니다. 실행 가능한 옵션은 아래 두가지가 있습니다.</p><ul><li><strong>auto</strong> : 임의의 패스워드를 설정합니다. 패스워드들은 이 명령 실행 후 콘솔에 딱 한번 나타나기 때문에 다른곳에 잘 적어 보관해야 합니다.</li><li><strong>interactive</strong> : 각 계정별로 패스워드를 직접 설정합니다.</li></ul><p>저희는 interactive 로 해 보겠습니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[]$ bin/elasticsearch-setup-passwords interactive</span><br><span class="line">Initiating the setup of passwords for reserved users elastic,kibana,logstash_system,beats_system.</span><br><span class="line">You will be prompted to enter passwords as the process progresses.</span><br><span class="line">Please confirm that you would like to continue [y/N]y</span><br><span class="line"></span><br><span class="line">Enter password for [elastic]:</span><br><span class="line">Reenter password for [elastic]:</span><br><span class="line">Enter password for [kibana]:</span><br><span class="line">Reenter password for [kibana]:</span><br><span class="line">Enter password for [logstash_system]:</span><br><span class="line">Reenter password for [logstash_system]:</span><br><span class="line">Enter password for [beats_system]:</span><br><span class="line">Reenter password for [beats_system]:</span><br><span class="line">Changed password for user [kibana]</span><br><span class="line">Changed password for user [logstash_system]</span><br><span class="line">Changed password for user [beats_system]</span><br><span class="line">Changed password for user [elastic]</span><br><span class="line">[]$</span><br></pre></td></tr></table></figure></p><p>위 명령에는 보이지 않았지만 <code>elastic</code>,<code>kibana</code>,<code>logstash_system</code>,<code>beats_system</code> 각 계정에 대해 설정할 패스워드를 2번씩 쳐 넣습니다. 저는 모든 계정의 패스워드를 <code>changeme</code> 로 했습니다. 패스워드를 넣지 않고 curl 명령을 한번 날려보고, 다시 -u elastic:changeme 를 추가하고 날려봐서 제대로 설정이 되었는지 확인합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[]$ curl es-node1:9200</span><br><span class="line">&#123;&quot;error&quot;:&#123;&quot;root_cause&quot;:[&#123;&quot;type&quot;:&quot;security_exception&quot;,&quot;reason&quot;:&quot;missing authentication token for REST request [/]&quot;,&quot;header&quot;:&#123;&quot;WWW-Authenticate&quot;:&quot;Basic realm=\&quot;security\&quot; charset=\&quot;UTF-8\&quot;&quot;&#125;&#125;],&quot;type&quot;:&quot;security_exception&quot;,&quot;reason&quot;:&quot;missing authentication token for REST request [/]&quot;,&quot;header&quot;:&#123;&quot;WWW-Authenticate&quot;:&quot;Basic realm=\&quot;security\&quot; charset=\&quot;UTF-8\&quot;&quot;&#125;&#125;,&quot;status&quot;:401&#125;</span><br><span class="line"></span><br><span class="line">[]$ curl es-node1:9200 -u elastic:changeme</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot; : &quot;kr-demo-service&quot;,</span><br><span class="line">  &quot;cluster_name&quot; : &quot;es-cluster&quot;,</span><br><span class="line">  &quot;cluster_uuid&quot; : &quot;ZJ1eRGTRSzeiUzT0MTY--Q&quot;,</span><br><span class="line">  &quot;version&quot; : &#123;</span><br><span class="line">    &quot;number&quot; : &quot;6.3.2&quot;,</span><br><span class="line">    &quot;build_flavor&quot; : &quot;default&quot;,</span><br><span class="line">    &quot;build_type&quot; : &quot;tar&quot;,</span><br><span class="line">    &quot;build_hash&quot; : &quot;053779d&quot;,</span><br><span class="line">    &quot;build_date&quot; : &quot;2018-07-20T05:20:23.451332Z&quot;,</span><br><span class="line">    &quot;build_snapshot&quot; : false,</span><br><span class="line">    &quot;lucene_version&quot; : &quot;7.3.1&quot;,</span><br><span class="line">    &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,</span><br><span class="line">    &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;tagline&quot; : &quot;You Know, for Search&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>이제 kibana 에도 아래 설정을 추가하고 kibana를 실행해서 로그인 화면이 나타나는지 확인합니다.<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">xpack.security.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="string">elasticsearch.username:</span> <span class="string">"kibana"</span></span><br><span class="line"><span class="string">elasticsearch.password:</span> <span class="string">"changeme"</span></span><br></pre></td></tr></table></figure></p><p><img src="kibana-login.png" alt=""></p><p>슈퍼유저 계정인 elastic / changeme 를 넣고 로그인 합니다. Management 메뉴에 가 보면 Security 메뉴도 생성된 것을 볼 수 있습니다.</p><p><img src="security-menu.png" alt=""></p><p>아직까지는 라이센스를 업로드 하려고 하면 여전히 TLS 설정이 안 되었기 때문에 업로드가 불가능합니다. 예전에 <a href="/2018/01/2018-01-build-es-cluster-6">X-Pack Security를 이용한 SSL 및 TLS 설정</a> 포스트에서 한번 설명은 했는데 6.3에서 인증파일 생성 프로그램 경로가 바뀌어서 다시 한번 설명 하고 넘어가겠습니다.</p><p>이미 회사 서버에 사용중인 인증키가 있다면 그대로 사용이 가능합니다. 아직 없다면 인증키를 만들 수 있는 프로그램이 elasticsearch/bin 디렉토리 아래에 있습니다. <code>bin/elasticsearch-certgen</code> 파일입니다. elasticsearch 설치 디렉토리에서 이 프로그램을 실행합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[]$ bin/elasticsearch-certgen</span><br><span class="line">...</span><br><span class="line">Let&apos;s get started...</span><br><span class="line"></span><br><span class="line">Please enter the desired output file [certificate-bundle.zip]:</span><br><span class="line">Enter instance name: es-cluster</span><br><span class="line">Enter name for directories and files [es-cluster]:</span><br><span class="line">Enter IP Addresses for instance (comma-separated if more than one) []: 179.34.27.193,179.34.16.96,179.34.22.211</span><br><span class="line">Enter DNS names for instance (comma-separated if more than one) []: es-node1,es-node2,es-node3</span><br><span class="line">Would you like to specify another instance? Press &apos;y&apos; to continue entering instance information: n</span><br><span class="line">Certificates written to /home/elastic/elasticsearch-6.3.2/certificate-bundle.zip</span><br></pre></td></tr></table></figure></p><ul><li>먼저 저장할 파일 이름을 물어보는데 (enter the desired output file) 그냥 엔터를 치면 <code>certificate-bundle.zip</code> 으로 저장됩니다.</li><li>다음으로 인스턴스명을 물어봅니다. 저는 <code>es-cluster</code>라고 했습니다.</li><li>다음으로 디렉토리를 물어보는데 그냥 엔터를 치면 인스턴스명과 동일하게 하고 넘어갑니다.</li><li>다음은 노드들이 있는 서버의 IP 주소들을 쉼표(,)로 구분해서 적어줍니다. <code>179.34.27.193</code>,<code>179.34.16.96</code>,<code>179.34.22.211</code> 3개를 적었습니다.</li><li>다음은 마찬가지로 노드들이 있는 서버의 호스트명을 쉼표(,)로 구분해서 적어줍니다. <code>es-node1</code>,<code>es-node2</code>,<code>es-node3</code> 를 적었습니다.</li><li>인증키를 추가로 안 만들꺼면 n 을 눌러 종료합니다.</li></ul><p>종료하고 나면 bin/elasticsearch-certgen 명령을 실행한 디렉토리에 certificate-bundle.zip 있을겁니다. 저는 이것을 elastic 계정 홈 디렉토리 아래에 cert 라는 디렉토리를 만들고 그 아래에 압축을 풀었습니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[~]$ cd</span><br><span class="line">[~]$ mkdir cert</span><br><span class="line">[~]$ cd cert/</span><br><span class="line">[cert]$ mv ../elasticsearch-6.3.2/certificate-bundle.zip ./</span><br><span class="line">[cert]$ unzip certificate-bundle.zip</span><br><span class="line">Archive:  certificate-bundle.zip</span><br><span class="line">   creating: ca/</span><br><span class="line">  inflating: ca/ca.crt</span><br><span class="line">  inflating: ca/ca.key</span><br><span class="line">   creating: es-cluster/</span><br><span class="line">  inflating: es-cluster/es-cluster.crt</span><br><span class="line">  inflating: es-cluster/es-cluster.key</span><br></pre></td></tr></table></figure></p><p>cert 디렉토리 아래에 <code>ca</code>, <code>es-cluster</code> 디렉토리가 생기고 그 아래 <em>.crt, </em>.key 파일들이 생성됩니다.</p><p>이제 elasticsearch.yml 에 아래 설정을 추가하고 노드들을 재시작합니다.</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">xpack.ssl.key:</span> <span class="string">/home/elastic/cert/es-cluster/es-cluster.key</span></span><br><span class="line"><span class="string">xpack.ssl.certificate:</span> <span class="string">/home/elastic/cert/es-cluster/es-cluster.crt</span></span><br><span class="line"><span class="string">xpack.ssl.certificate_authorities:</span> <span class="string">[</span> <span class="string">"/home/elastic/cert/ca/ca.crt"</span> <span class="string">]</span></span><br><span class="line"><span class="string">xpack.security.transport.ssl.enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>당연히 위 파일들은 모든 서버들의 동일한 경로에 복사되어 있어야 합니다. 가능하면 이런 파일들은 NFS 같은 네트워크 디렉토리를 사용하는 것이 좋습니다. 노드를 재시작 하면 이제 TLS가 활성화 되어 노드들끼리 9300번 포트에서 하는 TCP 통신은 모두 암호화되어 전송됩니다.</p><p>이제 Management &gt; License Management 메뉴에 가서 가지고 있는 라이센스 키를 업로드 하면 정상적으로 사용 기간이 라이센스 기간 만큼 늘어나게 됩니다.</p><p><img src="platinum-enabled.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Elastic Satck 6.3 부터는 기존의 X-Pack 상용 기능이 별도 설치가 아닌 기본 내장으로 변경되었습니다. 이에 따른 새로운 설정법에 대해 설명합니다. Elastic Cluster 생성과 기본 설정에 대한 부분은 이전의 Elastic
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Elastic Cluster Settings" scheme="http://kimjmin.net/tags/Elastic-Cluster-Settings/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Certified Engineer 자격 시험</title>
    <link href="http://kimjmin.net/2018/07/2018-07-elastic-certified-engineer/"/>
    <id>http://kimjmin.net/2018/07/2018-07-elastic-certified-engineer/</id>
    <published>2018-07-11T15:00:00.000Z</published>
    <updated>2018-07-21T03:38:50.519Z</updated>
    
    <content type="html"><![CDATA[<p>2018년 7월 Elastic에서 첫번째 공식 자격증을 내 놓았습니다.<br>신청은 아래 링크에 가서 하면 됩니다.<br><a href="https://training.elastic.co/exam/elastic-certified-engineer" target="_blank" rel="noopener">https://training.elastic.co/exam/elastic-certified-engineer</a></p><p><img src="cert-register.png" alt=""></p><p>응시 가격은 400 달러 입니다.<br>저도 시험이 어떻게 생겼는지 문의가 밀려올 것이 뻔해서 우선 봐봤습니다.<br>결과부터 말씀 드리면, <strong>합격했습니다.</strong> 🤓</p><h3 id="출제-범위"><a href="#출제-범위" class="headerlink" title="출제 범위"></a>출제 범위</h3><p>신청 페이지 안에 들어가면 어떤 문제가 출시되는지에 대한 <a href="https://training.elastic.co/exam/elastic-certified-engineer#objectives" target="_blank" rel="noopener">Exam Objectives</a> 내용이 있습니다. 대충 아래와 같네요.</p><blockquote><p>Installation and Configuration</p><ul><li>Deploy and start an Elasticsearch cluster that satisfies a given set of requirements<br>…</li></ul><p>Indexing Data</p><ul><li>Define an index that satisfies a given set of requirements<br>…</li></ul><p>Queries</p><ul><li>Write and execute a search query for terms and/or phrases in one or more fields of an index<br>…</li></ul><p>Aggregations</p><ul><li>Write and execute metric and bucket aggregations<br>…</li></ul><p>Mappings and Text Analysis</p><ul><li>Define a mapping that satisfies a given set of requirements<br>…</li></ul><p>Cluster Administration</p><ul><li>Allocate the shards of an index to specific nodes based on a given set of requirements<br>…</li></ul></blockquote><p>위 내용이 전부 다 나오진 않습니다만 어떤게 나올지 모르니 준비는 다 해야겠지요. 시험은 단답형이나 다지 선다형이 아닌 전부 실습 형태로 진행됩니다.</p><h3 id="시험-준비"><a href="#시험-준비" class="headerlink" title="시험 준비"></a>시험 준비</h3><p>먼저 시험을 신청을 완료하게 되면 시험을 주관하는 <a href="https://www.examslocal.com" target="_blank" rel="noopener">https://www.examslocal.com</a> 라는 시스템에 접속해서 계정을 만들라는 메일을 받게 됩니다. 여기에 접속을 하고 메일로 받은 코드로 내가 볼 시험을 찾아 등록하면 시험 볼 날짜와 시간을 직접 지정하게 됩니다. 시험 시간은 <span style="color:red"><strong>3시간</strong></span> 입니다. 시험 스케줄 등록을 마치면 남은 시간이 나오며 24시간 전에 리마인드 메일이 또 옵니다.</p><p><img src="exam-2.png" alt=""></p><p>시험을 볼 장소, 컴퓨터 등의 환경들을 직접 준비해야 합니다. 시험 볼 컴퓨터에는 <span style="color:red"><strong>웹캠, 마이크</strong></span> 장비가 달려 있어야 합니다. 그리고 <strong>Compability Tool</strong> 메뉴에 가면 미리 필요한 환경을 체크 해 볼 수 있는 메뉴가 있습니다. 사용할 웹 브라우저에 플러그인을 설치 해야 하고, 네트워크 속도도 정확히 기억은 안 나지만 10MBps 이상은 되는지 체크 해야 했습니다.</p><p>시험 시간인 3시간 동안에는 <span style="color:red"><strong>격리된 공간</strong></span>에 있어야 하며 <span style="color:red"><strong>아무도 출입하면 안됩니다.</strong></span> 시험을 보는 동안 얼굴과 상반신을 웹캠이 비추고 있어야 하고 마이크로 방 안의 소리를 들리게 한 상태로 <strong>원격으로 감독관이 감독을 하게 됩니다.</strong> 당연한 이야기지만 시험 중간에 누가 들어온다거나, 말을 한다거나, 휴대폰이 울리면 시험은 중지됩니다.</p><p>시스템에 접속하면 시험 시작 15분 전에 부터 감독관과 대화가 가능하고 준비를 할 수 있습니다. 먼저 감독관이 웹캠으로 시험을 볼 장소와 테이블 위를 비추게 하는데, <span style="color:red"><strong>테이블에는 아무것도 있으면 안됩니다.</strong></span> 저도 시험 보면서 마시려고 커피랑 초콜릿 몇개를 갖고 들어왔는데 다 치우라고 요구하더군요. 😱<br>3시간 동안 아무것도 먹거나 마시거나 화장실 다녀오거나 할 수 없으니 미리 몸 상태를 조절 해 놓기 바랍니다.</p><p>시험이 진행되는 동안 브라우저에 설치된 플러그인이 웹캠과 데스크탑 화면을 계속해서 감독관에게 공유합니다. 화면 캡쳐나 기타 꼼수 프로그램 실행 등은 할 수 없습니다.<br>웹 브라우저로 시스템에 접속하면 감독관이 1:1 채팅으로 계속 이야기를 합니다. 먼저 시험을 볼 브라우저 외 다른 프로그램들은 모두 닫으라고 하고, 브라우저도 시험 환경 페이지 외에 다른 탭은 모두 닫으라고 합니다. 그리고 실행중인 응용 프로그램 창 (맥의 경우 option+command+esc) 을 띄워 실행중인 불순한 프로그램이 없는지도 확인을 합니다. 그리고 준비가 다 되면 시험을 시작합니다.</p><h3 id="시험-진행"><a href="#시험-진행" class="headerlink" title="시험 진행"></a>시험 진행</h3><p>시험은 웹 브라우저를 통해 원격으로 CentOS의 X-Window에 접속해서 진행을 합니다. 필요한 설정들이 다 셋팅이 되어 있고 처음 시작하면 시험 진행 방법과 시험 문제가 나와 있는 (VM 내) 크롬 브라우저가 하나 떠 있습니다. </p><p>일단 기쁜 소식은 <strong>Kibana 를 사용할 수 있습니다.</strong> 자동 완성이 된다는 이야기지요. 그리고 <strong>elastic.co 의 도큐먼트를 보는것도 허락됩니다</strong>만, <span style="color:red"><strong>모두 VM 안에 있는 브라우저로 해야합니다.</strong></span> 이게 상당히 곤욕스러운게, 서버가 미국에 있어서 그런지 굉장히 느리고 답답합니다. 도큐먼트좀 찾아보려고 가서 스크롤 하면 1초 정도 있다가 뚝,뚝 끊기면서 내려가서 다시 올리고 하는데 뒷모가지가 막 땡겨옵니다. 오히려 감독관이 제 의자 뒤에 앉아서 감독하고 제 로컬 머신의 브라우저로 시험을 볼 수 있었으면 훨씬 더 편하겠다는 생각을 했습니다. 이게 은근히 신경쓰이고 시간을 잡아먹어서 로컬에서 할 때 보다 체감상 시간이 3배 정도 걸리는것 같았습니다.</p><p>시험을 보는 도중에 턱을 괴거나 얼굴을 모니터에 가까이 대거나 하면 감독관이 채팅창으로 좀 더 뒤로 가서 바른 자세로 앉으라고 이야기 합니다. 입을 가리는것도 부정 행위로 간주된다고 경고를 주고요.<br><strong>3시간 동안 쉬지도 못하고 정자세로 꼿꼿히 앉아서 시험을 봐야 합니다.</strong> 저는 시험 끝나고 나서 목에 디스크가 왔습니다.</p><h3 id="시험-문제"><a href="#시험-문제" class="headerlink" title="시험 문제"></a>시험 문제</h3><p>제가 본 것만 말씀드리기 때문에 다른 문제가 나올 수도 있습니다. 캡쳐나 문제에 대한 피드백등을 주지 않기 때문에, 제 기억에만 의지해서 설명 드리도록 하겠습니다. 지금부터 설명드리는 내용은 전부 원격 환경 안에서 진행해야 합니다. 예를 들면 Kibana도 내가 시험 보는 로컬 머신의 브라우저 안에 있는 원격 환경 안에서 브라우저를 다시 띄워서 사용해야 합니다.</p><p>처음 원격 환경에 접속하면 브라우저가 하나 띄워져 있고 시험 내용에 대한 설명 창이 떠 있습니다. 답안도 이 브라우저 안에 적고 진행 버튼을 눌러 다음 문제로 넘어가는 형식입니다.<br>문제는 총 12 문제가 나왔습니다. (이것도 정해진 것이 아닐 수 있습니다.)</p><p>1번 문제는 시험 환경에서 또다시 ssh로 터미널 접속을 해서 3개의 elasticsearch 노드를 실행시켜서 클러스터를 구동시키는 문제였습니다. 몇가지 환경에 대한 조건이 주어지는데 (예: 1번 노드는 master dedicated 노드로 하고, 2번 노드는 hot, 3번 노드는 warm 으로 설정) 이 조건을 모두 만족하는 클러스터를 구동하는 것입니다.<br>문제가 어렵지는 않아 보이나, 원격 안에서 또 다시 다른 터미널로 왔다 갔다 하면서 elasticsearch.yml 을 vim 등으로 작업해야 해서 손이 많이 갑니다. 설정 하나 빼먹어서 실행 제대로 안되면 또 다시 3개 다 체크하는 등의 작업을 해야 해서 은근히 시간이 걸렸습니다.<br>1번 문제 풀고 나니까 30분이 지났더군요. 속으로 망했다… 싶었습니다. 😭</p><p>다행이 이후 몇 문제는 크게 어렵지는 않은 문제가 나왔습니다. 주어진 조건대로 query, aggregation 등을 짜서 정답란에 쿼리문을 제출하는 문제가 5~6 문제 나왔던 것 같습니다.</p><p>중간에 _reindex, ingest pipeline, painless script 를 조합하는 문제가 몇개 나왔는데, 실무에서 일반적인 사용법만 경험하신 분들은 좀 어려울 수 있을것 같았습니다. 예를 들면 이미 데이터가 들어있는 A 라는 인덱스가 클러스터 안에 들어있습니다. 그걸 위 기능들을 이용해서 특정 필드의 매핑을 바꾸거나 필드를 추가해서 x 필드의 배열 값을 숫자로 넣는다던지 해서 새로운 B 인덱스로 재색인 하는 형식의 문제입니다.<br>이런 형식의 문제들은 답안 제출란이 없고 그냥 다음 문제로 넘어가는 버튼만 있습니다. 아마 시험이 끝나면 채점관이 B 인덱스를 확인하고 채점하는 것 같았습니다.</p><p>시험범위 중에 cross cluster search 도 있는데 저는 나오지 않았습니다. painless script 는 두세 문제 나왔기 때문에 이건 꼭 한문제 이상 나온다고 생각해도 될것 같습니다.</p><p>Elasticsearch Engineering 공식 교육을 수강하면 확실히 도움이 많이 될 것 같습니다. 문제가 실습에 나오는 패턴과 많이 유사합니다.</p><h3 id="시험이-끝난-후"><a href="#시험이-끝난-후" class="headerlink" title="시험이 끝난 후"></a>시험이 끝난 후</h3><p>시험 시스템이 좀 불안했던건지, 제가 잘못한건지 모르겠는데, 시험 끝나고 제출 버튼을 눌렀는데 화면이 정지됬습니다. 감독관이 당황하면서 기술자들에게 확인하겠다고 기다리라고 해서 시험 끝나고 무려 50 여분을 더 기다렸습니다. 시험 보기 위해 예약한 미팅룸 시간이 끝나가서 감독관에게 여기 예약이 끝나간다고 하니 그럼 잠깐만 브라우저 다른 탭 여는걸 허락할테니 지금 시간 늘리라고 하더군요. 50여분이 지나고 나서 제가 저장한 답변들이 시스템에 제출이 된걸 확인하고 나서 나올 수 있었습니다. 아마 미국은 일하는 시간이 아니어서 엔지니어들도 확인하는데 시간이 걸렸던 것 같습니다.</p><p>시험 안내문에 시험 후 working day 기준으로 3일 후에 결과가 나온다고 되어 있는데, 아직 시스템에 문제가 좀 있는것 같습니다. 4일째 certification 프로그램을 관리하는 Elastic 직원에게서 시험 합격했다는 메일이 왔고, 뱃지는 며칠 더 기다리라고 하더군요. 한 1주일 기다리니 뱃지 링크가 왔습니다.</p><p><a href="https://badge.trueability.com/issued_certifications/ZvNgWmgkj51" target="_blank" rel="noopener">https://badge.trueability.com/issued_certifications/ZvNgWmgkj51</a></p><p><img src="badge.png" alt=""></p><p>Elastic Certified Engineer 시험을 준비하고자 하시는 분들께 이 글이 조금이나마 도움이 되길 바랍니다. 🤓</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;2018년 7월 Elastic에서 첫번째 공식 자격증을 내 놓았습니다.&lt;br&gt;신청은 아래 링크에 가서 하면 됩니다.&lt;br&gt;&lt;a href=&quot;https://training.elastic.co/exam/elastic-certified-engineer&quot;
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic Certified Engineer" scheme="http://kimjmin.net/tags/Elastic-Certified-Engineer/"/>
    
      <category term="elasticsearch 자격증" scheme="http://kimjmin.net/tags/elasticsearch-%EC%9E%90%EA%B2%A9%EC%A6%9D/"/>
    
  </entry>
  
  <entry>
    <title>Swiftype 사이트 서치</title>
    <link href="http://kimjmin.net/2018/04/2018-04-swiftype-site-search/"/>
    <id>http://kimjmin.net/2018/04/2018-04-swiftype-site-search/</id>
    <published>2018-04-03T15:00:00.000Z</published>
    <updated>2018-09-01T05:45:49.774Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Swiftype"><a href="#Swiftype" class="headerlink" title="Swiftype"></a>Swiftype</h2><p>작년 2017년 11월 경 Elastic은 사이트 서치, 엔터프라이즈 서치 기업인 <a href="https://swiftype.com" target="_blank" rel="noopener">Swiftype</a>을 인수했습니다. (관련 블로그:<a href="https://www.elastic.co/blog/swiftype-joins-forces-with-elastic" target="_blank" rel="noopener">https://www.elastic.co/blog/swiftype-joins-forces-with-elastic</a>)<br>저도 처음 소식을 들었을 때는 우리도 스타트업인데 회사가 또 뭘 이렇게 인수하나 싶었는데, 실제로 Swiftype 기능을 한번 보고 나서는 이거 정말 괜찮은 물건이구나 싶었습니다.</p><p>swiftype 기능 소개는 아래 영상에서 확인할 수 있습니다.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/fmLZzpds0hI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><p>이것도 좀 다뤄봐야 하는데 계속 다른 작업에 밀려서 못 하고 있다가 오늘 삘 받아서 한번 사용을 해 봤습니다.<br>눈썰미 좋은 분들은 제 블로그 첫 페이지에 검색 기능이 생긴 것을 눈치 치셨을텐데요, 이번 포스트에서는 개인 블로그에 Swiftype 적용 한 내용을 다루도록 하겠습니다.<br><img src="001.png" alt=""></p><h2 id="서비스-가입-및-데이터-수집"><a href="#서비스-가입-및-데이터-수집" class="headerlink" title="서비스 가입 및 데이터 수집"></a>서비스 가입 및 데이터 수집</h2><p>처음에 서비스를 가입하면 14일간 트라이얼 버전의 사용이 가능합니다. 웹 페이지 내용을 가져오는 방법은</p><ul><li>크롤러를 사용해서 페이지 내용을 긁어오기</li><li>웹페이지에 swiftype API 코드 삽입</li></ul><p>두가지 방법이 있습니다. 저는 크롤러를 사용해서 내용을 가져오도록 설정했습니다. </p><p><img src="002.png" alt=""></p><p>크롤러 사용을 선택한 후 웹사이트 주소만 적어주면 바로 크롤링을 시작합니다.</p><p><img src="003.png" alt=""> <img src="004.png" alt=""></p><p>사이트 하나를 Swiftype 에서는 엔진 (engine) 이라는 단위로 분류하며, 엔진별로 과금을 하게 됩니다. 스탠다드가 월 79달러 입니다.</p><p><img src="005.png" alt=""></p><h2 id="검색-데이터-관리"><a href="#검색-데이터-관리" class="headerlink" title="검색 데이터 관리"></a>검색 데이터 관리</h2><p>크롤러가 데이터를 다 수집하고 나면 다음과 같이 Search Preview 메뉴에서 실제로 수집 된 내용들을 검색 해 볼 수 있습니다.</p><p><img src="006.png" alt=""></p><p>각 필드별로 가중치를 조절해서 검색 순위를 조절할 수도 있습니다. 오른쪽에 검색 결과가 달라지는 모습이 실시간으로 나타납니다.</p><p><img src="007.png" alt=""></p><p>Synonym 메뉴에서 동의어 지정도 가능합니다. 아래는 <code>meetup</code>과 <code>밋업</code>을 동의어로 지정하고 검색 해 본 결과입니다.</p><p><img src="008.png" alt="">, <img src="009.png" alt=""></p><h2 id="웹페이지에-검색-기능-추가"><a href="#웹페이지에-검색-기능-추가" class="headerlink" title="웹페이지에 검색 기능 추가"></a>웹페이지에 검색 기능 추가</h2><p>interface -&gt; install search 메뉴로 들어가면 웹페이지에 추가할 수 있는 javascript 코드가 나타납니다.</p><p><img src="010.png" alt=""> <img src="011.png" alt=""></p><p>여기서 configurations 메뉴에 들어가면 웹 페이지에 나타나는 모양과 검색 창 입력 형식을 지정할 수 있습니다. 기존에 검색 기능이 없는 경우에는 <code>No, my site needs an input field</code> 를 선택하면 검색창을 추가할 수 있는 input 폼 코드, 또는 swiftype search 탭을 사용하도록 선택이 가능합니다.</p><p><img src="012.png" alt=""> <img src="013.png" alt=""></p><p>이제 이 코드들을 웹페이지에 넣으면 웹 페이지에서 검색 기능을 사용할 수 있습니다.</p><p><img src="012.png" alt=""></p><p>지금까지의 과정을 비디오로 녹화했습니다. 아래 페이지에 가셔서 정보를 입력 하시고 submit를 누르시면 영상을 보실 수 있습니다. Swiftype 을 이용해서 이 웹 페이지에 검색 기능을 추가하는 과정을 처음부터 설명합니다.</p><p><a href="https://www.elastic.co/kr/videos/swiftype-site-search-introduction" target="_blank" rel="noopener">https://www.elastic.co/kr/videos/swiftype-site-search-introduction</a></p><blockquote><p>다만, 저도 14일간 트라이얼 버전을 사용하고 있기 때문에 4월 17일 이후에는 검색 기능이 동작을 안 할 수도 있습니다. 🤓</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Swiftype&quot;&gt;&lt;a href=&quot;#Swiftype&quot; class=&quot;headerlink&quot; title=&quot;Swiftype&quot;&gt;&lt;/a&gt;Swiftype&lt;/h2&gt;&lt;p&gt;작년 2017년 11월 경 Elastic은 사이트 서치, 엔터프라이즈 서치 기업인 
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Site Search" scheme="http://kimjmin.net/tags/Site-Search/"/>
    
      <category term="Swiftype" scheme="http://kimjmin.net/tags/Swiftype/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 6.x 에서의 join 사용</title>
    <link href="http://kimjmin.net/2018/01/2018-01-parent-child-to-join/"/>
    <id>http://kimjmin.net/2018/01/2018-01-parent-child-to-join/</id>
    <published>2018-01-18T15:00:00.000Z</published>
    <updated>2018-01-22T04:32:32.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="5-x-이전의-도큐먼트-간-parent-child-구조"><a href="#5-x-이전의-도큐먼트-간-parent-child-구조" class="headerlink" title="5.x 이전의 도큐먼트 간 parent - child 구조"></a>5.x 이전의 도큐먼트 간 parent - child 구조</h2><p>Elasticsearch 에서는 도큐먼트들 간에 연결을 맺을 수 있는 몇가지 기능들을 제공하고 있습니다. 대표적으로는 nested type 이 있으며, 5.x 이전 버전에서는 parent-child 구조의 정의를 할 수 있었습니다.</p><p>5.x 이전의 parent - child 구조는 인덱스 내부의 타입을 parent, 그리고 child 타입으로 나눠서 생성하고 child 에 속한 도큐먼트들이 색인될 때 해당 도큐먼트의 parent 를 명시 해서 저장하는 방식으로 사용했습니다. 자세한 내용은 아래를 문서를 참고하세요.<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/mapping-parent-field.html#_parent_child_restrictions" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.6/mapping-parent-field.html#_parent_child_restrictions</a></p><p>다음은 <code>stackoverflow</code> 라는 인덱스에 <code>question</code> 타입과 <code>answer</code> 타입을 각각 parent - child 구조로 저장 한 예제 입니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;stackoverflow&quot;: &#123;</span><br><span class="line">    &quot;mappings&quot;: &#123;</span><br><span class="line">      &quot;question&quot;: &#123;</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">          &quot;accepted_answer_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;</span><br><span class="line">          ... 중략 ...</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;answer&quot;: &#123;</span><br><span class="line">        &quot;_parent&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;question&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;_routing&quot;: &#123;</span><br><span class="line">          &quot;required&quot;: true</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">          &quot;id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="6-x-에서의-join-데이터-타입-설정"><a href="#6-x-에서의-join-데이터-타입-설정" class="headerlink" title="6.x 에서의 join 데이터 타입 설정"></a>6.x 에서의 join 데이터 타입 설정</h2><p>6.0 부터는 한 인덱스에 하나의 타입만 생성할 수 있도록 강제됩니다. 그래서 parent - child 구조는 더 이상 사용이 불가능하고, 대신 join 이라는 데이터 타입을 이용해서 도큐먼트들 간의 관계를 정의하게 됩니다. join 데이터 타입에 대해서는 아래 문서를 참고합니다.<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.1/parent-join.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.1/parent-join.html</a></p><p>먼저 관계를 설정하기 위한 join 필드를 새로 추가합니다. 저는 <code>qna_join</code> 이라는 필드를 join 필드로 설정했습니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT stackoverflow</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;doc&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;qna_join&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;join&quot;,</span><br><span class="line">          &quot;relations&quot;: &#123;</span><br><span class="line">            &quot;question&quot;: &quot;answer&quot; </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>그리고 question 도큐먼트에는 <code>qna_join</code> 필드 안의 <code>name</code> 값을 <code>question</code> 으로, answer 도큐먼트에는 <code>answer</code> 와 parent에 해당하는 question 도큐먼트의 id 값을 넣어줍니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST stackoverflow/doc/25691276?routing=25691276</span><br><span class="line">&#123;</span><br><span class="line">  &quot;title&quot;: &quot;Import CSV into MySQL - Offset by 1 Column&quot;,</span><br><span class="line">  &quot;accepted_answer_id&quot;: 25691509,</span><br><span class="line">  ... 중략 ...</span><br><span class="line">  &quot;id&quot;: 25691276,</span><br><span class="line">  &quot;view_count&quot;: 15,</span><br><span class="line">  &quot;qna_join&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;question&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST stackoverflow/doc/25691509?routing=25691276</span><br><span class="line">&#123;</span><br><span class="line">  &quot;comment_count&quot;: 0,</span><br><span class="line">  &quot;owner&quot;: &#123;</span><br><span class="line">    &quot;location&quot;: &quot;Sao Paulo, Brazil&quot;,</span><br><span class="line">    &quot;id&quot;: 3337405,</span><br><span class="line">    &quot;display_name&quot;: &quot;vinibarr&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;comments&quot;: [],</span><br><span class="line">  &quot;creation_date&quot;: &quot;2014-09-05T18:01:23.033&quot;,</span><br><span class="line">  &quot;id&quot;: 25691509,</span><br><span class="line">  &quot;body&quot;: &quot;&quot;&quot;</span><br><span class="line">&lt;p&gt;You can load your data specifing the order columns that you&apos;re going to use into your table:</span><br><span class="line">... 중략 ...</span><br><span class="line">&quot;&quot;&quot;,</span><br><span class="line">  &quot;qna_join&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;answer&quot;,</span><br><span class="line">    &quot;parent&quot;:&quot;25691276&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>중요한 것은 parent, child 두개 도큐먼트는 항상 동일한 routing 값을 넣어줘야 합니다. 같은 routing 값을 가진 도큐먼트는 같은 샤드에 저장이 됩니다.<br>이렇게 저장한 후 <code>has_parent</code> 쿼리를 이용해서 <code>question</code> 도큐먼트의 id 필드 값을 이용해서 그 도큐먼트와 연결된 <code>answer</code> 도큐먼트를 가져오는 쿼리를 실행 해 봅니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET stackoverflow/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;has_parent&quot;: &#123;</span><br><span class="line">      &quot;parent_type&quot;: &quot;question&quot;,</span><br><span class="line">      &quot;query&quot;: &#123;</span><br><span class="line">        &quot;term&quot;: &#123;</span><br><span class="line">          &quot;id&quot;: &#123;</span><br><span class="line">            &quot;value&quot;: &quot;25691276&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>위 쿼리를 실행하면 아래와 같이 <code>answer</code> 도큐먼트를 결과로 가져옵니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 12,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 1,</span><br><span class="line">    &quot;successful&quot;: 1,</span><br><span class="line">    &quot;skipped&quot;: 0,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 1,</span><br><span class="line">    &quot;max_score&quot;: 1,</span><br><span class="line">    &quot;hits&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;stackoverflow&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;doc&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;25691509&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_routing&quot;: &quot;1&quot;,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;comment_count&quot;: 0,</span><br><span class="line">          &quot;owner&quot;: &#123;</span><br><span class="line">            &quot;location&quot;: &quot;Sao Paulo, Brazil&quot;,</span><br><span class="line">            &quot;id&quot;: 3337405,</span><br><span class="line">            &quot;display_name&quot;: &quot;vinibarr&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;comments&quot;: [],</span><br><span class="line">          &quot;creation_date&quot;: &quot;2014-09-05T18:01:23.033&quot;,</span><br><span class="line">          &quot;id&quot;: 25691509,</span><br><span class="line">          &quot;body&quot;: &quot;&quot;&quot;</span><br><span class="line">&lt;p&gt;You can load your data specifing the order columns that you&apos;re going to use into your table:</span><br><span class="line">    ... 중략 ...</span><br><span class="line">&quot;&quot;&quot;,</span><br><span class="line">          &quot;qna_join&quot;: &#123;</span><br><span class="line">            &quot;name&quot;: &quot;answer&quot;,</span><br><span class="line">            &quot;parent&quot;: &quot;25691276&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="Logstash-색인-설정"><a href="#Logstash-색인-설정" class="headerlink" title="Logstash 색인 설정"></a>Logstash 색인 설정</h2><p>이제 5.x 에서 parent - child 타입으로 나뉘어 있던 데이터를 6.x 로 재 색인을 해야 합니다. 먼저 데이터를 타입별로 구분해야 하므로 저는 question 타입과 answer 타입의 데이터들을 각각 <code>/Users/kimjmin/elastic/source/stackoverflow/</code> 경로 아래에 <code>question.json</code>, <code>answer.json</code> 이라는 파일들로 저장 했습니다.<br>이제 logstash 설정 파일을 작성하겠습니다. path 로 부터 파일 이름에 있는 <code>question</code> 그리고 <code>answer</code> 를 추출하여 <code>qna_join.name</code> 에 해당하는 값을 넣어주도록 했습니다.</p><p> 우선 파일 이름을 기준으로 <code>question</code>, <code>answer</code> 태그를 만들도록 합니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  file &#123;</span><br><span class="line">    path =&gt; &quot;/Users/kimjmin/elastic/source/stackoverflow/*.json&quot;</span><br><span class="line">    sincedb_path =&gt; &quot;/dev/null&quot;</span><br><span class="line">    start_position =&gt; &quot;beginning&quot;</span><br><span class="line">    codec =&gt; &quot;json&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">  # &quot;/&quot; 기준으로 path를 배열로 분리하여 [6]번째 값인 &quot;question.json&quot; 또는 &quot;answer.json&quot;을 path_array 에 저장.</span><br><span class="line">  mutate &#123;</span><br><span class="line">    split =&gt; &#123; &quot;path&quot; =&gt; &quot;/&quot; &#125;</span><br><span class="line">    add_field =&gt; &#123; &quot;path_array&quot; =&gt; &quot;%&#123;path[6]&#125;&quot; &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  mutate &#123;</span><br><span class="line">    # &quot;.&quot; 기준으로 path_array를 배열로 분리하여 [0]번째 값인 &quot;question&quot; 또는 &quot;answer&quot;을 qna_join.name, doc_type 에 저장.</span><br><span class="line">    split =&gt; &#123; &quot;path_array&quot; =&gt; &quot;.&quot; &#125;</span><br><span class="line">    add_field =&gt; &#123; &quot;[qna_join][name]&quot; =&gt; &quot;%&#123;path_array[0]&#125;&quot; &#125;</span><br><span class="line">    add_field =&gt; &#123; &quot;doc_type&quot; =&gt; &quot;%&#123;path_array[0]&#125;&quot; &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  mutate &#123;</span><br><span class="line">    remove_field =&gt; [&quot;host&quot;,&quot;@version&quot;,&quot;path&quot;,&quot;path_array&quot;,&quot;@timestamp&quot;]</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ... 중략 ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>현재 구성중인 stackoverflow 는 parent가 question, child 가 answer 구조로 되어 있습니다. 하지만 도큐먼트 내용을 보면 question 도큐먼트에는 answer 도큐먼트와 연결되는 <code>accepted_answer_id</code> 필드가 있지만 answer 에는 question 도큐먼트를 확인하는 필드가 없습니다. answer 도큐먼트가 색인 될 때 연결되는 question 도큐먼트의 id 값을 가져오기 위해 Logstash 의 filter 내부에 <code>elasticsearch</code> 필터를 추가합니다.<br><a href="https://www.elastic.co/guide/en/logstash/6.1/plugins-filters-elasticsearch.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/6.1/plugins-filters-elasticsearch.html</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line"></span><br><span class="line">  ... 중략 ...</span><br><span class="line"></span><br><span class="line">  if [doc_type] == &quot;question&quot; &#123;</span><br><span class="line">    # routing 을 위해 question 도큐먼트의 id를 question_id 필드에 저장</span><br><span class="line">    mutate&#123;</span><br><span class="line">      add_field =&gt; &#123; &quot;question_id&quot; =&gt; &quot;%&#123;id&#125;&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; else if [doc_type] == &quot;answer&quot; &#123;</span><br><span class="line">    # routing 을 위해 answer에 해당하는 question 도큐먼트의 id 를 가져와서 question_id 필드에 저장</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">      hosts =&gt; [&quot;localhost:9200&quot;]</span><br><span class="line">      index =&gt; &quot;stackoverflow&quot;</span><br><span class="line">      query =&gt; &quot;doc_type:question AND accepted_answer_id:%&#123;id&#125;&quot;</span><br><span class="line">      fields =&gt; &#123; &quot;id&quot; =&gt; &quot;[qna_join][parent]&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    mutate&#123;</span><br><span class="line">      add_field =&gt; &#123; &quot;question_id&quot; =&gt; &quot;%&#123;[qna_join][parent]&#125;&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>이제 데이터를 elasticsearch로 저장하도록 output 을 입력합니다. parent - child 구조의 도큐먼트는 같은 샤드에 저장하기 위해 항상 같은 rounting 값을 적어줘야 합니다. routing 값을 question 도큐먼트의 id 값인 <code>question_id</code> 필드 값으로 지정합니다. 만약에 stackoverflow 인덱스에 샤드가 1개만 있다고 하면 routing 에 모든 도큐먼트에 적용되는 임의의 값을 넣어도 됩니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    index =&gt; &quot;stackoverflow&quot;</span><br><span class="line">    document_type =&gt; &quot;doc&quot;</span><br><span class="line">    document_id =&gt; &quot;%&#123;id&#125;&quot;</span><br><span class="line">    routing =&gt; &quot;%&#123;question_id&#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>이제 데이터를 색인합니다.</p><blockquote><p>중요! 반드시 <code>question</code> 도큐먼트들을 먼저 색인 한 뒤에 <code>answer</code> 도큐먼트들을 색인해야 합니다.</p></blockquote><p>데이터 색인이 끝난 뒤 앞에서 실행했던 <code>has_parent</code> 쿼리를 이용해서 데이터가 정상적으로 나오는지 확인 해 봅니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET stackoverflow/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;has_parent&quot;: &#123;</span><br><span class="line">      &quot;parent_type&quot;: &quot;question&quot;,</span><br><span class="line">      &quot;query&quot;: &#123;</span><br><span class="line">        &quot;term&quot;: &#123;</span><br><span class="line">          &quot;id&quot;: &#123;</span><br><span class="line">            &quot;value&quot;: &quot;25691276&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 1,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 5,</span><br><span class="line">    &quot;successful&quot;: 5,</span><br><span class="line">    &quot;skipped&quot;: 0,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 1,</span><br><span class="line">    &quot;max_score&quot;: 1,</span><br><span class="line">    &quot;hits&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;stackoverflow&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;doc&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;25691509&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_routing&quot;: &quot;1&quot;,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;comment_count&quot;: 0,</span><br><span class="line">          &quot;owner&quot;: &#123;</span><br><span class="line">            &quot;location&quot;: &quot;Sao Paulo, Brazil&quot;,</span><br><span class="line">            &quot;id&quot;: 3337405,</span><br><span class="line">            &quot;display_name&quot;: &quot;vinibarr&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;comments&quot;: [],</span><br><span class="line">          &quot;creation_date&quot;: &quot;2014-09-05T18:01:23.033&quot;,</span><br><span class="line">          &quot;id&quot;: 25691509,</span><br><span class="line">          &quot;body&quot;: &quot;&quot;&quot;</span><br><span class="line">&lt;p&gt;You can load your data specifing the order columns that you&apos;re going to use into your table:</span><br><span class="line">    ... 중략 ...</span><br><span class="line">&quot;&quot;&quot;,</span><br><span class="line">          &quot;qna_join&quot;: &#123;</span><br><span class="line">            &quot;name&quot;: &quot;answer&quot;,</span><br><span class="line">            &quot;parent&quot;: &quot;25691276&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>이처럼 <code>join</code> 타입의 필드를 사용해서 과거처럼 parent-child 구조를 만들 수 있으며, logstash의 <code>elasticsearch</code> 필터를 사용해서 데이터를 색인할 때 elasticsearch 에 있는 데이터를 가져와서 도큐먼트에 추가할 수 있습니다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;5-x-이전의-도큐먼트-간-parent-child-구조&quot;&gt;&lt;a href=&quot;#5-x-이전의-도큐먼트-간-parent-child-구조&quot; class=&quot;headerlink&quot; title=&quot;5.x 이전의 도큐먼트 간 parent - child 구조
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Cluster 구성 8</title>
    <link href="http://kimjmin.net/2018/01/2018-01-build-es-cluster-8/"/>
    <id>http://kimjmin.net/2018/01/2018-01-build-es-cluster-8/</id>
    <published>2018-01-07T15:00:00.000Z</published>
    <updated>2018-01-12T05:41:20.959Z</updated>
    
    <content type="html"><![CDATA[<p><del>새로 산 게임기 하느라</del> 바쁜 일정 때문에 며칠만에 포스팅 하네요.</p><p>오늘은 Logstash 설치 및 Elasticsearch 기본 템플릿 설정을 하도록 하겠습니다. 이전 또는 이후 내용들은 아래 포스트에서 확인하세요.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><strong>8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</strong></p></blockquote><p>아래는 저희가 지금까지 설치한 아키텍쳐입니다. </p><p><img src="architecture-security.png" alt=""></p><p>오늘은 Service 서버에 Logstash 설치를 먼저 해 보겠습니다. 오늘 포스트에서 Logstash 기본적인 사용 방법을 설명하진 않겠습니다. 설명은</p><ul><li>공식 도큐먼트 : <a href="https://www.elastic.co/guide/en/logstash/current/index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/current/index.html</a></li><li>또는 비디오: <a href="https://www.elastic.co/kr/webinars/getting-started-logstash" target="_blank" rel="noopener">https://www.elastic.co/kr/webinars/getting-started-logstash</a><br>등을 참고 부탁드립니다.</li></ul><h2 id="Logstash-설치"><a href="#Logstash-설치" class="headerlink" title="Logstash 설치"></a>Logstash 설치</h2><p>Logstash도 지금까지 설치한 Elasticsearch, Kibana와 마찬가지로 서비스로 돌릴 수 있도록 설치 해 보겠습니다.<br>Logstash도 Elasticsearch와 마찬가지로 Java 에서 실행되며 1.8 버전을 권장합니다. 앞서 Java는 설치했으므로 바로 넘어가겠습니다.</p><h3 id="Yum-설치"><a href="#Yum-설치" class="headerlink" title="Yum 설치"></a>Yum 설치</h3><p>아래 문서를 참고해서 설치를 진행하겠습니다.<br><a href="https://www.elastic.co/guide/en/logstash/current/installing-logstash.html#_yum" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/current/installing-logstash.html#_yum</a></p><p>Yum 설치를 위해 <code>/etc/yum.repos.d/</code>에 <code>logstash.repo</code> 파일을 만들고 아래 내용을 추가합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[logstash-6.x]</span><br><span class="line">name=Elastic repository for 6.x packages</span><br><span class="line">baseurl=https://artifacts.elastic.co/packages/6.x/yum</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch</span><br><span class="line">enabled=1</span><br><span class="line">autorefresh=1</span><br><span class="line">type=rpm-md</span><br></pre></td></tr></table></figure></p><p>그리고 설치합니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install logstash</span><br></pre></td></tr></table></figure><p>Logstash의 RPM 버전 설치 경로들은 아래와 같습니다.</p><ul><li>기본 프로그램 (<strong>$LS_HOME</strong>) : <code>/usr/share/logstash</code><ul><li>실행 파일 : <code>bin/logstash</code></li></ul></li><li>설정 : <code>/etc/logstash</code><ul><li><code>logstash.yml</code></li><li><code>jvm.options</code></li><li><code>log4j2.properties</code></li><li><code>startup.options</code></li></ul></li><li>파이프라인 설정 (<strong>path.config</strong>) : <code>/etc/logstash/conf.d</code></li><li>플러그인(<strong>path.plugins</strong>) : <code>/usr/share/logstash/plugins</code></li><li>데이터 (추가 플러그인 설치 등) : <code>/var/lib/logstash</code></li><li>로그 (<strong>path.logs</strong>) : <code>/var/log/logstash</code></li></ul><p>설치가 끝나고 logstash를 시작하기 위해서는 initctl를 사용합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo initctl start logstash</span><br></pre></td></tr></table></figure></p><p>실행중인 logstash를 정지하려면 아래 명령을 사용합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo initctl stop logstash</span><br></pre></td></tr></table></figure></p><h3 id="X-Pack-설치"><a href="#X-Pack-설치" class="headerlink" title="X-Pack 설치"></a>X-Pack 설치</h3><p>6.0 부터는 Logstash도 X-Pack을 설치할 수 있습니다. X-Pack을 설치하게 되면 Logstash 상태 모니터링과 파이프라인 뷰어, 파이프라인 빌더 등의 사용이 가능합니다.</p><p>우선 설치 경로로 이동해서<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /usr/share/logstash</span><br></pre></td></tr></table></figure></p><p>X-Pack을 설치합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo bin/logstash-plugin install x-pack</span><br></pre></td></tr></table></figure></p><p>그리고 <code>logstash.yml</code> 파일에 사용자와 ID, password를 등록 해 줘야 합니다. <a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a> 에서 생성한 <code>logstash_system</code> id를 사용합니다.</p><h3 id="Logstash-모니터링-설정"><a href="#Logstash-모니터링-설정" class="headerlink" title="Logstash 모니터링 설정"></a>Logstash 모니터링 설정</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ]$ sudo vim /etc/logstash/logstash.yml</span><br><span class="line"></span><br><span class="line">xpack.monitoring.elasticsearch.url: [&quot;http://192.168.0.10:9200&quot;]</span><br><span class="line">xpack.monitoring.elasticsearch.username: logstash_system</span><br><span class="line">xpack.monitoring.elasticsearch.password: logstashpassword</span><br></pre></td></tr></table></figure><p>저희는 elasticsearch의 네트워크 설정을 했기 때문에 <code>xpack.monitoring.elasticsearch.url</code>에 실제 IP 주소를 적어야 합니다.<br>위 내용을 입력하고 나면 이제 Kibana 에서 Logstash 모니터링이 가능합니다.</p><p><img src="ls-monitoring.png" alt=""></p><h3 id="Logstash-관리-기능-설정"><a href="#Logstash-관리-기능-설정" class="headerlink" title="Logstash 관리 기능 설정"></a>Logstash 관리 기능 설정</h3><p>Kibana에서 Logstash 관리 기능의 사용이 가능합니다. 먼저 사용자 중에 <code>logstash_admin</code> 권한을 가진 사용자가 필요합니다. Kibana 에서 <code>logstash-admin-user</code> 라는 이름으로 사용자를 추가하겠습니다. 이 사용자에게는 <code>logstash_admin</code> 그리고 <code>logstash_system</code> 권한을 부여하도록 합니다.</p><p><img src="ls-user-add.png" alt=""></p><p><code>logstash.yml</code>에 아래 내용을 추가 해 줍니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xpack.management.enabled: true</span><br><span class="line">xpack.management.elasticsearch.url: &quot;http://192.168.0.10:9200/&quot;</span><br><span class="line">xpack.management.elasticsearch.username: logstash-admin-user</span><br><span class="line">xpack.management.elasticsearch.password: password</span><br><span class="line">xpack.management.logstash.poll_interval: 5s</span><br><span class="line">xpack.management.pipeline.id: [&quot;apache&quot;, &quot;cloudwatch_logs&quot;,&quot;ls-custom&quot;]</span><br></pre></td></tr></table></figure><p><code>xpack.management.elasticsearch.password</code> 항목에는 당연히 <code>logstash-admin-user</code> 사용자의 계정 비밀번호를 넣으면 됩니다. 그리고 <code>xpack.management.pipeline.id</code> 항목에 내가 관리자 화면에서 사용할 Logstash 파이프 ID 들을 추가 해 줍니다. 저는 <code>ls-custom</code> 이라는 id를 추가 해 보았습니다. 뒤에 나오는 파이프라인 관리 화면에서는 이곳에 정의된 ID의 파이프들만 추가가 가능합니다.</p><h3 id="Logstash-관리-화면에서-파이프라인-추가"><a href="#Logstash-관리-화면에서-파이프라인-추가" class="headerlink" title="Logstash 관리 화면에서 파이프라인 추가"></a>Logstash 관리 화면에서 파이프라인 추가</h3><p>이제 Logstash를 시작하고 Kibana의 <code>Management</code> &gt; <code>[Logstash] Pipelines</code> 메뉴에 들어가서 <code>add</code> 버튼을 눌러 <code>ls-custom</code> 파이프를 추가 해 보겠습니다.</p><p><img src="ls-custom.png" alt=""></p><p>위 그림과 같이 입력은 <code>tcp</code> 의 9999 포트에서 입력 받아 출력은 <code>elasticsearch</code> 로 해 보겠습니다.</p><p>이제 콘솔에서 nc(NetCat) 명령을 이용해서 9999 포트로 “hello” 라는 메시지를 전송 해 보겠습니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ]$ echo &apos;hello&apos; | nc 172.31.27.193 9999</span><br></pre></td></tr></table></figure><p>그리고 <code>logstash-*</code> 인덱스를 확인 해 보면 <code>&quot;message&quot;: &quot;hello&quot;</code> 인 도큐먼트가 입력된 것을 확인할 수 있습니다.</p><p><img src="ls-data-indexed.png" alt=""></p><h3 id="모니터-화면에서-파이프라인-확인"><a href="#모니터-화면에서-파이프라인-확인" class="headerlink" title="모니터 화면에서 파이프라인 확인"></a>모니터 화면에서 파이프라인 확인</h3><p><code>Monitoring</code> &gt; <code>[Logstash] Pipelines</code> 로 들어가 보면 방금 만든 <code>ls-custom</code> 파이프가 보입니다.</p><p><img src="pipe-view-1.png" alt=""></p><p>클릭하고 들어가면 자세한 파이프를 볼 수 있습니다.</p><p><img src="pipe-view-2.png" alt=""></p><p>참고로 파이프라인 관리 도구는 X-Pack Gold 라이센스 이상, 파이프라인 모니터링 도구는 X-Pack Basic 라이센스에서 사용이 가능합니다. 라이센스는 아래 링크에서 확인하세요.<br><a href="https://www.elastic.co/kr/subscriptions" target="_blank" rel="noopener">https://www.elastic.co/kr/subscriptions</a></p><h2 id="기본-Template-설정"><a href="#기본-Template-설정" class="headerlink" title="기본 Template 설정"></a>기본 Template 설정</h2><p><code>_template</code> API를 사용하면 특정한 인덱스 이름등에 대해서 setting, mapping 등의 값들을 미리 정해줄 수 있습니다.<br><code>GET /_cat/templates</code> 또는 <code>GET /_templates/템플릿이름</code> 을 이용해서 지금 설정되어 있는 템플릿들과 세부 내용들을 볼 수 있습니다.</p><p><img src="get-template.png" alt=""></p><p>Elasticsearch 가 가지고 있는 몇가지 기본 설정들이 있는데, 저희는 클러스터가 작고 노드가 3개밖에 없으므로 몇가지 기본 설정을 좀 변경 해 주겠습니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT _template/basic</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index_patterns&quot; : [&quot;*&quot;],</span><br><span class="line">  &quot;order&quot;: &quot;0&quot;,</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;number_of_shards&quot;: 1,</span><br><span class="line">    &quot;refresh_interval&quot;: &quot;10s&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><code>&quot;index_patterns&quot; : [&quot;*&quot;]</code> : 앞으로 이 클러스터에서 생성될 모든 인덱스에 적용합니다.</li><li><code>&quot;order&quot;: &quot;0&quot;</code> : 이 값이 높을수록 템플릿의 우선순위가 높으며, 지금 만든 basic 템플릿은 우선순위가 0으로 가장 낮습니다. logstash-* 와 같은 인덱스 패턴에 적용되는 또다른 템플릿이 order:1 등으로 설정되게 되면 해당 이름의 인덱스들은 더 높은 우선순위의 템플릿을 적용받습니다.</li><li><code>&quot;settings.number_of_shards&quot;: 1</code> : 기본 샤드 개수를 5개 –&gt; 1개로 변경합니다.</li><li><code>&quot;settings.refresh_interval&quot;: &quot;10s&quot;</code> : refresh 주기를 1초 –&gt; 10초 로 변경합니다.</li></ul><p>자, 이제 Logstash 설치와 템플릿 설정도 모두 끝났으니 클러스터에 데이터를 입력하고 사용할 준비를 모두 마쳤습니다.</p><p>기본 클러스터 구성에 대한 내용은 지금까지의 블로그 포스트 시리즈로 설명을 드렸습니다.<br>앞으로 유용한 설정이나 운영 기법 등은 기회가 되는 대로 별도 개별 포스트 또는 새로운 시리즈로 추가하도록 하겠습니다.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><strong>8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</strong></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;del&gt;새로 산 게임기 하느라&lt;/del&gt; 바쁜 일정 때문에 며칠만에 포스팅 하네요.&lt;/p&gt;
&lt;p&gt;오늘은 Logstash 설치 및 Elasticsearch 기본 템플릿 설정을 하도록 하겠습니다. 이전 또는 이후 내용들은 아래 포스트에서 확인하세요
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Elastic Cluster Settings" scheme="http://kimjmin.net/tags/Elastic-Cluster-Settings/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Cluster 구성 7</title>
    <link href="http://kimjmin.net/2018/01/2018-01-build-es-cluster-7/"/>
    <id>http://kimjmin.net/2018/01/2018-01-build-es-cluster-7/</id>
    <published>2018-01-06T15:00:00.000Z</published>
    <updated>2018-01-12T05:41:25.277Z</updated>
    
    <content type="html"><![CDATA[<p>이번 포스트에서는 X-Pack License 적용 및 신규 사용자 생성을 하도록 하겠습니다. 이전 또는 이후 내용들은 아래 포스트에서 확인하세요.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><strong>7. X-Pack License 적용 및 사용자 생성</strong><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote><h2 id="X-Pack-License-적용"><a href="#X-Pack-License-적용" class="headerlink" title="X-Pack License 적용"></a>X-Pack License 적용</h2><p>X-Pack 을 설치하면 기본적으로 30일 간 Trial 버전으로 사용이 가능합니다. X-Pack는 각각 Basic(무료), Gold, Platinum, Enterprise(ECE) 라이센스들이 있으며 각 라이센스 별 기술과 기능의 지원 범위는 아래 페이지에서 확인 가능합니다.<br><a href="https://www.elastic.co/kr/subscriptions" target="_blank" rel="noopener">https://www.elastic.co/kr/subscriptions</a></p><p><img src="subscriptions.png" alt=""></p><p>Elastic Stack - Elasticsearch, Logstash, Kibana, Beats 는 완전한 오픈소스 라이센스이고, X-Pack Monitoring의 경우 Basic 라이센스를 통해 사용이 가능합니다. 그 외의 기능은 Gold 이상의 라이센스가 필요하며 Graph, Machine Learning 의 경우 Platinum 이상에서 제공됩니다. 라이센스는 Elastic사와 구독을 통해 기술지원 계약을 맺게 되면 라이센스가 저장된 키 파일을 제공받습니다.</p><p>라이센스 키는 json 문서가 저장된 .json 형태의 파일입니다. 라이센스는 <code>_xpack/license</code> API에 저장이 되는데, 먼저 GET 명령으로 이 API를 적용시켜 보면 현재 라이센스 정보를 확인할 수 있습니다. 아래는 라이센스가 적용되지 않은 Trial 상태의 라이센스 정보입니다.</p><p><img src="license-trial.png" alt=""></p><p>상태는 <code>&quot;type&quot;:&quot;trial&quot;</code>, 만료 일자는 설치 후 30일인 <code>&quot;expiry_date&quot;:&quot;2018-02-02...&quot;</code> 로 되어 있는것을 확인할 수 있습니다.</p><p>이제 아래 링크의 문서를 참고해서 라이센스를 적용 해 보겠습니다.<br><a href="https://www.elastic.co/guide/en/x-pack/current/installing-license.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/x-pack/current/installing-license.html</a></p><p>라이센스 키를 적용하기 위해서는 먼저, curl 명령을 통해 를 통해 라이센스 파일의 내용을 PUT 하는 방법이 있습니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XPUT -u elastic &apos;https://192.168.0.10:9200/_xpack/license&apos; -H &quot;Content-Type: application/json&quot; -d @es-demo-fcc1-580-8dd0-8a389a-v5.json</span><br><span class="line">Enter host password for user &apos;elastic&apos;:</span><br></pre></td></tr></table></figure><p>또는 라이센스 파일의 내용을 Kibana의 Dev Tools 에서 PUT 으로 입력해도 됩니다.</p><p><img src="put-license.png" alt=""></p><p>라이센스 적용 후 다시 <code>GET _xpack/license</code> API를 확인 해 보면</p><p><img src="license-platinum.png" alt=""></p><p>상태가 <code>&quot;type&quot;:&quot;platinum&quot;</code>, 만료 일자는 계약 만료일인 <code>&quot;expiry_date&quot;:&quot;2018-08-01...&quot;</code> 로 변경 된 것을 확인할 수 있습니다.</p><blockquote><p>참고로 이전 포스트에서 설정한 TLS 설정이 활성화 되어 있지 않으면 X-Pack 라이센스가 적용이 되지 않습니다. TLS 설정은 X-Pack Gold 이상을 사용하기 위한 최소한으로 해 주어야 하는 설정입니다.</p></blockquote><h2 id="사용자-생성"><a href="#사용자-생성" class="headerlink" title="사용자 생성"></a>사용자 생성</h2><p>X-Pack 이 설치되면 Kibana의 Management 메뉴에 Security 를 설정하는 메뉴가 나타납니다. Security 에서는 사용자(User)와 권한(Role)을 생성하거나 관리할 수 있습니다.</p><p><img src="management-security.png" alt=""></p><p><code>Roles</code> 메뉴에서 허용할 인덱스, 필드 및 도큐먼트에 대한 접근 권한들을 설정할 수 있습니다. </p><p><img src="set-role.png" alt=""></p><p><code>Roles</code> 메뉴의 항목들은 다음과 같습니다.</p><ul><li><strong>Name</strong>: 권한 이름. 1개의 영문+숫자 단어여야 합니다.</li><li><strong>Cluster Privileges</strong>: 클러스터에 대한 권한</li><li><strong>Add a user…</strong>: 이 권한을 적용받는 사용자. 이 항목은 비워 둔 다음 권한을 먼저 만들고 나중에 사용자를 만들때 권한을 적용하는것도 가능합니다.</li><li><strong>Indices</strong>: 접근 가능한 인덱스들. <code>*</code>로 설정하면 모든 인덱스에 접근이 가능합니다.</li><li><strong>Privileges</strong>: 앞의 인덱스들에 대해 read, create, delete 등의 권한 설정이 가능합니다.</li><li><strong>Granted Documents Query</strong>: 해당 권한의 사용자가 쿼리를 할 때 항상 적용 될 서브쿼리를 적습니다. 권한에 따라 특정 도큐먼트를 필터링 하기 위함입니다.</li><li><strong>Granted Fields</strong>: 이 권한의 사용자에게는 이 항목에 입력된 필드들만 나타납니다. 권한에 따라 특정 필드를 필터링 하기 위함입니다.</li></ul><p>또한 <code>Users</code> 메뉴에서 신규 사용자의 생성이 가능합니다.</p><p><img src="set-user.png" alt=""></p><p><code>Roles</code> 항목 에서 이 사용자에게 어떤 권한을 부여할지 입력합니다. 권한은 1개 이상이 될 수 있으며 <strong><em>여러개의 권한을 부여하는 경우 부여된 모든 권한에 대해 접근 가능 범위가 적용이 됩니다</em></strong>. 다시말해 OR 조건으로 권한이 부여되며 어떤 유저가 <code>superuser</code> 그리고 <code>new_user</code> 의 권한을 부여받으면 이 유저는 <code>superuser</code> 권한이 가진 모든 권한을 헹사할 수 있습니다. 그렇기 때문에 적용할 권한은 최소한, 겹치는 영역 없이 하는것이 (가능하면 1 사용자 : 1 권한) 바람직합니다.</p><p>다음 포스트에서는 Elastic Cluster 구성 시리즈의 마지막으로 Logstash 설치 및 Elasticsearch 기본 템플릿 설정에 대해 살펴보도록 하겠습니다.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><strong>7. X-Pack License 적용 및 사용자 생성</strong><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;이번 포스트에서는 X-Pack License 적용 및 신규 사용자 생성을 하도록 하겠습니다. 이전 또는 이후 내용들은 아래 포스트에서 확인하세요.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;/2018/01/2018-01-build-es-
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Elastic Cluster Settings" scheme="http://kimjmin.net/tags/Elastic-Cluster-Settings/"/>
    
      <category term="X-Pack" scheme="http://kimjmin.net/tags/X-Pack/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Cluster 구성 6</title>
    <link href="http://kimjmin.net/2018/01/2018-01-build-es-cluster-6/"/>
    <id>http://kimjmin.net/2018/01/2018-01-build-es-cluster-6/</id>
    <published>2018-01-05T15:00:00.000Z</published>
    <updated>2018-01-12T05:41:24.541Z</updated>
    
    <content type="html"><![CDATA[<p>이번 포스트에서는 X-Pack Security를 이용한 보안 설정을 하도록 하겠습니다. 이전 또는 이후 내용들은 아래 포스트에서 확인하세요.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><strong>6. X-Pack Security를 이용한 SSL 및 TLS 설정</strong><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote><p>참고로 X-Pack은 Elastic에서 배포하는 공식 상용 플러그인이며 다음과 같은 모듈들을 가지고 있습니다.</p><p><img src="x-pack-list.png" alt=""></p><ul><li><a href="https://www.elastic.co/kr/products/x-pack/security" target="_blank" rel="noopener">Security</a>: 사용자/권한 기반의 인증 및 통신 암호화 기능을 제공합니다.</li><li><a href="https://www.elastic.co/kr/products/x-pack/alerting" target="_blank" rel="noopener">Alerting</a>: 쿼리 기반의 자동 알림 기능을 제공합니다.</li><li><a href="https://www.elastic.co/kr/products/x-pack/monitoring" target="_blank" rel="noopener">Monitoring</a>: ES 클러스터의 상태 모니터링 기능을 제공합니다.</li><li><a href="https://www.elastic.co/kr/products/x-pack/graph" target="_blank" rel="noopener">Graph</a>: 관계도 분석 기능을 제공합니다.</li><li><a href="https://www.elastic.co/kr/products/x-pack/reporting" target="_blank" rel="noopener">Reporting</a>: Kibana 대시보드를 PDF로 내려받거나 데이터를 CSV 파일로 저장합니다.</li><li><a href="https://www.elastic.co/kr/products/x-pack/machine-learning" target="_blank" rel="noopener">Machine Learning</a>: 시계열 데이터 기반의 실시간 이상징후 탐지 기능을 제공합니다.</li></ul><p>다른 모듈들에 대해서는 각 제목에 링크된 공식 홈페이지 내용을 참고하시기 바랍니다.</p><p>오늘은 작업 할 내용들은 다음과 같습니다.</p><ul><li>Elasticsearch 노드들 간의 통신에 TLS를 설정 하고, Elasticsearch와 다른 클라이언트 프로그램들 간에는 그냥 http로 두겠습니다.</li><li>Kibana 에 SSL을 적용해서 사용자가 Kibana에 접속할 때 <a href="https://host:5601" target="_blank" rel="noopener">https://host:5601</a> 로 접속할 수 있도록 하겠습니다.</li><li>Audit(감사) 로그를 수집하도록 하겠습니다.</li></ul><p><img src="architecture-security.png" alt=""></p><h2 id="Elasticsearch-노드들-간의-TLS-설정"><a href="#Elasticsearch-노드들-간의-TLS-설정" class="headerlink" title="Elasticsearch 노드들 간의 TLS 설정"></a>Elasticsearch 노드들 간의 TLS 설정</h2><p>Elasticsearch 6.0 부터는 X-Pack 설치 이후에는 기본적으로 노드들 간의 통신에 TLS를 설정 해 주어야 합니다. 그렇지 않으면 계속 해서 경고가 표시되고 심지어 기술지원 라이센스의 등록도 되지 않습니다.</p><p><img src="tls-warning.png" alt=""></p><h3 id="인증서-파일-생성"><a href="#인증서-파일-생성" class="headerlink" title="인증서 파일 생성"></a>인증서 파일 생성</h3><p>X-Pack은 이미 설치가 되어 있으니 이제 인증서 파일을 만들어 줍니다. 공인 인증기관으로부터 구매한 인증서가 있다면 사용하셔도 되고, X-Pack 에는 Elastic 에서 발행하는 사설 인증서를 생성하는 도구인 <code>certgen</code> 을 포함하고 있습니다. <code>certgen</code>에 대한 내용은 아래 링크를 참고하세요.<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.1/certgen.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.1/certgen.html</a></p><p>인증서를 생성하기 위해 설치 디렉토리로 가서 다음과 같은 명령을 실행합니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ]$ cd /usr/share/elasticsearch/</span><br><span class="line">[ ]$ sudo bin/x-pack/certgen</span><br><span class="line">This tool assists you in the generation of X.509 certificates and certificate</span><br><span class="line"></span><br><span class="line">... 중략 ...</span><br><span class="line"></span><br><span class="line">Let&apos;s get started...</span><br></pre></td></tr></table></figure><p>몇가지 질문이 나옵니다.<br>인증서 파일 세트를 담은 압축 파일은 <code>certificate-bundle.zip</code> 그대로 두겠습니다. 비워두고 그냥 엔터를 칩니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Please enter the desired output file [certificate-bundle.zip]:</span><br></pre></td></tr></table></figure></p><p>인증서 인스턴스 이름은 임의의 이름을 입력하면 됩니다. 여기서는 <code>es-demo</code> 라고 하겠습니다. <code>es-demo</code>를 입력하고 엔터를 칩니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Enter instance name: es-demo</span><br></pre></td></tr></table></figure></p><p>디렉토리, 파일 이름은 인증서 이름이랑 동일하게 하면 됩니다. 그냥 엔터를 칩니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Enter name for directories and files [es-demo]:</span><br></pre></td></tr></table></figure></p><p>인증서에 적용할 IP 주소들을 적습니다. 저희 노드를 설치한 서버들의 IP 주소들을 콤마로 구분해서 모두 적어줍니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Enter IP Addresses for instance (comma-separated if more than one) []: 192.168.0.10,192.168.0.11,192.168.0.12,192.168.0.13</span><br></pre></td></tr></table></figure></p><p>DNS는 없으니까 비워두겠습니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Enter DNS names for instance (comma-separated if more than one) []:</span><br></pre></td></tr></table></figure></p><p>추가 인증서는 만들지 않으니 <code>n</code>을 입력하고 엔터를 칩니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Would you like to specify another instance? Press &apos;y&apos; to continue entering instance information: n</span><br></pre></td></tr></table></figure></p><p>그럼 이제 <code>/usr/share/elasticsearch/certificate-bundle.zip</code> 경로에 인증서가 담긴 압축 파일이 생성됩니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Certificates written to /usr/share/elasticsearch/certificate-bundle.zip</span><br><span class="line">... 후략 ...</span><br></pre></td></tr></table></figure></p><p>이제 이 압축 파일을 <code>/usr/share/elasticsearch</code> 아래에 <code>cert</code> 라는 디렉토리를 만들고 이곳으로 옮겨 압축을 풀도록 하겠습니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ]$ sudo mkdir cert</span><br><span class="line">[ ]$ sudo mv certificate-bundle.zip ./cert</span><br><span class="line">[ ]$ cd cert/</span><br><span class="line">[ ]$ sudo unzip certificate-bundle.zip</span><br><span class="line">Archive:  certificate-bundle.zip</span><br><span class="line">   creating: ca/</span><br><span class="line">  inflating: ca/ca.crt</span><br><span class="line">  inflating: ca/ca.key</span><br><span class="line">   creating: es-demo/</span><br><span class="line">  inflating: es-demo/es-demo.crt</span><br><span class="line">  inflating: es-demo/es-demo.key</span><br></pre></td></tr></table></figure></p><p>압축을 풀면 <code>ca</code> 디렉토리 아래에 <code>ca.crt</code>, <code>ca.key</code> 파일, 그리고 <code>es-demo</code> 디렉토리 아래에 <code>es-demo.crt</code>, <code>es-demo.key</code> 파일, 총 4개의 파일이 생성됩니다.</p><h3 id="Elasticsearch-설정"><a href="#Elasticsearch-설정" class="headerlink" title="Elasticsearch 설정"></a>Elasticsearch 설정</h3><p>이제 인증서가 만들어 졌으니 elasticsearch 설정을 합니다. 설정은 아래 페이지를 참고하여 진행합니다.<br><a href="https://www.elastic.co/guide/en/x-pack/current/ssl-tls.html#enable-ssl" target="_blank" rel="noopener">https://www.elastic.co/guide/en/x-pack/current/ssl-tls.html#enable-ssl</a></p><p>코디네이션 노드의 <code>elasticsearcy.yml</code> 파일을 열고<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/elasticsearch/elasticsearch.yml</span><br></pre></td></tr></table></figure></p><p>아래와 같이 입력 해 줍니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xpack.ssl.key: /usr/share/elasticsearch/cert/es-demo/es-demo.key</span><br><span class="line">xpack.ssl.certificate: /usr/share/elasticsearch/cert/es-demo/es-demo.crt</span><br><span class="line">xpack.ssl.certificate_authorities: [ &quot;/usr/share/elasticsearch/cert/ca/ca.crt&quot; ]</span><br><span class="line"></span><br><span class="line">xpack.security.transport.ssl.enabled: true</span><br><span class="line">xpack.security.http.ssl.enabled: true</span><br></pre></td></tr></table></figure></p><p><code>xpack.security.http.ssl.enabled: true</code> 이 http SSL 설정 부분은 나중에는 다시 제거하겠으나 테스트를 위해 일단 지금은 설정을 하겠습니다.</p><p>데이터 노드들도 위와 동일하게 하는데 데이터 노드들은 http 기능을 잠궈 놓았기 때문에 <code>xpack.security.http.ssl.enabled: true</code> 이 부분은 입력하지 않도록 합니다.</p><p>이제 설정이 끝났으면 모든 노드들을 재시작 해 보겠습니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo service elasticsearch restart</span><br></pre></td></tr></table></figure></p><p>그리고 로그를 확인 해 보면… 오류가 납니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Caused by: java.security.AccessControlException: access denied (&quot;java.io.FilePermission&quot; &quot;/usr/share/elasticsearch/cert/ca/ca.crt&quot; &quot;read&quot;)</span><br></pre></td></tr></table></figure></p><p>지금 설치된 서버의 Java에 java.io.FilePermission 권한이 없어서 그렇습니다. 조금 귀찮은 작업을 좀 해야 하는데요, <code>java.policy</code> 파일 내용을 수정해야 합니다. 아래와 같이 <code>java.policy</code> 파일을 열고 (시스템 마다 설치 경로는 다를 수 있습니다.)<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /usr/lib/jvm/jre-1.8.0-openjdk.x86_64/lib/security/java.policy</span><br></pre></td></tr></table></figure></p><p><code>grant</code> 내부의 맨 아래 부분에 다음과 같이 추가 해 줍니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grant &#123;</span><br><span class="line">  ... 중략 ...</span><br><span class="line"></span><br><span class="line">        permission java.io.FilePermission &quot;&lt;&lt;ALL FILES&gt;&gt;&quot;, &quot;read&quot;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>이제 다시 한번 노드들을 재시작 하고 나면 정상적으로 실행 되는 것을 확인할 수 있습니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo service elasticsearch restart</span><br></pre></td></tr></table></figure></p><h3 id="SSL-확인"><a href="#SSL-확인" class="headerlink" title="SSL 확인"></a>SSL 확인</h3><p>코디네이트 노드가 있는 서버 콘솔에서 curl 로 접속을 해 보면<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ]$ curl http://172.31.27.193:9200</span><br><span class="line">curl: (52) Empty reply from server</span><br></pre></td></tr></table></figure></p><p>서버가 없다고 나옵니다. SSL을 적용 했기 때문에 http가 아닌 https 로 접속해야 합니다. https로 접속을 해 보면<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ]$ curl https://172.31.27.193:9200</span><br><span class="line">curl: (60) Peer&apos;s Certificate issuer is not recognized.</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>또 다시 아까와는 다른 오류 메시지가 나오는데, 제가 사용한 인증서가 사설 인증서라서 나오는 경고입니다. -k 옵션을 추가 해 주면 경고를 무시합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ]$ curl https://172.31.27.193:9200 -k</span><br><span class="line">&#123;&quot;error&quot;:&#123;&quot;root_cause&quot;:[&#123;&quot;type&quot;:&quot;security_exception&quot;,&quot;reason&quot;:&quot;missing authentication token for REST request [/]&quot;,&quot;header&quot;:&#123;&quot;WWW-Authenticate&quot;:&quot;Basic realm=\&quot;security\&quot; charset=\&quot;UTF-8\&quot;&quot;&#125;&#125;],&quot;type&quot;:&quot;security_exception&quot;,&quot;reason&quot;:&quot;missing authentication token for REST request [/]&quot;,&quot;header&quot;:&#123;&quot;WWW-Authenticate&quot;:&quot;Basic realm=\&quot;security\&quot; charset=\&quot;UTF-8\&quot;&quot;&#125;&#125;,&quot;status&quot;:401&#125;</span><br></pre></td></tr></table></figure></p><p>이제 조금 익숙한 화면이 나옵니다. -u 옵션으로 사용자 이름, 암호까지 넣어주면 이제 확인이 가능합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ]$ curl https://172.31.27.193:9200 -k -u elastic</span><br><span class="line">Enter host password for user &apos;elastic&apos;:</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot; : &quot;es-demo-service&quot;,</span><br><span class="line">  &quot;cluster_name&quot; : &quot;es-demo&quot;,</span><br><span class="line">  &quot;cluster_uuid&quot; : &quot;VLakkqSHynSuf0g&quot;,</span><br><span class="line">  &quot;version&quot; : &#123;</span><br><span class="line">    &quot;number&quot; : &quot;6.1.1&quot;,</span><br><span class="line">    &quot;build_hash&quot; : &quot;bd92e7f&quot;,</span><br><span class="line">    &quot;build_date&quot; : &quot;2017-12-17T20:23:25.338Z&quot;,</span><br><span class="line">    &quot;build_snapshot&quot; : false,</span><br><span class="line">    &quot;lucene_version&quot; : &quot;7.1.0&quot;,</span><br><span class="line">    &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,</span><br><span class="line">    &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;tagline&quot; : &quot;You Know, for Search&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>http SSL을 사용하려면 kibana 등에서도 <code>elasticsearch.url:</code> 값을 <code>https://...</code> 로 바꾸는 등 여러가지 설정을 해야 합니다. 그리고 지금 사용중인 인증서가 공인 기관의 인증서가 아닌 사설 인증서이기 때문에 elasticsearch에 REST API로 접속하는 프로그램들은 모두 인증서 경고에 대한 예외 처리를 히야 해서 손이 많이 가고, elasticsearch 코디네이트 노드와의 통신은 모두 같은 로컬 서버에서 이루어지기 때문에, http SSL 옵션은 다시 꺼 놓도록 하겠습니다.<br>코디네이션 노드의 <code>elasticsearcy.yml</code> 파일의 <code>xpack.security.http.ssl.enabled: true</code> 부분은 삭제 또는 주석처리 하도록 합니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/elasticsearch/elasticsearch.yml</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xpack.security.transport.ssl.enabled: true</span><br><span class="line">#xpack.security.http.ssl.enabled: true</span><br></pre></td></tr></table></figure><p>참고로, Kibana 의 Monitoring 화면을 확인 해 보면 아까 나타났었던 TLS 경고 문구가 사라져 있습니다.</p><h2 id="Kibana-SSL-설정"><a href="#Kibana-SSL-설정" class="headerlink" title="Kibana SSL 설정"></a>Kibana SSL 설정</h2><p>이제 Kibana에도 SSL을 설정 해 보도록 하겠습니다. 먼저 <code>kibana.yml</code> 파일을 열어서<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/kibana/kibana.yml</span><br></pre></td></tr></table></figure></p><p>아래 내용을 추가 해 줍니다. 중간에 잘 찾아 보면 주석 처리 된 부분이 있는데 이 부분을 풀고 수정 해도 됩니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server.ssl.enabled: true</span><br><span class="line">server.ssl.certificate: /usr/share/elasticsearch/cert/es-demo/es-demo.crt</span><br><span class="line">server.ssl.key: /usr/share/elasticsearch/cert/es-demo/es-demo.key</span><br></pre></td></tr></table></figure></p><p>이제 Kibana 를 재시작하고 나면<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo service kibana restart</span><br></pre></td></tr></table></figure></p><p>Kibana도 <code>https://서버주소:5601</code> 로 접속할 수 있습니다. 그런데 접속 해 보면 사설인증서를 알리는 경고창이 뜹니다.</p><p><img src="kibana-https.png" alt=""></p><p><code>고급</code> &gt; <code>예외 추가</code>를 눌러서 (브라우저 마다 다를 수 있습니다. 저는 FireFox Quantum을 씁니다.) 인증서를 허가 하면 이제 Kibana 화면이 나타납니다.</p><p><img src="kibana-https-done.png" alt=""></p><h2 id="Audit-감사-로그-설정"><a href="#Audit-감사-로그-설정" class="headerlink" title="Audit(감사) 로그 설정"></a>Audit(감사) 로그 설정</h2><p>X-Pack Security 에는 접속 및 사용 이력을 기록하는 감사 로그를 설정할 수 있습니다. 감사 로그 설정은 아래 문서를 참고해서 진행합니다.<br><a href="https://www.elastic.co/guide/en/x-pack/current/auditing.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/x-pack/current/auditing.html</a></p><p>감사 로그는 다음의 두가지 방법으로 기록할 수 있습니다. 둘 다 동시에 하는것도 가능합니다.</p><ol><li>elasticsearch 시스템 로그 파일에 기록</li><li>elasticsearch 인덱스 안에 도큐먼트로 색인</li></ol><p>저희는 2번째 방법처럼 elasticsearch 인덱스 안에 기록하도록 하겠습니다. <code>elasticsearcy.yml</code> 파일을 열고<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/elasticsearch/elasticsearch.yml</span><br></pre></td></tr></table></figure></p><p>아래 내용을 추가합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xpack.security.audit.enabled: true</span><br><span class="line">xpack.security.audit.outputs: [ &quot;index&quot; ]</span><br></pre></td></tr></table></figure></p><p>이제 elasticsearch를 재시작 하고 나면 이제부터 감사 로그가 <code>.security_audit_log-yyyy.mm.dd</code> 인덱스에 쌓이게 됩니다.</p><p>Kibana의 Dev Tool 에서<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -XGET &quot;http://서버주소:9200/.security_audit_log-*/_search&quot;</span><br></pre></td></tr></table></figure></p><p>로 확인이 가능합니다.</p><p>그런데 감사 로그는 기본적으로 모든 접속에 대한 이력을 쌓기 때문에 데이터가 쌓이는 속도가 어마무시 합니다. 가만히 있어도 .monitoring 이나 .watcher-history 같은 데이터와 같이 쌓이기 때문에 세밀하게 접속 정보를 모니터링 할게 아니라면 쌓이는데 필터링을 해 주는 것이 좋습니다.</p><p>오늘 포스트는 여기까지 해서 마치도록 하고 감사 로그의 추가적인 설정은 다음에 기회가 되면 또 다루어 보도록 하겠습니다. 다음 포스트에서는 X-Pack License 적용 및 사용자 생성에 대해 다루도록 하겠습니다.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><strong>6. X-Pack Security를 이용한 SSL 및 TLS 설정</strong><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;이번 포스트에서는 X-Pack Security를 이용한 보안 설정을 하도록 하겠습니다. 이전 또는 이후 내용들은 아래 포스트에서 확인하세요.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;/2018/01/2018-01-build-es-clu
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Elastic Cluster Settings" scheme="http://kimjmin.net/tags/Elastic-Cluster-Settings/"/>
    
      <category term="X-Pack" scheme="http://kimjmin.net/tags/X-Pack/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Cluster 구성 5</title>
    <link href="http://kimjmin.net/2018/01/2018-01-build-es-cluster-5/"/>
    <id>http://kimjmin.net/2018/01/2018-01-build-es-cluster-5/</id>
    <published>2018-01-04T15:00:00.000Z</published>
    <updated>2018-01-12T05:41:23.728Z</updated>
    
    <content type="html"><![CDATA[<p>원래 이번 포스트에서는 X-Pack Security를 다루려고 했으나 몇가지 구성을 먼저 추가하려고 합니다. 우선 NFS(Network File System)을 설정해서 모든 서버의 <code>/usr/share/elasticsearch</code> 디렉토리를 동기화 시키고 업그레이드나 플러그인 설치 등을 한번에 할 수 있도록 하겠습니다.</p><p>참고로 NFS 설정은 잘못하다가 설정이 꼬여버릴 수 있으니 주의하시고 설정을 원하지 않으면 다음 포스트로 넘어가시기 바랍니다.<br>(저도 설정 하다가 네트워크 디렉토리 퍼미션 설정 등 몇가지가 꼬여서 싹 밀고 처음부터 새로 설치했습니다.) 🤯</p><p>이전 또는 이후 내용들은 아래 포스트에서 확인하세요.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><strong>5. NFS 구성 및 elasticsearch 추가 설정</strong><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote><p>덧붙여 새벽에 페이스북에 달린 질문을 보고 잠시 고민이 되었습니다. 그리고 구성을 다음과 같이 데이터 노드 3개(마스터 겸임)와 코디네이트 노드(데이터를 저장하지 않고 애플리케이션과 통신만 담당하는, 클라이언트 노드 라고 부르기도 합니다) 노드로 바꾸기로 결정했습니다. 새로운 아키텍쳐의 구성은 다음과 같습니다.</p><p><img src="coordinate-node.png" alt=""></p><ul><li>데이터노드 1~3개 중 임의의 노드 하나가 마스터 노드를 겸하게 됩니다.</li><li>기존 마스터 노드는 코디네이트 노드로 Kibana 및 다른 애플리케이션과의 통신만 처리하게 됩니다.</li><li>코디네이트 노드는 다른 애플리케이션과 REST API를 사용합니다.(9200 포트)</li><li>코디네이트 노드와 데이터 노드들은 transport 프로토콜(9300 포트)로 데이터를 교환합니다.</li><li>데이터 노드들은 REST API를 사용하지 않도록 설정합니다. <code>http.enabled: false</code></li><li>코디네이트 노드 서버의 <code>/usr/share/elasticsearch</code> 디렉토리를 데이터 노드와 공유합니다.</li><li>보안그룹 1은 코디네이트 노드 서버에만 적용 되며 허가된 포트로만 외부 클라이언트와 통신이 가능합니다.</li><li>보안그룹 2는 모든 서버에 적용되며 이 그룹 안의 서버들 끼리는 자유롭게 통신이 가능합니다.</li></ul><h2 id="NFS-설정"><a href="#NFS-설정" class="headerlink" title="NFS 설정"></a>NFS 설정</h2><p>NFS 설정은 다음 포스트를 참고했습니다.<br><a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nfs-mount-on-centos-6" target="_blank" rel="noopener">https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nfs-mount-on-centos-6</a></p><p>편의상 코디네이트 노드를 서버, 데이터 노드 3대를 클라이언트 라고 표현 하겠습니다. 서버의 주소는 <code>192.168.0.10</code>, 클라이언트의 주소는 각각 <code>192.168.0.11</code>,<code>192.168.0.12</code>,<code>192.168.0.13</code> 이라고 가정 하겠습니다.<br>우선 저희 Amazon linux 서버에는 <code>nfs-utils</code>,<code>nfs-utils-lib</code> 가 이미 설치 되어 있습니다. 설치되어 있지 않다면 위 포스트를 참고해서 설치하시면 됩니다.</p><p>4개의 모든 서버에서 먼저 elasticsearch 서비스를 중지합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo service elasticsearch stop</span><br></pre></td></tr></table></figure></p><h3 id="usr-share-elasticsearch-공유-설정"><a href="#usr-share-elasticsearch-공유-설정" class="headerlink" title="/usr/share/elasticsearch 공유 설정"></a><code>/usr/share/elasticsearch</code> 공유 설정</h3><p>먼저 elasticsearch 프로그램들이 들어있는 <code>/usr/share/elasticsearch</code> 디렉토리 공유를 설정하겠습니다. 공유를 하는 목적은 업그레이드나 플러그인 설치 등을 각 서버별로 하지 않고 한번에 적용할 수 있도록 하기 위함입니다.</p><h4 id="서버"><a href="#서버" class="headerlink" title="서버"></a>서버</h4><p>서버에서 <code>/etc/exports</code> 파일을 열고<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/exports</span><br></pre></td></tr></table></figure></p><p>아래 내용을 추가합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/usr/share/elasticsearch  192.168.0.11(rw,sync,no_root_squash,no_subtree_check)</span><br><span class="line">/usr/share/elasticsearch  192.168.0.12(rw,sync,no_root_squash,no_subtree_check)</span><br><span class="line">/usr/share/elasticsearch  192.168.0.13(rw,sync,no_root_squash,no_subtree_check)</span><br></pre></td></tr></table></figure></p><p>그리고 설정을 적용 해 줍니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo exportfs -a</span><br></pre></td></tr></table></figure></p><h4 id="클라이언트"><a href="#클라이언트" class="headerlink" title="클라이언트"></a>클라이언트</h4><p>이제 클라이언트를 설정합니다. 3개 시스템에 모두 적용 해 줘야 합니다.<br>먼저 기존의 <code>/usr/share/elasticsearch</code> 를 삭제하고 빈 디렉토리로 다시 만듭니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo rm -rf /usr/share/elasticsearch</span><br><span class="line">sudo mkdir /usr/share/elasticsearch</span><br></pre></td></tr></table></figure></p><p>그리고 나서 서버의 네트워크 디렉토리를 마운트 해 줍니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo mount 192.168.0.10:/usr/share/elasticsearch /usr/share/elasticsearch</span><br></pre></td></tr></table></figure></p><p>시스템 재시작 후에도 공유 디렉토리가 유지되도록 <code>/etc/fstab</code> 파일에 다음 내용을 추가합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/fstab</span><br><span class="line">192.168.0.10:/usr/share/elasticsearch    /usr/share/elasticsearch  nfs     auto,noatime,nolock,bg,nfsvers=3,intr,tcp,actimeo=1800  0 0</span><br></pre></td></tr></table></figure></p><h3 id="etc-elasticsearch-공유-설정"><a href="#etc-elasticsearch-공유-설정" class="headerlink" title="/etc/elasticsearch 공유 설정"></a><code>/etc/elasticsearch</code> 공유 설정</h3><p>다음은 config 파일들이 들어있는 <code>/etc/elasticsearch</code> 디렉토리 공유를 설정하겠습니다. config 파일들은 코디네이터 노드와 데이터 노드들이 구분되어야 하기 때문에 데이터 노드들은 서버에 <code>/etc/elasticsearch-data</code> 라는 디렉토리를 새로 만들어 이 디렉토리와 공유되도록 하겠습니다.</p><h4 id="서버-1"><a href="#서버-1" class="headerlink" title="서버"></a>서버</h4><p>먼저 서버에서 기존 <code>/etc/elasticsearch</code> 디렉토리를 권한 그대로 <code>/etc/elasticsearch-data</code>로 복사합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo cp -pr /etc/elasticsearch /etc/elasticsearch-data</span><br></pre></td></tr></table></figure></p><p>다시 <code>/etc/exports</code> 파일을 열고<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/exports</span><br></pre></td></tr></table></figure></p><p>아래 내용을 추가합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/etc/elasticsearch-data  192.168.0.11(rw,sync,no_root_squash,no_subtree_check)</span><br><span class="line">/etc/elasticsearch-data  192.168.0.12(rw,sync,no_root_squash,no_subtree_check)</span><br><span class="line">/etc/elasticsearch-data  192.168.0.13(rw,sync,no_root_squash,no_subtree_check)</span><br></pre></td></tr></table></figure></p><p>그리고 설정을 실행 해 줍니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo exportfs -a</span><br></pre></td></tr></table></figure></p><h4 id="클라이언트-1"><a href="#클라이언트-1" class="headerlink" title="클라이언트"></a>클라이언트</h4><p>다시 클라이언트로(3개 모두 실행해야 합니다) 가서 기존의 <code>/etc/elasticsearch</code> 에 있는 파일들을 모두 삭제 해 줍니다. 루트 권한으로 들어가서 삭제 하는 것이 편합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo su</span><br><span class="line">cd /etc/elasticsearch</span><br><span class="line">rm -rf ./*</span><br><span class="line">exit</span><br></pre></td></tr></table></figure></p><p>서버의 <code>/etc/elasticsearch-data</code> 네트워크 디렉토리를 클라이언트의 <code>/etc/elasticsearch</code>로 마운트 해 줍니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo mount 192.168.0.10:/etc/elasticsearch-data /etc/elasticsearch</span><br></pre></td></tr></table></figure></p><p>시스템 재시작 후에도 NFS가 유지되도록 <code>/etc/fstab</code> 파일에 다음 내용을 추가합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/fstab</span><br><span class="line">192.168.0.10:/etc/elasticsearch-data  /etc/elasticsearch  nfs     auto,noatime,nolock,bg,nfsvers=3,intr,tcp,actimeo=1800  0 0</span><br></pre></td></tr></table></figure></p><blockquote><p>만약 재시작 후 데이터 노드에서 오류가 나면 기존 데이터 디렉토리를 삭제해야 합니다.<br>아직 운영 데이터는 없기를 바랍니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo rm -rf /var/lib/elasticsearch/*</span><br></pre></td></tr></table></figure></p><p>그리고 혹시 클라이언트에 X-Pack 같은 플러그인 설정 파일들이 없다면 서버의 마스터 설정 디렉토리 <code>/etc/elasticsearch</code> 에서 데이터 설정 디렉토리 <code>/etc/elasticsearch-data</code> 로 복사 해줘야 합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo cp -rp /etc/elasticsearch/elasticsearch.keystore /etc/elasticsearch-data/elasticsearch.keystore</span><br><span class="line">sudo cp -rp /etc/elasticsearch/x-pack /etc/elasticsearch-data/x-pack</span><br></pre></td></tr></table></figure></p><p>파일 접근 권한 때문에 데이터 노드들이 실행이 안 될수 있습니다. 데이터 노드들의 그룹 권한을 아래와 같이 elasticsearch로 설정 해 주어야 합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo chown -R root:elasticsearch /etc/elasticsearch</span><br></pre></td></tr></table></figure></p></blockquote><h2 id="elasticsearch-재설정"><a href="#elasticsearch-재설정" class="headerlink" title="elasticsearch 재설정"></a>elasticsearch 재설정</h2><p>이제 이전 포스트들을 참고 해서 <code>/etc/elasticsearch</code>,<code>/etc/elasticsearch-data</code> 안에 있는 설정 파일들을 데이터 노드 설정에 맞게 바꾸도록 합니다. 기존에 마스터 노드였던 노드는 코디네이터 노드로 다시 변경하겠습니다. 이후 모든 명령은 코디네이터 노드에서 실행 해 줍니다.</p><h3 id="Coordinate-Client-Node"><a href="#Coordinate-Client-Node" class="headerlink" title="Coordinate (Client) Node"></a>Coordinate (Client) Node</h3><p>먼저 코디네이트 노드의 메모리는 기존에 4GB 에서 2GB로 줄이도록 하겠습니다. 데이터 노드는 8GB 그대로 둡니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ]$ sudo vim /etc/elasticsearch/jvm.options</span><br><span class="line">-Xms2g</span><br><span class="line">-Xmx2g</span><br></pre></td></tr></table></figure></p><p>이제 코디네이트 노드의 <code>elasticsearch.yml</code> 설정을 변경합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/elasticsearch/elasticsearch.yml</span><br></pre></td></tr></table></figure></p><p>마스터 노드가 코디네이트 노드로 바뀌었기 때문에 unicast 설정도 데이터노드 3개의 아이피를 넣어줍니다. 코디네이트 노드와 데이터 노드 설정 파일 모두 적용해야 합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">discovery.zen.ping.unicast.hosts:</span><br><span class="line">  - 192.168.0.11</span><br><span class="line">  - 192.168.0.12</span><br><span class="line">  - 192.168.0.13</span><br></pre></td></tr></table></figure></p><p>다음은 코디네이트 노드의 마스터와 데이터 설정을 모두 비활성화 시킵니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">node.master: false</span><br><span class="line">node.data: false</span><br></pre></td></tr></table></figure></p><h3 id="Data-Node"><a href="#Data-Node" class="headerlink" title="Data Node"></a>Data Node</h3><p>데이터 노드의 <code>elasticsearch.yml</code> 설정을 변경합니다. 코디네이트 노드가 있는 서버에서 공유 디렉토리에 있는 설정 파일을 편집하면 됩니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/elasticsearch-data/elasticsearch.yml</span><br></pre></td></tr></table></figure></p><p>코디네이트 노드와 마찬가지로 unicast 설정을 데이터노드 3개의 아이피로 변경합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">discovery.zen.ping.unicast.hosts:</span><br><span class="line">  - 192.168.0.11</span><br><span class="line">  - 192.168.0.12</span><br><span class="line">  - 192.168.0.13</span><br></pre></td></tr></table></figure></p><p>기존의 <code>node.master: false</code> 부분은 삭제합니다.</p><p>마지막으로 데이터 노드들은 REST API를 사용하지 않도록 http 포트를 비활성화 시킵니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http.enabled: false</span><br></pre></td></tr></table></figure></p><p>이제 모든 설정이 끝났으면 서버들을 재시작 합니다. 개인적인 경험인데 한꺼번에 동시에 재시작 하니까 데이터노드 하나가 클러스터에 안 붙는 경우가 있었는데 그 서버만 다시 재시작 하면 정상적으로 붙습니다.</p><p>X-Pack 모니터링 화면에서 확인 해 보면 이번에는 데이터 노드 중 하나가 마스터를 겸하고 있고 기존의 마스터 노드는 계속 데이터를 저장하지 않는 코디네이트 노드로 남은 것을 확인할 수 있습니다.</p><p><img src="coordinate-monitoring.png" alt=""></p><p>이제 네트워크 파일 설정이 끝났으니 앞으로 환경 설정을 변경하거나 업그레이드, 패치 등을 할 때도 데이터 노드 서버에 접속할 일 없이 코디네이트 노드 서버에서 모든 것을 할 수 있게 되었습니다.</p><p>다음편에는 진짜로 X-Pack Security 설정을 다루도록 하겠습니다.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><strong>5. NFS 구성 및 elasticsearch 추가 설정</strong><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;원래 이번 포스트에서는 X-Pack Security를 다루려고 했으나 몇가지 구성을 먼저 추가하려고 합니다. 우선 NFS(Network File System)을 설정해서 모든 서버의 &lt;code&gt;/usr/share/elasticsearch&lt;/cod
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Elastic Cluster Settings" scheme="http://kimjmin.net/tags/Elastic-Cluster-Settings/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Cluster 구성 4</title>
    <link href="http://kimjmin.net/2018/01/2018-01-build-es-cluster-4/"/>
    <id>http://kimjmin.net/2018/01/2018-01-build-es-cluster-4/</id>
    <published>2018-01-03T15:00:00.000Z</published>
    <updated>2018-08-11T05:21:55.342Z</updated>
    
    <content type="html"><![CDATA[<p>이번 포스트에서는 Kibana 설치 및 X-Pack 설치를 하고 Monitoring을 통한 클러스터 상태를 확인 해 보도록 하겠습니다. 이전 또는 이후 내용들은 아래 포스트에서 확인하세요.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><strong>4. Kibana 설치 및 X-Pack Monitoring 확인</strong><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote><h2 id="Kibana-설치"><a href="#Kibana-설치" class="headerlink" title="Kibana 설치"></a>Kibana 설치</h2><p>다음 링크를 참고하여 Kibana 역시 yum 을 이용한 rpm 으로 설치하겠습니다.<br><a href="https://www.elastic.co/guide/en/kibana/current/rpm.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/current/rpm.html</a></p><p>Kibana도 elasticsearch와 마찬가지로 <code>/etc/yum.repos.d/</code> 디렉토리 아래에 <code>kibana.repo</code> 파일을 만들고 아래와 같이 내용을 입력합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[kibana-6.x]</span><br><span class="line">name=Kibana repository for 6.x packages</span><br><span class="line">baseurl=https://artifacts.elastic.co/packages/6.x/yum</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch</span><br><span class="line">enabled=1</span><br><span class="line">autorefresh=1</span><br><span class="line">type=rpm-md</span><br></pre></td></tr></table></figure></p><p>파일을 추가하고 나서 이제 yum을 이용해서 Kibana를 설치합니다. 오류가 나지 않도록 설치 된 elasticsearch 와 동일한 버전으로 설치합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install kibana -y</span><br></pre></td></tr></table></figure></p><p>마찬가지로 위와 같이 하면 최신 버전이 설치되고, 특정 버전을 설치하고 싶으면 다음과 같이 뒤에 버전을 명시 해 주면 됩니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install kibana-6.0.0 -y</span><br></pre></td></tr></table></figure></p><p>설치 문서에 나와 있는대로 <code>ps -p 1</code> 를 이용해서 SysV <code>init</code> 과 <code>systemd</code> 중 어떤 서비스를 사용하는지 확인합니다. 제가 만든 인스턴스는 init 을 사용하고 있습니다. 서비스에 등록하기 위해 다음 명령을 실행합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo chkconfig --add kibana</span><br></pre></td></tr></table></figure></p><p>이제 Kibana도 service 명령으로 실행 또는 종료가 가능합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo -i service kibana start</span><br><span class="line">sudo -i service kibana stop</span><br></pre></td></tr></table></figure></p><h2 id="Kibana-설정"><a href="#Kibana-설정" class="headerlink" title="Kibana 설정"></a>Kibana 설정</h2><p>Kibana RPM 버전의 기본적인 설치 경로들은 아래와 같습니다. 대부분의 설정이 <a href="/2018/01/2018-01-build-es-cluster-1/#Elasticsearch-설치">1. 서버 생성 및 Elasticsearch RPM 설치</a> 포스트에서 다루었던 Elasticsearch 설정과 유사합니다.</p><ul><li>기본 프로그램 (<strong>$KIBANA_HOME</strong>) : <code>/usr/share/kibana</code><ul><li>실행 파일 : <code>bin/kibana</code></li><li>플러그인 : <code>plugins</code></li></ul></li><li>설정 : <code>/etc/kibana/kibana.yml</code></li><li>데이터 (<strong>path.data</strong>) : <code>/var/lib/kibana</code></li><li>optimize : <code>/usr/share/kibana/optimize</code></li><li>로그 (<strong>path.logs</strong>) : <code>/var/log/kibana</code></li></ul><p>데이터와 로그 파일의 경로는 <code>/etc/kibana/kibana.yml</code> 설정 파일에서 수정이 가능합니다.<br>모든 경로에 접근하기 위해서는 기본적으로 root 권한을 필요로 합니다. 예를 들어 elasticsearch.yml 설정 파일을 vim 으로 편집하려고 하면 다음과 같이 실행해야 합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/kibana/kibana.yml</span><br></pre></td></tr></table></figure></p><h3 id="X-Pack-설치"><a href="#X-Pack-설치" class="headerlink" title="X-Pack 설치"></a>X-Pack 설치</h3><p>Kibana도 Elasticsearch 와 마찬가지로 X-Pack을 설치 해야 합니다. X-Pack 설치에 대한 내용은 아래 도큐먼트를 참고해서 진행합니다.<br><a href="https://www.elastic.co/guide/en/kibana/current/installing-xpack-kb.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/current/installing-xpack-kb.html</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ]$ cd /usr/share/kibana</span><br><span class="line">[ ]$ sudo bin/kibana-plugin install x-pack</span><br><span class="line">Attempting to transfer from https://artifacts.elastic.co/downloads/kibana-plugins/x-pack/x-pack-6.0.0.zip</span><br><span class="line">Transferring 120307264 bytes....................</span><br><span class="line">Transfer complete</span><br><span class="line">Retrieving metadata from plugin archive</span><br><span class="line">Extracting plugin archive</span><br><span class="line">Extraction complete</span><br><span class="line">Optimizing and caching browser bundles...</span><br><span class="line"></span><br><span class="line">Plugin installation complete</span><br></pre></td></tr></table></figure><p>패스워드는 Elasticsearch 에서 설정 했기 때문에 Kibana 에서는 따로 설정하지 않아도 됩니다.</p><h3 id="kibana-yml-설정"><a href="#kibana-yml-설정" class="headerlink" title="kibana.yml 설정"></a>kibana.yml 설정</h3><p>이제 Kibana 를 실행하고 실행 로그를 살펴보면…</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo service kibana start</span><br><span class="line">sudo tail -f /var/log/kibana/kibana.stdout</span><br></pre></td></tr></table></figure><p>아래와 같은 오류들이 나타납니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&quot;type&quot;:&quot;log&quot;,&quot;@timestamp&quot;:&quot;2018-01-02T07:09:36Z&quot;,&quot;tags&quot;:[&quot;warning&quot;,&quot;elasticsearch&quot;,&quot;admin&quot;],&quot;pid&quot;:3388,&quot;message&quot;:&quot;Unable to revive connection: http://localhost:9200/&quot;&#125;</span><br><span class="line">&#123;&quot;type&quot;:&quot;log&quot;,&quot;@timestamp&quot;:&quot;2018-01-02T07:09:36Z&quot;,&quot;tags&quot;:[&quot;warning&quot;,&quot;elasticsearch&quot;,&quot;admin&quot;],&quot;pid&quot;:3388,&quot;message&quot;:&quot;No living connections&quot;&#125;</span><br></pre></td></tr></table></figure></p><p>Elasticsearch와 정상적으로 통신을 하고, 외부에서 접근하기 위해 <code>kibana.yml</code>에 몇가지 설정을 추가해야 합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/kibana/kibana.yml</span><br></pre></td></tr></table></figure></p><p>먼저 Kibana 는 기본적으로 localhost:9200 을 통해 elasticsearch에 접근하도록 되어 있습니다. 저희는 앞에서 elasticsearch의 <code>network.host</code>를 실제 IP 주소로 수정했기 때문에 Kibana 역시 실제 IP 주소로 elasticsearch를 찾도록 <code>elasticsearch.url</code> 설정을 실제 IP 주소로 설정 해 주어야 합니다.</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">elasticsearch.url:</span> <span class="string">"http://192.168.0.10:9200"</span></span><br></pre></td></tr></table></figure><p>그리고 외부에서 접근하기 위해서는 <code>server.host</code> 도 실제 IP 주소로 수정해야 합니다.<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">server.host:</span> <span class="string">"192.168.0.10"</span></span><br></pre></td></tr></table></figure></p><p>그리고 X-Pack Security를 설치했기 때문에 Elasticsearch 에 접속을 위한 kibana 계정의 아이디와 패스워드도 입력합니다.<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">elasticsearch.username:</span> <span class="string">"kibana"</span></span><br><span class="line"><span class="string">elasticsearch.password:</span> <span class="string">"changeme"</span></span><br></pre></td></tr></table></figure></p><p>Kibana는 기본적으로 5601 포트를 사용합니다. (AWS의 경우) 외부에서 접근 가능하도록 보안 그룹에 5601 포트를 추가로 오픈 해 줍니다.</p><p><img src="kibana_sec_group.png" alt=""></p><p><code>kibana.yml</code>에 위 설정을을 추가하고 보안 그룹 설정을 마치면 Kibana 서비스를 재시작 합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ]$ sudo service kibana restart</span><br><span class="line">kibana stopped.</span><br><span class="line">kibana started</span><br></pre></td></tr></table></figure></p><h2 id="X-Pack-Monitoring-확인"><a href="#X-Pack-Monitoring-확인" class="headerlink" title="X-Pack Monitoring 확인"></a>X-Pack Monitoring 확인</h2><p>이제 웹브라우저를 열고 해당 <a href="http://서버주소:5601" target="_blank" rel="noopener">http://서버주소:5601</a> 로 접속을 하면 Kibana 로그인 화면이 나타납니다.</p><p><img src="kibana_login.png" alt=""></p><p>처음 X-Pack을 설치할 때 만들었던 아이디와 패스워드를 가지고 로그인을 합니다. 로그인 뒤에 왼쪽의 Monitoring 메뉴를 클릭 해 보면 현재 시스템 상태를 확인 해 볼 수 있습니다. </p><p><img src="monitoring-1.png" alt=""></p><p><code>Nodes</code>를 클릭해서 들어가 보면 ★ 표시가 된 마스터 노드, 그리고 데이터 노드들이 보이고, 마스터 노드에는 데이터가 저장되지 않은 것을 확인할 수 있습니다.</p><p><img src="monitoring-2.png" alt=""></p><p>지금까지 Kibana 설치 및 X-Pack Monitoring 사용에 대해 살펴 보았습니다.<br>다음 포스트에서는 X-Pack Security 설정을 통해 클라이언트 및 노드들 간의 통신을 암호화 하는 방법에 대해 살펴보도록 하겠습니다.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><strong>4. Kibana 설치 및 X-Pack Monitoring 확인</strong><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;이번 포스트에서는 Kibana 설치 및 X-Pack 설치를 하고 Monitoring을 통한 클러스터 상태를 확인 해 보도록 하겠습니다. 이전 또는 이후 내용들은 아래 포스트에서 확인하세요.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;/2
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Elastic Cluster Settings" scheme="http://kimjmin.net/tags/Elastic-Cluster-Settings/"/>
    
      <category term="X-Pack" scheme="http://kimjmin.net/tags/X-Pack/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Cluster 구성 3</title>
    <link href="http://kimjmin.net/2018/01/2018-01-build-es-cluster-3/"/>
    <id>http://kimjmin.net/2018/01/2018-01-build-es-cluster-3/</id>
    <published>2018-01-02T15:00:00.000Z</published>
    <updated>2018-01-12T05:41:22.018Z</updated>
    
    <content type="html"><![CDATA[<p>이번 포스트에서는 클러스터 구성 및 마스터, 데이터 노드 설정에 대해서 다루도록 하겠습니다. 이전 또는 이후 내용들은 아래 포스트에서 확인하세요.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><strong>3. 클러스터 구성 및 마스터, 데이터 노드 설정</strong><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote><h2 id="데이터-노드-추가"><a href="#데이터-노드-추가" class="headerlink" title="데이터 노드 추가"></a>데이터 노드 추가</h2><p>앞의 두 포스트에서 Elasticsearch 서버 설치를 완료 했습니다. 4개 서버로 구성된 클러스터를 만들기 위해서는 앞의 내용대로 서버를 하나씩 만드는 방법도 있겠지만, AWS 에는 서버의 이미지 스냅샷을 찍어 그 이미지를 기준으로 새로운 서버를 만드는 기능이 있어 저는 그 방법을 이용하도록 하겠습니다.</p><p>먼저 앞서 만든 인스턴스의 이미지를 저장합니다.</p><p><img src="snapshot_save.png" alt=""></p><p>이제 새로운 인스턴스를 생성할 때 저장 해 놓은 이미지를 가지고 생성을 합니다.</p><p><img src="snapshot_create.png" alt=""></p><p>새 서버들이 완성되면 이 서버들 끼리는 통신이 가능하도록 보안 그룹을 설정 해 주어야 합니다.<br>보안 그룹을 하나 만들고 나서 소스에 해당 보안 그룹의 id를 적으면 그 보안그룹에 소속된 인스턴스 끼리 자유롭게 통신이 가능합니다. </p><p><img src="security_rule.png" alt=""></p><p>저는 아래와 같이 보안 그룹을 2개를 만들어 한 그룹에는 4개 인스턴스 전체를, 한 그룹은 마스터 노드가 속해 있는 인스턴스를 할당해서 일부 포트만 오픈 했습니다. 이렇게 하면 4개의 노드들은 자유롭게 데이터를 주고받을 수 있고, 외부에서 접속하기 위해서는 마스터 노드를 통해서만 접근이 가능합니다.</p><p><img src="security_architecture.png" alt=""></p><p>이제 설정을 완료 한 뒤에 추가한 3개의 노드들을 차례로 실행시키면서 마스터 노드의 로그를 살펴보면…</p><p>노드 바인딩이 되지 않습니다. 추가한 노드들의 로그를 살펴보면 아래와 같은 에러 로그들이 보입니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[2017-12-29T08:17:53,144][INFO ][o.e.d.z.ZenDiscovery     ] [es-master] failed to send join request to master </span><br><span class="line">[&#123;es-master&#125;&#123;KTKlgNlqllbkaw&#125;&#123;7QMJWBW40MIw&#125;&#123;192.168.0.10&#125;&#123;192.168.0.10:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125;], </span><br><span class="line">reason [RemoteTransportException[[es-master][192.168.0.10:9300][internal:discovery/zen/join]]; </span><br><span class="line">nested: IllegalArgumentException[can&apos;t add node &#123;es-master&#125;&#123;KTKlgNlqllbkaw&#125;&#123;7QMJWBW40MIw&#125;&#123;192.168.0.11&#125;&#123;192.168.0.11:9300&#125;</span><br><span class="line">&#123;ml.max_open_jobs=10, ml.enabled=true&#125;, found existing node &#123;es-master&#125;&#123;KTKlgNlqllbkaw&#125;&#123;7QMJWBW40MIw&#125;&#123;192.168.0.10&#125;&#123;192.168.0.10:9300&#125;</span><br><span class="line">&#123;ml.max_open_jobs=10, ml.enabled=true&#125; with the same id but is a different node instance]; ]</span><br></pre></td></tr></table></figure><p>아마 이미지를 복사하지 않고 하나씩 만들었다면 위와 같은 로그가 나타나지 않을 것입니다. 처음 저장한 이미지에서 elasticsearch의 path.data 경로에 이미 생성된 노드의 정보가 있어서 오류가 난 것입니다. 추가한 노드들에서는 이 데이터들을 먼저 삭제 한 후에 실행을 해야 합니다.</p><p>데이터 노드를 추가한 뒤에 먼저 다음 설정들을 진행합니다.</p><ul><li><p>서비스 중지</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo service elasticsearch stop</span><br></pre></td></tr></table></figure></li><li><p>데이터 디렉토리 삭제</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo rm -rf /var/lib/elasticsearch/nodes</span><br></pre></td></tr></table></figure></li><li><p>호스트 네임 변경: 노드 이름이 호스트명으로 할당되도록 설정되어 있으므로, 각 데이터 노드들의 호스트명을 해당 노드에 맞게 바꿔줍니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/sysconfig/network</span><br><span class="line">HOSTNAME=es-data-1</span><br></pre></td></tr></table></figure></li><li><p>이제 서버를 재시작 합니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo reboot</span><br></pre></td></tr></table></figure></li></ul><p>데이터 노드를 하나씩 재실행 시키면서 마스터 노드의 로그를 보면 노드가 하나씩 바인딩 되는 것을 확인할 수 있습니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[2018-01-02T05:57:55,000][INFO ][o.e.c.s.MasterService    ] [es-master] zen-disco-node-join[&#123;es-data-1&#125;&#123;OgBrTj6zQ&#125;&#123;WTWfWw3w&#125;&#123;192.168.0.3&#125;&#123;192.168.0.3:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125;], reason: added &#123;&#123;es-data-1&#125;&#123;OgBrTj6zQ&#125;&#123;WTWfWw3w&#125;&#123;192.168.0.3&#125;&#123;192.168.0.3:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125;,&#125;</span><br><span class="line">[2018-01-02T05:57:55,937][INFO ][o.e.c.s.ClusterApplierService] [es-master] added &#123;&#123;es-data-1&#125;&#123;OgBrTj6zQ&#125;&#123;WTWfWw3w&#125;&#123;192.168.0.3&#125;&#123;192.168.0.3:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125;,&#125;, reason: apply cluster state (from master [master &#123;es-master&#125;&#123;KTKlgNlqRcKqfyzLllbkaw&#125;&#123;AcalEOAwS-OHeQYQm_qq1Q&#125;&#123;192.168.0.1&#125;&#123;192.168.0.1:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125; committed version [13] source [zen-disco-node-join[&#123;es-data-1&#125;&#123;OgBrTj6zQ&#125;&#123;WTWfWw3w&#125;&#123;192.168.0.3&#125;&#123;192.168.0.3:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125;]]])</span><br><span class="line"></span><br><span class="line">[2018-01-02T05:58:51,582][INFO ][o.e.c.s.MasterService    ] [es-master] zen-disco-node-join[&#123;es-data-2&#125;&#123;9lSNRqQ&#125;&#123;XqoDP-1g&#125;&#123;192.168.0.2&#125;&#123;192.168.0.2:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125;], reason: added &#123;&#123;es-data-2&#125;&#123;9lSNRqQ&#125;&#123;XqoDP-1g&#125;&#123;192.168.0.2&#125;&#123;192.168.0.2:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125;,&#125;</span><br><span class="line">[2018-01-02T05:58:52,286][INFO ][o.e.c.s.ClusterApplierService] [es-master] added &#123;&#123;es-data-2&#125;&#123;9lSNRqQ&#125;&#123;XqoDP-1g&#125;&#123;192.168.0.2&#125;&#123;192.168.0.2:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125;,&#125;, reason: apply cluster state (from master [master &#123;es-master&#125;&#123;KTKlgNlqRcKqfyzLllbkaw&#125;&#123;AcalEOAwS-OHeQYQm_qq1Q&#125;&#123;192.168.0.1&#125;&#123;192.168.0.1:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125; committed version [26] source [zen-disco-node-join[&#123;es-data-2&#125;&#123;9lSNRqQ&#125;&#123;XqoDP-1g&#125;&#123;192.168.0.2&#125;&#123;192.168.0.2:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125;]]])</span><br><span class="line"></span><br><span class="line">[2018-01-02T05:59:27,587][INFO ][o.e.c.s.MasterService    ] [es-master] zen-disco-node-join[&#123;es-data-3&#125;&#123;3OLGwIZQ&#125;&#123;wjDTfuTA&#125;&#123;192.168.0.4&#125;&#123;192.168.0.4:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125;], reason: added &#123;&#123;es-data-3&#125;&#123;3OLGwIZQ&#125;&#123;wjDTfuTA&#125;&#123;192.168.0.4&#125;&#123;192.168.0.4:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125;,&#125;</span><br><span class="line">[2018-01-02T05:59:28,562][INFO ][o.e.c.s.ClusterApplierService] [es-master] added &#123;&#123;es-data-3&#125;&#123;3OLGwIZQ&#125;&#123;wjDTfuTA&#125;&#123;192.168.0.4&#125;&#123;192.168.0.4:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125;,&#125;, reason: apply cluster state (from master [master &#123;es-master&#125;&#123;KTKlgNlqRcKqfyzLllbkaw&#125;&#123;AcalEOAwS-OHeQYQm_qq1Q&#125;&#123;192.168.0.1&#125;&#123;192.168.0.1:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125; committed version [36] source [zen-disco-node-join[&#123;es-data-3&#125;&#123;3OLGwIZQ&#125;&#123;wjDTfuTA&#125;&#123;192.168.0.4&#125;&#123;192.168.0.4:9300&#125;&#123;ml.max_open_jobs=10, ml.enabled=true&#125;]]])</span><br></pre></td></tr></table></figure><h2 id="configuration-설정"><a href="#configuration-설정" class="headerlink" title="configuration 설정."></a>configuration 설정.</h2><p>클러스터 구성이 완료 되었으니 이제 각 노드별로 상이한 옵션들을 설정 하겠습니다.<br>먼저 마스터 노드의 Java Heap 메모리는 4gb로 조정합니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/elasticsearch/jvm.options</span><br><span class="line"></span><br><span class="line">-Xms4g</span><br><span class="line">-Xmx4g</span><br></pre></td></tr></table></figure><p>마스터 노드는 데이터를 저장하지 않도록 <code>elasticsearch.yml</code> 에서 <code>node.master: true</code>, <code>node.data: false</code> 를 추가합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/elasticsearch/elasticsearch.yml</span><br><span class="line"></span><br><span class="line">node.master: true</span><br><span class="line">node.data: false</span><br></pre></td></tr></table></figure></p><p>각 데이터 노드들은 반대로 <code>node.master: false</code>, <code>node.data: true</code> 를 추가합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/elasticsearch/elasticsearch.yml</span><br><span class="line"></span><br><span class="line">node.master: false</span><br><span class="line">node.data: true</span><br></pre></td></tr></table></figure></p><p>이제 모든 노드들의 서비스 또는 서버를 재 시작합니다.</p><p><img src="reboot_all.png" alt=""></p><p>지금까지 클러스터 구성 및 마스터, 데이터 노드 설정에 대해 살펴보았습니다.<br>다음 포스트에서는 Kibana를 설치하고 클러스터에 데이터들이 저희 구상대로 정상적으로 분배 되었는지 X-Pack Monitoring 을 통해서 확인 해 보도록 하겠습니다.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><strong>3. 클러스터 구성 및 마스터, 데이터 노드 설정</strong><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;이번 포스트에서는 클러스터 구성 및 마스터, 데이터 노드 설정에 대해서 다루도록 하겠습니다. 이전 또는 이후 내용들은 아래 포스트에서 확인하세요.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;/2018/01/2018-01-build-es-
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Elastic Cluster Settings" scheme="http://kimjmin.net/tags/Elastic-Cluster-Settings/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Cluster 구성 2</title>
    <link href="http://kimjmin.net/2018/01/2018-01-build-es-cluster-2/"/>
    <id>http://kimjmin.net/2018/01/2018-01-build-es-cluster-2/</id>
    <published>2018-01-01T15:00:00.000Z</published>
    <updated>2018-08-11T05:21:26.286Z</updated>
    
    <content type="html"><![CDATA[<p>이번 포스트에서는 네트워크 설정 및 플러그인 설치에 대해서 다루도록 하도록 하겠습니다. 이전 또는 이후 내용들은 아래 포스트에서 확인하세요.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><strong>2. 메모리, 네트워크 설정 및 플러그인 설치</strong><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote><h2 id="Java-Heap-메모리-설정"><a href="#Java-Heap-메모리-설정" class="headerlink" title="Java Heap 메모리 설정."></a>Java Heap 메모리 설정.</h2><p>Java Heap 메모리는 <code>jvm.options</code> 파일에서 설정합니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/elasticsearch/jvm.options</span><br></pre></td></tr></table></figure><p>마스터 노드는 4GB, 데이터 노드는 8GB로 각각 설정을 할 예정입니다. 여기서는 우선 8GB로 설정 합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-Xms8g</span><br><span class="line">-Xmx8g</span><br></pre></td></tr></table></figure></p><p>Java Heap 외에 시스템 메모리의 절반은 루씬 파일 캐시를 위해 남겨둬야 합니다. 자세한 설명이 아래 블로그들에 나와 있으니 한번은 꼭 읽어보도록 권해 드립니다.</p><ul><li><a href="https://www.elastic.co/kr/blog/performance-considerations-elasticsearch-indexing" target="_blank" rel="noopener">Elasticsearch 인덱싱에 대한 성능 고려 사항</a></li><li><a href="https://www.elastic.co/kr/blog/performance-indexing-2-0" target="_blank" rel="noopener">Elasticsearch 2.0 인덱싱 성능 고려사항</a></li><li><a href="https://www.elastic.co/blog/a-heap-of-trouble" target="_blank" rel="noopener">A Heap of Trouble: Managing Elasticsearch’s Managed Heap</a></li></ul><h2 id="네트워크-설정"><a href="#네트워크-설정" class="headerlink" title="네트워크 설정"></a>네트워크 설정</h2><p>네트워크 설정은 <code>elasticsearch.yml</code> 설정 파일의 <code>network.host</code> 부분을 수정합니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/elasticsearch/elasticsearch.yml</span><br></pre></td></tr></table></figure><p>보통은 <code>network.host: 192.168.0.1</code> 과 같은 형식으로 IP 주소를 직접 입력해도 되지만, 더 간편하게 <code>_local_</code>, <code>_site_</code>, <code>_global_</code> 같은 값 들을 이용할 수도 있습니다. 저희 서버는 아래와 같이 설정하였습니다.</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">network.host:</span> <span class="string">_site_</span></span><br></pre></td></tr></table></figure><p>network.host 의 값들에 대해서는 아래 페이지를 참고하시기 바랍니다.<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.1/modules-network.html#network-interface-values" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.1/modules-network.html#network-interface-values</a></p><h2 id="Bootstrap-Check"><a href="#Bootstrap-Check" class="headerlink" title="Bootstrap Check"></a>Bootstrap Check</h2><p>기본적으로 아래 문서에 나와있는 설정들은 모두 확인 하도록 합니다.<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.1/important-settings.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.1/important-settings.html</a></p><h3 id="bootstrap-memory-lock-활성"><a href="#bootstrap-memory-lock-활성" class="headerlink" title="bootstrap.memory_lock 활성"></a>bootstrap.memory_lock 활성</h3><p><code>elasticsearch.yml</code> 설정 파일에서 <code>bootstrap.memory_lock</code> 을 활성화 합니다.</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">bootstrap.memory_lock:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>설정 후 elasticsearch를 재시작하면 실행에 실패하는 경우가 있습니다. 시스템 로그를 보면 친절하게 어떻게 설정을 해 줘야 하는지 안내하고 있습니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[2017-12-29T06:16:43,809][WARN ][o.e.b.JNANatives         ] Unable to lock JVM Memory: error=12, reason=Cannot allocate memory</span><br><span class="line">[2017-12-29T06:16:43,811][WARN ][o.e.b.JNANatives         ] This can result in part of the JVM being swapped out.</span><br><span class="line">[2017-12-29T06:16:43,811][WARN ][o.e.b.JNANatives         ] Increase RLIMIT_MEMLOCK, soft limit: 65536, hard limit: 65536</span><br><span class="line">[2017-12-29T06:16:43,812][WARN ][o.e.b.JNANatives         ] These can be adjusted by modifying /etc/security/limits.conf, for example:</span><br><span class="line"># allow user &apos;elasticsearch&apos; mlockall</span><br><span class="line">elasticsearch soft memlock unlimited</span><br><span class="line">elasticsearch hard memlock unlimited</span><br><span class="line">[2017-12-29T06:16:43,812][WARN ][o.e.b.JNANatives         ] If you are logged in interactively, you will have to re-login for the new limits to take effect.</span><br><span class="line">...</span><br><span class="line">[1] bootstrap checks failed</span><br><span class="line">[1]: memory locking requested for elasticsearch process but memory is not locked</span><br></pre></td></tr></table></figure><p><code>/etc/security/limits.conf</code> 파일을 열고<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/security/limits.conf</span><br></pre></td></tr></table></figure></p><p><code>elasticsearch soft memlock unlimited</code>, <code>elasticsearch hard memlock unlimited</code> 내용을 추가 해 줍니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">#ftp             hard    nproc           0</span><br><span class="line">#@student        -       maxlogins       4</span><br><span class="line"></span><br><span class="line">elasticsearch soft memlock unlimited</span><br><span class="line">elasticsearch hard memlock unlimited</span><br><span class="line"></span><br><span class="line"># End of file</span><br></pre></td></tr></table></figure></p><h3 id="Unicast-설정"><a href="#Unicast-설정" class="headerlink" title="Unicast 설정"></a>Unicast 설정</h3><p>다른 노드들이 마스터 노드와 연결될 수 있도록 <code>discovery.zen.ping.unicast.hosts</code> 부분을 마스터노드의 ip 주소로 입력 해 줍니다. 네트워크 주소는 <code>ifconfig</code> 또는 <code>ip addr</code> 명령으로 확인합니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">discovery.zen.ping.unicast.hosts:</span><br><span class="line">  - 192.168.1.10:9300</span><br></pre></td></tr></table></figure><p>위 예문에는 <code>192.168.1.10</code> 이라고 적었지만, 실제로 설치된 서버의 IP 주소를 적으면 됩니다.</p><h3 id="⚠️-Split-Brain-문제"><a href="#⚠️-Split-Brain-문제" class="headerlink" title="⚠️ Split Brain 문제"></a>⚠️ Split Brain 문제</h3><p>저는 마스터 노드를 1개만 운영 할 것이기 때문에 <code>discovery.zen.minimum_master_nodes</code> 설정은 따로 하지 않았습니다.</p><p>보통 노드가 10개 내의 클러스터는 마스터 노드를 따로 구분하지 않고 데이터 노드 중 임의의 노드가 마스터 역할을 병행해서 수행하도록 해도 큰 문제는 없습니다. 10개 이상의 노드로 구성된 클러스터인 경우 마스터 전용 노드와 데이터 전용 노드를 분리하는 것이 좋으며, 이 때 마스터 기능의 수행이 가능한 후보(master-eligible) 노드를 3(또는 그 이상의 홀수)개를 두어 실제 마스터 노드가 다운된 경우 다른 노드가 그 역할을 대신 할 수 있도록 합니다. 2개만 두는 경우에는 네트워크 단절로 인한 클러스터 분리 문제 (quorum)로 인해 하나의 클러스터가 서로 다른 마스터를 가진 2개의 클러스터로 나누어 져서 나중에 동기화 문제가 생길 수 있습니다. 이를 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.1/modules-node.html#split-brain" target="_blank" rel="noopener">Split Brain</a> 이라고 합니다.</p><p>마스터 후보 노드를 3개(또는 그 이상의 홀수)로 두는 경우에는 네트워크 단절로 인해 클러스터가 분리가 되면 마스터 후보가 2개인 클러스터만 실제로 동작하고 1개인 클러스터는 동작을 멈추게 됩니다. 그렇게 해서 다시 네트워크가 복구 되었을 때 활성 상태였던 클러스터 노드들의 업데이트 정보가 비활성 상태였던 클러스터 노드들로 자연스럽게 동기화가 될 수 있습니다.</p><h2 id="X-Pack-설치"><a href="#X-Pack-설치" class="headerlink" title="X-Pack 설치"></a>X-Pack 설치</h2><p>X-Pack 설치에 대한 내용은 아래 도큐먼트를 참고해서 진행합니다.<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/installing-xpack-es.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/installing-xpack-es.html</a></p><h3 id="X-Pack-플러그인-설치"><a href="#X-Pack-플러그인-설치" class="headerlink" title="X-Pack 플러그인 설치"></a>X-Pack 플러그인 설치</h3><p>elasticsearch 가 설치된 디렉토리에서 <code>bin/elasticsearch-plugin install x-pack</code> 명령으로 설치가 가능합니다. X-Pack 그리고 대부분의 플러그인들은 모든 노드들에 동일하게 설치가 되어 있어야 합니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ]$ cd /usr/share/elasticsearch</span><br><span class="line">[ ]$ sudo bin/elasticsearch-plugin install x-pack</span><br><span class="line">-&gt; Downloading x-pack from elastic</span><br><span class="line">[=================================================] 100%</span><br><span class="line">@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span><br><span class="line">@     WARNING: plugin requires additional permissions     @</span><br><span class="line">@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span><br><span class="line">* java.io.FilePermission \\.\pipe\* read,write</span><br><span class="line">* java.lang.RuntimePermission accessClassInPackage.com.sun.activation.registries</span><br><span class="line">* java.lang.RuntimePermission getClassLoader</span><br><span class="line">* java.lang.RuntimePermission setContextClassLoader</span><br><span class="line">* java.lang.RuntimePermission setFactory</span><br><span class="line">* java.net.SocketPermission * connect,accept,resolve</span><br><span class="line">* java.security.SecurityPermission createPolicy.JavaPolicy</span><br><span class="line">* java.security.SecurityPermission getPolicy</span><br><span class="line">* java.security.SecurityPermission putProviderProperty.BC</span><br><span class="line">* java.security.SecurityPermission setPolicy</span><br><span class="line">* java.util.PropertyPermission * read,write</span><br><span class="line">* java.util.PropertyPermission sun.nio.ch.bugLevel write</span><br><span class="line">See http://docs.oracle.com/javase/8/docs/technotes/guides/security/permissions.html</span><br><span class="line">for descriptions of what these permissions allow and the associated risks.</span><br><span class="line"></span><br><span class="line">Continue with installation? [y/N]y</span><br><span class="line">@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span><br><span class="line">@        WARNING: plugin forks a native controller        @</span><br><span class="line">@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span><br><span class="line">This plugin launches a native controller that is not subject to the Java</span><br><span class="line">security manager nor to system call filters.</span><br><span class="line"></span><br><span class="line">Continue with installation? [y/N]y</span><br><span class="line">Elasticsearch keystore is required by plugin [x-pack], creating...</span><br><span class="line">-&gt; Installed x-pack</span><br></pre></td></tr></table></figure><h3 id="X-Pack-Security-패스워드-설정"><a href="#X-Pack-Security-패스워드-설정" class="headerlink" title="X-Pack Security 패스워드 설정"></a>X-Pack Security 패스워드 설정</h3><p>5.x 에서는 기본적으로 슈퍼유저 계정인 elastic에 패스워드 changeme 가 기본적으로 생성되었으나, 6.0 부터는 기본 패스워드가 생성되지 않습니다. X-Pack 설치 이후에는 바로 <code>setup-passwords</code> 프로그램을 이용해서 주요 시스템 계정인 <code>elastic</code>, <code>kibana</code>, <code>logstash_system</code>의 패스워드를 생성 해 줘야 합니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ]$ cd /usr/share/elasticsearch</span><br><span class="line">[ ]$ sudo bin/x-pack/setup-passwords interactive</span><br><span class="line">Initiating the setup of reserved user elastic,kibana,logstash_system passwords.</span><br><span class="line">You will be prompted to enter passwords as the process progresses.</span><br><span class="line">Please confirm that you would like to continue [y/N]y</span><br><span class="line"></span><br><span class="line">Enter password for [elastic]:</span><br><span class="line">Reenter password for [elastic]:</span><br><span class="line">Enter password for [kibana]:</span><br><span class="line">Reenter password for [kibana]:</span><br><span class="line">Enter password for [logstash_system]:</span><br><span class="line">Reenter password for [logstash_system]:</span><br><span class="line">Changed password for user [kibana]</span><br><span class="line">Changed password for user [logstash_system]</span><br><span class="line">Changed password for user [elastic]</span><br><span class="line">[ ]$</span><br></pre></td></tr></table></figure><h3 id="SSL-TLS"><a href="#SSL-TLS" class="headerlink" title="SSL/TLS"></a>SSL/TLS</h3><p>X-Pack Security는 노드간, 그리고 클러스터와 클라이언트 간의 통신을 암호화 하는 SSL/TLS 기능을 가지고 있습니다. 특히 elasticsearch 6.0 부터는 X-Pack Security를 사용하기 위해서는 SSL/TLS 설정을 반드시 활성화 해야 오류나 경고 메시지가 나타나지 않습니다.<br>SSL/TLS 설정은 다음 포스트에서 클러스터의 모든 노드들의 생성이 끝난 뒤에 설정 하도록 하겠습니다.</p><h2 id="한글-형태소-분석기-설치"><a href="#한글-형태소-분석기-설치" class="headerlink" title="한글 형태소 분석기 설치"></a>한글 형태소 분석기 설치</h2><p>아래 블로그 포스트 또는 각 커뮤니티의 문서를 참고해서 설치하도록 합니다.<br>아리랑 : <a href="https://www.elastic.co/kr/blog/arirang-analyzer-with-elasticsearch" target="_blank" rel="noopener">https://www.elastic.co/kr/blog/arirang-analyzer-with-elasticsearch</a></p><p>정상적으로 설치가 되면 elasticsearch를 재시작 후 로그에 다음과 같이 플러그인이 나타납니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[2017-12-29T07:18:31,240][INFO ][o.e.p.PluginsService     ] [kr-demo-master] loaded plugin [analysis-arirang]</span><br></pre></td></tr></table></figure></p><p>여기까지 Elasticsearch의 공통적인 설치 및 설정들이 완료되었습니다.<br>다음 포스트에서는 지금까지 만든 설정들을 복사해서 1개의 마스터 노드와 3개의 데이터 노드 시스템을 생성하고, 각 노드별로 구분되어야 할 환경들을 설정 해 보도록 하겠습니다.</p><blockquote><p><a href="/2018/01/2018-01-build-es-cluster-1">1. 서버 생성 및 Elasticsearch RPM 설치</a><br><strong>2. 메모리, 네트워크 설정 및 플러그인 설치</strong><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;이번 포스트에서는 네트워크 설정 및 플러그인 설치에 대해서 다루도록 하도록 하겠습니다. 이전 또는 이후 내용들은 아래 포스트에서 확인하세요.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;/2018/01/2018-01-build-es-clu
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Elastic Cluster Settings" scheme="http://kimjmin.net/tags/Elastic-Cluster-Settings/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Cluster 구성 1</title>
    <link href="http://kimjmin.net/2018/01/2018-01-build-es-cluster-1/"/>
    <id>http://kimjmin.net/2018/01/2018-01-build-es-cluster-1/</id>
    <published>2017-12-31T15:00:00.000Z</published>
    <updated>2018-08-11T05:20:45.851Z</updated>
    
    <content type="html"><![CDATA[<p>이번에 필요에 의해 새로 Elastic Stack 클러스터를 구성하게 되었습니다. 구성 방법에 대해서는 여러 레퍼런스가 있지만, 처음부터 다시 한번 쭉 정리 할 생각으로 블로그 포스트에 시리즈로 작성하려고 합니다.</p><blockquote><p><strong>1. 서버 생성 및 Elasticsearch RPM 설치</strong><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote><p>구성은 최대한 실제 서비스 되는 구성에 가깝게 설치 해 볼 예정입니다. 개략적인 컨셉 아키텍쳐는 다음과 같습니다.</p><p><img src="es-demo-architecture.png" alt=""></p><blockquote><ul><li>3개의 데이터 전용 노드, 1개의 마스터 전용 노드로 구성합니다.</li><li>Master Node가 설치된 서버에는 Kibana, Logstash 및 기타 프로그램들을 같이 설치합니다.</li><li>마스터 노드만 HTTP REST API를 열고, Data Node 들은 Transport 통신만을 합니다.</li><li>Kibana, Logstash 및 기타 프로그램은 Master Node 와 REST로 통신합니다.</li><li>데이터는 Master Node 를 통해서만 색인됩니다.</li></ul></blockquote><h3 id="서버-생성"><a href="#서버-생성" class="headerlink" title="서버 생성"></a>서버 생성</h3><p>AWS 에서 EC2 인스턴스를 생성하도록 합니다. 인스턴스 생성은 AWS EC2 콘솔에서 그냥 실행하면서 넘어가면 되기 때문에 과정을 따로 설명하진 않겠습니다. 제가 구성한 환경은 아래와 같습니다.</p><blockquote><ul><li>m4.xlarge: 4 vCPU / 16GB</li><li>OS: Amazon Linux AMI 2017.09.1</li><li>EBS: 200GB</li></ul></blockquote><h3 id="시간대-설정"><a href="#시간대-설정" class="headerlink" title="시간대 설정"></a>시간대 설정</h3><p>서버의 초기 시간 설정이 UTP로 되어 있는데, 대한민국 서울 시간으로 변경 해 줍니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo cp -p /usr/share/zoneinfo/Asia/Seoul /etc/localtime</span><br></pre></td></tr></table></figure></p><h3 id="Java-업그레이드"><a href="#Java-업그레이드" class="headerlink" title="Java 업그레이드"></a>Java 업그레이드</h3><p>Elasticsearch 를 지원하는 Java 버전은 <a href="https://www.elastic.co/support/matrix#matrix_jvm" target="_blank" rel="noopener">Support Matrix</a> 페이지에서 확인이 가능합니다. 1.8 버전에서 안정적으로 사용이 가능합니다.</p><p>제가 설치한 AWS 서버에는 기본적으로 Java 1.7 버전이 설치가 되어 있습니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ ~]$ java -version</span><br><span class="line">java version &quot;1.7.0_161&quot;</span><br><span class="line">OpenJDK Runtime Environment (amzn-2.6.12.0.75.amzn1-x86_64 u161-b00)</span><br><span class="line">OpenJDK 64-Bit Server VM (build 24.161-b00, mixed mode)</span><br></pre></td></tr></table></figure><p>Amazon Linux 는 CentOS 기반이기 때문에 Yum 설치가 가능합니다. Java를 1.8로 업데이트 해 줍니다.</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum remove java-1.7.0-openjdk.x86_64 -y</span><br><span class="line">sudo yum install java-1.8.0-openjdk-devel.x86_64 -y</span><br></pre></td></tr></table></figure><h3 id="Elasticsearch-설치"><a href="#Elasticsearch-설치" class="headerlink" title="Elasticsearch 설치"></a>Elasticsearch 설치</h3><p>다음 링크를 참고하여 elasticsearch 를 yum 을 이용한 rpm 으로 설치하겠습니다.<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/rpm.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/rpm.html</a></p><p>최신 버전의 elasticsearch를 yum 으로 설치하기 위해서는 <code>/etc/yum.repos.d/</code> 디렉토리 아래에 <code>elasticsearch.repo</code> 파일을 만들고 아래와 같이 내용을 입력해야 합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[elasticsearch-6.x]</span><br><span class="line">name=Elasticsearch repository for 6.x packages</span><br><span class="line">baseurl=https://artifacts.elastic.co/packages/6.x/yum</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch</span><br><span class="line">enabled=1</span><br><span class="line">autorefresh=1</span><br><span class="line">type=rpm-md</span><br></pre></td></tr></table></figure></p><p>파일을 추가하고 나서 이제 yum을 이용해서 Elasticsearch를 설치합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install elasticsearch -y</span><br></pre></td></tr></table></figure></p><p>위와 같이 하면 최신 버전이 설치되고, 특정 버전을 설치하고 싶으면 다음과 같이 뒤에 버전을 명시 해 주면 됩니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install elasticsearch-6.0.0 -y</span><br></pre></td></tr></table></figure></p><p>elasticsearch rpm 설치 문서에 나와 있는대로 <code>ps -p 1</code> 를 이용해서 SysV <code>init</code> 과 <code>systemd</code> 중 어떤 서비스를 사용하는지 확인합니다. 제가 만든 인스턴스는 init 을 사용하고 있습니다. 서비스에 등록하기 위해 다음 명령을 실행합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo chkconfig --add elasticsearch</span><br></pre></td></tr></table></figure></p><p>Elasticsearch는 이제 service 명령으로 실행 또는 종료가 가능합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo -i service elasticsearch start</span><br><span class="line">sudo -i service elasticsearch stop</span><br></pre></td></tr></table></figure></p><h2 id="호스트명-변경"><a href="#호스트명-변경" class="headerlink" title="호스트명 변경"></a>호스트명 변경</h2><p>호스트명을 변경하기 위해서는 <code>/etc/sysconfig/network</code> 파일의 <code>HOSTNAME=</code> 부분을 수정합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/sysconfig/network</span><br><span class="line">HOSTNAME=es-master</span><br></pre></td></tr></table></figure></p><p>나중에 설정 및 모니터링을 편하게 하기 위함이며 생성하는 각 인스턴스 별로 <code>HOSTNAME=es-master</code>, <code>HOSTNAME=es-data-1</code>, <code>HOSTNAME=es-data-2</code> 등과 같이 설정 해 줍니다.<br>호스트명을 변경 한 후에는 인스턴스를 재시작 해야 합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo reboot</span><br></pre></td></tr></table></figure></p><p>인스턴스 재 시작 후에 호스트명이 제대로 바뀌었는지, elasticsearch 서비스는 자동으로 잘 실행 되는지 한번 확인 해 봅니다.<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[ ~]$ hostname</span><br><span class="line">es-master</span><br><span class="line">[ ~]$ curl localhost:9200</span><br><span class="line">&#123;</span><br><span class="line">  "name" : "KTKlgNl",</span><br><span class="line">  "cluster_name" : "elasticsearch",</span><br><span class="line">  "cluster_uuid" : "uFE9aZzTR6CQxoLlJ_aogA",</span><br><span class="line">  "version" : &#123;</span><br><span class="line">    "number" : "6.0.0",</span><br><span class="line">    "build_hash" : "8f0685b",</span><br><span class="line">    "build_date" : "2017-11-10T18:41:22.859Z",</span><br><span class="line">    "build_snapshot" : false,</span><br><span class="line">    "lucene_version" : "7.0.1",</span><br><span class="line">    "minimum_wire_compatibility_version" : "5.6.0",</span><br><span class="line">    "minimum_index_compatibility_version" : "5.0.0"</span><br><span class="line">  &#125;,</span><br><span class="line">  "tagline" : "You Know, for Search"</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="Elasticsearch-설정"><a href="#Elasticsearch-설정" class="headerlink" title="Elasticsearch 설정"></a>Elasticsearch 설정</h2><p>이제 Elasticsearch의 설치가 완료 되었습니다. RPM 버전의 기본적인 설치 경로들은 아래와 같습니다.</p><ul><li>기본 프로그램 (<strong>$ES_HOME</strong>) : <code>/usr/share/elasticsearch</code><ul><li>실행 파일 : <code>bin/elasticsearch</code></li><li>플러그인 : <code>plugins</code></li></ul></li><li>설정 : <code>/etc/elasticsearch</code><ul><li><code>elasticsearch.yml</code></li><li><code>jvm.options</code></li><li><code>log4j2.properties</code></li></ul></li><li>데이터 (<strong>path.data</strong>) : <code>/var/lib/elasticsearch</code></li><li>로그 (<strong>path.logs</strong>) : <code>/var/log/elasticsearch</code></li></ul><p>데이터와 로그 파일의 경로는 <code>/etc/elasticsearch/elasticsearch.yml</code> 설정 파일에서 수정이 가능합니다.<br>모든 경로에 접근하기 위해서는 기본적으로 root 권한을 필요로 합니다. 예를 들어 elasticsearch.yml 설정 파일을 vim 으로 편집하려고 하면 다음과 같이 실행해야 합니다.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/elasticsearch/elasticsearch.yml</span><br></pre></td></tr></table></figure></p><p>Elasticsearch의 기본 클러스터명은 <strong>elasticsearch</strong> 로 되어 있습니다. Elasticsearch의 노드들은 클러스터명을 기준으로 바인딩이 되기 때문에 처음 설치가 끝나면 우선적으로 클러스터명을 바꿔 줘야 나중에 실수로 노드가 엉뚱한 클러스터에 바인딩 되는 것을 막을 수 있습니다. <code>elasticsearch.yml</code>설정 파일을 열고 먼저 클러스터명을 변경 해 줍니다.<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">cluster.name:</span> <span class="string">es-demo</span></span><br></pre></td></tr></table></figure></p><p>노드들도 나중에 구분하기 편하도록 노드명에 호스트 이름을 사용하도록 설정 해 줍니다.<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">node.name:</span> <span class="string">$&#123;HOSTNAME&#125;</span></span><br></pre></td></tr></table></figure></p><p>이제 elasticsearch 를 재시작하여 노드명과 클러스터명이 정상적으로 반영이 되었는지를 확인 해 봅니다.<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[ ~]$ sudo service elasticsearch restart</span><br><span class="line">Stopping elasticsearch:                                    [  OK  ]</span><br><span class="line">Starting elasticsearch:                                    [  OK  ]</span><br><span class="line">[ ~]$ curl localhost:9200</span><br><span class="line">&#123;</span><br><span class="line">  "name" : "es-master",</span><br><span class="line">  "cluster_name" : "es-demo",</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>이제 Elasticsearch의 기본 설치가 끝났습니다.<br>다음 포스트에서는 운영에서 사용하기 위한 메모리, 네트워크 및 기타 세부 설정들을 해 보도록 하겠습니다. Elasticsearch 노드는 네트워크 설정이 되어있지 않으면 개발 모드로 실행되어 localhost 에서만 접근이 가능하며 부트스트랩 체크를 하지 않습니다. 네트워크 설정을 실제 IP 주소로 변경하고 실행하게 되면 운영 모드로 인식을 하고 부트스트랩 체크를 하게 되며 여러가지 운영 설정 등을 바꿔줘야 합니다.</p><blockquote><p><strong>1. 서버 생성 및 Elasticsearch RPM 설치</strong><br><a href="/2018/01/2018-01-build-es-cluster-2">2. 메모리, 네트워크 설정 및 플러그인 설치</a><br><a href="/2018/01/2018-01-build-es-cluster-3">3. 클러스터 구성 및 마스터, 데이터 노드 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-4">4. Kibana 설치 및 X-Pack Monitoring 확인</a><br><a href="/2018/01/2018-01-build-es-cluster-5">5. NFS 구성 및 elasticsearch 추가 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-6">6. X-Pack Security를 이용한 SSL 및 TLS 설정</a><br><a href="/2018/01/2018-01-build-es-cluster-7">7. X-Pack License 적용 및 사용자 생성</a><br><a href="/2018/01/2018-01-build-es-cluster-8">8. Logstash 설치 및 Elasticsearch 기본 템플릿 설정</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;이번에 필요에 의해 새로 Elastic Stack 클러스터를 구성하게 되었습니다. 구성 방법에 대해서는 여러 레퍼런스가 있지만, 처음부터 다시 한번 쭉 정리 할 생각으로 블로그 포스트에 시리즈로 작성하려고 합니다.&lt;/p&gt;
&lt;blockquote&gt;

      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
      <category term="Elastic Cluster Settings" scheme="http://kimjmin.net/tags/Elastic-Cluster-Settings/"/>
    
  </entry>
  
  <entry>
    <title>기술 문서 번역에 대하여</title>
    <link href="http://kimjmin.net/2017/11/2017-11-technical-translations/"/>
    <id>http://kimjmin.net/2017/11/2017-11-technical-translations/</id>
    <published>2017-11-12T15:00:00.000Z</published>
    <updated>2017-11-24T22:42:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>정말 오랫만에 포스팅을 하네요. 오늘 일 하다가 재미있는게 있어 페이스북에 끄적일까 하다가 좀 더 오래 기록하고 싶은 마음에 블로그에 끄적여봅니다.</p><p>5.0 버전이 출시된게 엊그제 같은데 6.0 출시 준비를 앞두고 있습니다. 항상 그렇듯이 새 버전이 나올때면 홈페이지 리뉴얼과 관련 보도자료, 블로그 등일 쏟아낼 준비를 하기에 마케팅, 웹 페이지 관리 인원들은 이맘때 쯤 정신 없이 바쁜 시간을 보냅니다.</p><p>저도 업무상 한국 로컬라이징 컨텐츠들의 1차 리뷰어로 지정이 되어 있어서 여러가지 번역 및 리뷰 업무들이 쏟아져 들어오기 마련입니다. 5.0 출시할 때 30페이지 정도 번역 리뷰했던 기억이 나는데 (<a href="/2016/11/elastic-stack-5-release">관련 포스트</a>) 이번에도 그 때 만큼은 아니더라도 여러 새로운 페이지들이 있어 작업 요청들이 계속 날아오고 있네요.</p><p>그래도 제가 항상 뿌듯하게 생각했던 것 중 하나가, Elastic 이라는 회사가 (모든 페이지는 아니지만) 로컬라이징 하는 부분에 있어서 제공하고 있는 6개의 언어 중 대한민국의 한글 페이지가 있다는 점입니다.</p><p><img src="local_pages.png" alt=""></p><p>더군다나 이게 일본어 다음으로 불어, 독일어보다 먼저 제공되고 있었던 점에 대해 항상 자랑스럽게 생각하고 있습니다. Elastic이 한국 시장을 그만큼 많이 신경쓰고 있다는 뜻으로 볼 수도 있고, 로컬 Evangelist 입장에서 (괜히 혼자) 열심히 한 것 같은 보람도 느끼고요. 그리고 요즘은 저희 한국 지역에도 직원분들이 많이 합류하시고, 한국어 정보 전용 페이지(<a href="https://info.elastic.co/Korea-Local-Page" target="_blank" rel="noopener">https://info.elastic.co/Korea-Local-Page</a>) 도 만들고, 이래 저래 많이 발전해서 기쁩니다.</p><p>여튼, 짧게 쓰려고 했는데, 서론이 길었습니다. 오늘도 6.0 관련 포스트 번역 리뷰를 하다 보니 재미있는 일이 있어서 끄적입니다. <a href="/2016/11/elastic-stack-5-release">5.0 번역 포스트</a>에서도 그렇고 <a href="https://www.elastic.co/kr/blog/introducing-elastic-cloud-and-elastic-cloud-enterprise" target="_blank" rel="noopener">Elastic Cloud 관련 블로그</a> 에 썼던 것도 그렇고, 기술 문서 번역, 특히 Elastic 의 기술 문서 번역은 참 쉽지 않은것 같습니다. (이게 다 원문을 이상하게 쓰는 우리 테크니컬 라이터 Tyler 때문이다… 사실 이 친구가 저희 Evangelist 팀 리드이면서 제 매니저 입니다.)</p><p>오늘 번역 리뷰하다가 발견한 이슈들 입니다.</p><p><strong><em><code>culmination of thousands of pull requests</code> –&gt; <code>수천건의 가져오기 요청의 정점에 도달</code></em></strong><br>네… Git을 안 써봤으면 개발자도 모르는 <code>pull requests</code> 라는 용어를 번역가 분들이 어찌 알겠습니까. 저는 <code>수천건의 풀 리퀘스트 요청에 대한 결과가 정점을 찍는 날입니다</code>로 바꿨습니다.</p><p><strong><em><code>GA(General Availability)</code> –&gt; <code>일반 가용성</code></em></strong><br>RC, GA 같은 용어들도 계속 제품 릴리스를 찾는 분이거나 프로덕트 매니지먼트 하시는 분이 아니면 모를수도 있죠. 저는 <code>일반 사용자 버전</code>으로 바꿨습니다.</p><p><strong><em><code>GA’ing multiple products on the same day isn’t enough</code> –&gt; <code>다양한 상품의 일반 가용성 확보로는 충분치 않기에</code></em></strong><br>마찬가지로 GA 관련 용어네요. 일부 기능은 아직 GA 버전에서 제공 안 된다는 내용인데 저는 <code>여러 제품의 일반 사용 버전의 출시가 여의치가 않은 관계로</code> 라고 바꿨습니다.</p><p><strong><em><code>Either you craft the next great novel</code> –&gt; <code>소설을 창작하거나</code></em></strong><br>이건 원문 쓴 친구를 탓해야 할 것 같은데요. 이런 문학적인 표현을 너무 좋아해서… 저도 고민 많이 했는데 <code>새로운 위대한 이야기 부터 시작 해 보시겠습니까?</code> 라고 일단 적었습니다.</p><p><strong><em><code>sparse data</code> –&gt; <code>스파스  데이터</code></em></strong><br>sparse 라는 단어가 군데군데 비어있다는 뜻인데 번역하기 애매하다보니. 스파스 데이터 라고도 쓰이긴 합니다. 성김 데이터 라고 하기에는 이상해서 일단 <code>데이터 파편</code> 이라고 했습니다. 혹시 더 좋은 번역 있으면 제보 부탁드립니다.</p><p><strong><em><code>more accessible via contrast changes</code> –&gt; <code>대비 및 변화 접근이 용이</code></em></strong><br>이건 시각화 도구인 Kibana 관련 내용인데, 이것도 시각 장애인, 색약 대한 웹 접근성에 대해 알고 계신 분이 아니면 이해하기 힘든 용어입니다. 저는 <code>더 나은 접근성을 위한 색상 대비</code> 라고 고쳤습니다.</p><p>그리고 하이라이트<br><strong><em><code>Beats &lt;3 containers and, also, Beats &lt;3 modules</code> –&gt; <code>3개 미만 컨테이너와 Beats 및 3개 미만 모듈의 Beats</code></em></strong><br>처음에 3개 미만의 컨테이너 라고 하길래 대체 뭔 소리인가 하고 원문을 찾아봤습니다. &lt;3 이 하트를 옆으로 뉘어 놓은 이모티콘을 나타내는건데, 이걸 3개 미만이라고 번역했네요. <code>Beats는 컨테이너를 사랑❤️합니다. 또한 Beats는 모듈을 사랑❤️합니다</code>로 고쳤습니다.</p><p>그리고 아예 번역이 안 된 문단이 있었는데 거기 아래와 같은 문장이 있습니다.<br><strong><em><code>First class support for Spark’s Structured Streaming has landed</code></em></strong><br>이것도 원문을 쓴 친구가 First class … landad 라고 써서 항공기의 퍼스트 클래스를 타고 착륙하다는 뜻으로 말장난을 써 놓은것 같습니다. 고민 하다가 <code>Spark의 Structured Streaming에 대한 First Class등급의 지원이 6.0에 안착했습니다</code> 라고 번역했네요.</p><p>리뷰 끝내고 생각 해 보니 위 내용을 번역하려면 정말 쉽지는 않겠구나 싶었습니다. 저보다 영어 잘 하시는 분들이 물론 많으시겠지만, 제가 이런 저런 잡다한거 해 본 경험이 이런데서 도움이 될줄 누가 알았겠는가 싶네요.<br>Git을 안 해봤으면 pull request를 몰랐을테고, Front-End 쪽 안 건드려 봤으면 색약, 시각장애인 지원 관련 웹 접근성이란 주제에 대해 연관지어 생각 못 해봤을 것 같습니다. 그리고 저희 프로덕트들에 대한 내용도 알아야 하고, 히피스러운 우리 테크니컬 라이터 친구의 생각도 알아야 하고요.<br>거기에, 오늘은 없었지만 예전에는 스타워즈, 스타트렉 덕후가 아니면 알지 못하는 표현까지 나온적도 있었고요.</p><p>여하튼 배운 것은 살다 보면 어떻게든 쓰이는 날이 오기 마련인 것 같습니다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;정말 오랫만에 포스팅을 하네요. 오늘 일 하다가 재미있는게 있어 페이스북에 끄적일까 하다가 좀 더 오래 기록하고 싶은 마음에 블로그에 끄적여봅니다.&lt;/p&gt;
&lt;p&gt;5.0 버전이 출시된게 엊그제 같은데 6.0 출시 준비를 앞두고 있습니다. 항상 그렇
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://kimjmin.net/tags/Elasticsearch/"/>
    
      <category term="Elastic" scheme="http://kimjmin.net/tags/Elastic/"/>
    
  </entry>
  
</feed>
